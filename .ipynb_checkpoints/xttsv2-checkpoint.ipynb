{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6e9e570-24e1-4239-8162-47475e41b681",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e0dea1a-b071-4966-a3b9-43afe219cda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffe75366-4b79-4574-a2ef-04d573160ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 10:12:32.239510: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "from TTS.config.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.layers.xtts.trainer.gpt_trainer import GPTArgs, GPTTrainer, GPTTrainerConfig, XttsAudioConfig\n",
    "from TTS.utils.manage import ModelManager\n",
    "from TTS.config import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "156bf601-5971-49d9-81f4-b2c5b938fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "config_dataset = BaseDatasetConfig(\n",
    "    formatter=\"ljspeech\",\n",
    "    meta_file_train=\"Mixed_formatted.txt\",\n",
    "    # meta_file_train = \"No_Shouting_formatted.txt\",\n",
    "    path=os.path.join(OUT_PATH, \"data/\"),\n",
    "    language = \"en\"\n",
    ")\n",
    "# Define here the dataset that you want to use for the fine-tuning on.\n",
    "# config_dataset = BaseDatasetConfig(\n",
    "#     formatter=\"ljspeech\",\n",
    "#     dataset_name=\"ljspeech\",\n",
    "#     path=\"/raid/datasets/LJSpeech-1.1_24khz/\",\n",
    "#     meta_file_train=\"/raid/datasets/LJSpeech-1.1_24khz/metadata.csv\",\n",
    "#     language=\"en\",\n",
    "# )\n",
    "\n",
    "# Add here the configs of the datasets\n",
    "DATASETS_CONFIG_LIST = [config_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f46e491-967e-4976-8a10-1c2630adee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define audio config\n",
    "audio_config = XttsAudioConfig(sample_rate=22050, dvae_sample_rate=22050, output_sample_rate=22050)\n",
    "# training parameters config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6df6ece-5546-4f78-a848-9b6972bd1f78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the path where XTTS v1.1.1 files will be downloaded\n",
    "CHECKPOINTS_OUT_PATH = os.path.join(OUT_PATH, \"xttsv2_checkpoint\", \"XTTS_v2.0_original_model_files/\")\n",
    "os.makedirs(CHECKPOINTS_OUT_PATH, exist_ok=True)\n",
    "\n",
    "\n",
    "# DVAE files\n",
    "DVAE_CHECKPOINT_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/dvae.pth\"\n",
    "MEL_NORM_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/mel_stats.pth\"\n",
    "\n",
    "# Set the path to the downloaded files\n",
    "DVAE_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(DVAE_CHECKPOINT_LINK))\n",
    "MEL_NORM_FILE = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(MEL_NORM_LINK))\n",
    "\n",
    "# download DVAE files if needed\n",
    "if not os.path.isfile(DVAE_CHECKPOINT) or not os.path.isfile(MEL_NORM_FILE):\n",
    "    print(\" > Downloading DVAE files!\")\n",
    "    ModelManager._download_model_files([MEL_NORM_LINK, DVAE_CHECKPOINT_LINK], CHECKPOINTS_OUT_PATH, progress_bar=True)\n",
    "\n",
    "# Download XTTS v2.0 checkpoint if needed\n",
    "TOKENIZER_FILE_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/vocab.json\"\n",
    "XTTS_CHECKPOINT_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/model.pth\"\n",
    "\n",
    "# XTTS transfer learning parameters: You we need to provide the paths of XTTS model checkpoint that you want to do the fine tuning.\n",
    "TOKENIZER_FILE = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(TOKENIZER_FILE_LINK))  # vocab.json file\n",
    "XTTS_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(XTTS_CHECKPOINT_LINK))  # model.pth file\n",
    "\n",
    "# download XTTS v2.0 files if needed\n",
    "if not os.path.isfile(TOKENIZER_FILE) or not os.path.isfile(XTTS_CHECKPOINT):\n",
    "    print(\" > Downloading XTTS v2.0 files!\")\n",
    "    ModelManager._download_model_files(\n",
    "        [TOKENIZER_FILE_LINK, XTTS_CHECKPOINT_LINK], CHECKPOINTS_OUT_PATH, progress_bar=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68f02965-cd37-4e27-af80-5996efec877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init args and config\n",
    "\n",
    "XTTS_CHECKPOINT = \"xttsv2_checkpoint/XTTS_v2.0_original_model_files/model.pth\"\n",
    "\n",
    "model_args = GPTArgs(\n",
    "    max_conditioning_length=int(132300*2.5),  # 18 secs\n",
    "    min_conditioning_length=66150,  # 3 secs\n",
    "    debug_loading_failures=True,\n",
    "    max_wav_length=255995*3,  # ~33 seconds\n",
    "    max_text_length=700,\n",
    "    mel_norm_file=MEL_NORM_FILE,\n",
    "    dvae_checkpoint=DVAE_CHECKPOINT,\n",
    "    xtts_checkpoint=XTTS_CHECKPOINT,  # checkpoint path of the model that you want to fine-tune\n",
    "    tokenizer_file=TOKENIZER_FILE,\n",
    "    gpt_num_audio_tokens=1026,\n",
    "    gpt_start_audio_token=1024,\n",
    "    gpt_stop_audio_token=1025,\n",
    "    gpt_use_masking_gt_prompt_approach=True,\n",
    "    gpt_use_perceiver_resampler=True,\n",
    "    # gpt_max_text_tokens = 500,\n",
    "    # gpt_max_prompt_tokens = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f1249d2-ba61-4372-bffb-b2f128dead68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training sentences generations\n",
    "# SPEAKER_REFERENCE = [\n",
    "#     \"data/wavs/1. Tyler1 THE_WORST_JUNGLER_EVER 1.wav\"  # speaker reference to be used in training test sentences\n",
    "# ]\n",
    "\n",
    "SPEAKER_REFERENCE = [\"data/wavs/\" + wav for wav in os.listdir('data/wavs/') if \"wav\" in wav]\n",
    "\n",
    "LANGUAGE = config_dataset.language\n",
    "\n",
    "config = GPTTrainerConfig(\n",
    "    output_path=OUT_PATH + '/xttsv2_checkpoint',\n",
    "    model_args=model_args,\n",
    "    run_name=\"tyler1_xttsv2\",\n",
    "    project_name=\"tyler1\",\n",
    "    dashboard_logger=\"tensorboard\",\n",
    "    # logger_uri=None,\n",
    "    audio=audio_config,\n",
    "    batch_size=1,\n",
    "    # batch_group_size=48,\n",
    "    eval_batch_size=1,\n",
    "    num_loader_workers=2,\n",
    "    # eval_split_max_size=256,\n",
    "    print_step=50,\n",
    "    plot_step=100,\n",
    "    log_model_step=1000,\n",
    "    save_step=10000,\n",
    "    save_n_checkpoints=1,\n",
    "    save_checkpoints=True,\n",
    "    # target_loss=\"loss\",\n",
    "    print_eval=True,\n",
    "    # Optimizer values like tortoise, pytorch implementation with modifications to not apply WD to non-weight parameters.\n",
    "    optimizer=\"AdamW\",\n",
    "    optimizer_wd_only_on_weights=True, # for multi-gpu training please make it False\n",
    "    optimizer_params={\"betas\": [0.9, 0.96], \"eps\": 1e-8, \"weight_decay\": 1e-2},\n",
    "    lr=5e-06,  # learning rate\n",
    "    lr_scheduler=\"MultiStepLR\",\n",
    "    # it was adjusted accordly for the new step scheme\n",
    "    lr_scheduler_params={\"milestones\": [50000 * 18, 150000 * 18, 300000 * 18], \"gamma\": 0.5, \"last_epoch\": -1},\n",
    "    test_sentences=[\n",
    "        {\n",
    "            \"text\": \"So he starts off level one just doing this. Like oh he's gonna like bro he losing, doesn't hit a single thing. Look at it like- what the fuck. Like bro okay whatever. Watch this top dive bro. I solo made Vayne one HP, right? Just wait out and fucking ghost, you twat.\",\n",
    "            \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "            \"language\": LANGUAGE,\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Okay whatever you're auto-ing a ward sure it's fine. Bro what are you d- just wait you fucking freak. Where's he walking to by the way? What the fuck! It's not a win-trade this guy played as our Jarvan too. He's a one-trick like bro.\",\n",
    "            \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "            \"language\": LANGUAGE,\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Hey! Sup? It's me, Tyler1 ready for the pre-alpha. We're back baby!\",\n",
    "            \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "            \"language\": LANGUAGE,\n",
    "        },\n",
    "    ],\n",
    "    # mixed_precision = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "698da81d-da4f-4500-8e45-a7a99a344cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Found 558 files in /home/sagemaker-user/dist/main/data\n"
     ]
    }
   ],
   "source": [
    "def formatter(root_path, manifest_file, **kwargs):  # pylint: disable=unused-argument\n",
    "    \"\"\"Assumes each line as ```<filename>|<transcription>```\n",
    "    \"\"\"\n",
    "    txt_file = os.path.join(root_path, manifest_file)\n",
    "    items = []\n",
    "    speaker_name = \"Tyler1\"\n",
    "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
    "        for line in ttf:\n",
    "            cols = line.split(\"|\")\n",
    "            wav_file = os.path.dirname(os.path.abspath('__file__')) + f\"/data/wavs/{cols[0]}.wav\"\n",
    "            text = cols[1]\n",
    "            # print(text)\n",
    "            items.append({\"text\":text, \"audio_file\":wav_file, \"speaker_name\":speaker_name, \"root_path\": root_path})\n",
    "    return items\n",
    "\n",
    "\n",
    "train_samples, eval_samples = load_tts_samples(\n",
    "    config_dataset,\n",
    "    # DATASETS_CONFIG_LIST,\n",
    "    eval_split=True,\n",
    "    # eval_split_max_size=config.eval_split_max_size,\n",
    "    eval_split_size=0.1,\n",
    "    formatter = formatter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be8dfbb1-2499-460d-ab56-8250696bc6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> DVAE weights restored from: /home/sagemaker-user/dist/main/xttsv2_checkpoint/XTTS_v2.0_original_model_files/dvae.pth\n"
     ]
    }
   ],
   "source": [
    "# init the model from config\n",
    "model = GPTTrainer.init_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "737adcb9-c5f1-4b24-8bc1-5649609a56f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: False\n",
      " | > Precision: float32\n",
      " | > Current device: 0\n",
      " | > Num. of GPUs: 1\n",
      " | > Num. of CPUs: 48\n",
      " | > Num. of Torch Threads: 1\n",
      " | > Torch seed: 1\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      " > Start Tensorboard: tensorboard --logdir=/home/sagemaker-user/dist/main/xttsv2_checkpoint/tyler1_xttsv2-February-28-2024_10+12AM-e526ca1\n",
      "\n",
      " > Model has 518442047 parameters\n"
     ]
    }
   ],
   "source": [
    "# init the trainer and 🚀\n",
    "\n",
    "# model_path = \"xttsv2_checkpoint/tyler1_xttsv2-February-19-2024_05+30AM-2b31060/\"\n",
    "trainer = Trainer(\n",
    "    TrainerArgs(\n",
    "        # continue_path = model_path,  # xtts checkpoint is restored via xtts_checkpoint key so no need of restore it using Trainer restore_path parameter\n",
    "        skip_train_epoch=False,\n",
    "        start_with_eval=True,\n",
    "        grad_accum_steps=256, # batch_size * grad_accum_steps >= 256,\n",
    "    ),\n",
    "    config,\n",
    "    output_path=OUT_PATH,\n",
    "    model=model,\n",
    "    train_samples=train_samples,\n",
    "    eval_samples=eval_samples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca2ed33-898b-4e1f-beea-18421ab87e5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/1000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/xttsv2_checkpoint/tyler1_xttsv2-February-28-2024_10+12AM-e526ca1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Filtering invalid eval samples!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Total eval samples after filtering: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_text_ce: 0.0258428156375885  (0.0258428156375885)\n",
      "     | > loss_mel_ce: 3.432394504547119  (3.432394504547119)\n",
      "     | > loss: 3.458237409591675  (3.458237409591675)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_text_ce: 0.019895030185580254  (0.019895030185580254)\n",
      "     | > loss_mel_ce: 4.103507041931152  (4.103507041931152)\n",
      "     | > loss: 4.123402118682861  (4.123402118682861)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_text_ce: 0.023496203124523163  (0.021695616655051708)\n",
      "     | > loss_mel_ce: 4.415037155151367  (4.25927209854126)\n",
      "     | > loss: 4.438533306121826  (4.280967712402344)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_text_ce: 0.03131064027547836  (0.02490062452852726)\n",
      "     | > loss_mel_ce: 4.0959882736206055  (4.204844156901042)\n",
      "     | > loss: 4.127298831939697  (4.229744752248128)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_text_ce: 0.024248966947197914  (0.024737710133194923)\n",
      "     | > loss_mel_ce: 4.163119316101074  (4.19441294670105)\n",
      "     | > loss: 4.187368392944336  (4.21915066242218)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_text_ce: 0.024374810978770256  (0.02466513030230999)\n",
      "     | > loss_mel_ce: 4.284640312194824  (4.2124584197998045)\n",
      "     | > loss: 4.309015274047852  (4.237123584747314)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_text_ce: 0.02294992096722126  (0.0243792620797952)\n",
      "     | > loss_mel_ce: 4.513387203216553  (4.26261321703593)\n",
      "     | > loss: 4.536336898803711  (4.286992470423381)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss_text_ce: 0.028767794370651245  (0.025006195264203206)\n",
      "     | > loss_mel_ce: 4.307527542114258  (4.269029549189976)\n",
      "     | > loss: 4.336295127868652  (4.294035707201276)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss_text_ce: 0.03047734685242176  (0.025690089212730527)\n",
      "     | > loss_mel_ce: 3.920578956604004  (4.22547322511673)\n",
      "     | > loss: 3.9510562419891357  (4.251163274049759)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss_text_ce: 0.02816014736890793  (0.02596454011897246)\n",
      "     | > loss_mel_ce: 4.328797340393066  (4.236953682369656)\n",
      "     | > loss: 4.35695743560791  (4.262918180889553)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss_text_ce: 0.025610901415348053  (0.02592917624861002)\n",
      "     | > loss_mel_ce: 3.903076410293579  (4.203565955162048)\n",
      "     | > loss: 3.928687334060669  (4.229495096206665)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss_text_ce: 0.02803296595811844  (0.02612042985856533)\n",
      "     | > loss_mel_ce: 4.385215759277344  (4.220079573717984)\n",
      "     | > loss: 4.413248538970947  (4.246199954639781)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss_text_ce: 0.024450933560729027  (0.025981305167078972)\n",
      "     | > loss_mel_ce: 4.431699752807617  (4.23771458864212)\n",
      "     | > loss: 4.456150531768799  (4.2636958360672)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss_text_ce: 0.027442554011940956  (0.026093708924376048)\n",
      "     | > loss_mel_ce: 3.7257161140441895  (4.198330090596126)\n",
      "     | > loss: 3.7531585693359375  (4.224423738626333)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss_text_ce: 0.023564007133245468  (0.025913015939295292)\n",
      "     | > loss_mel_ce: 3.576181411743164  (4.153890899249485)\n",
      "     | > loss: 3.599745512008667  (4.1798038652965)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss_text_ce: 0.024289416149258614  (0.025804775953292846)\n",
      "     | > loss_mel_ce: 4.250449180603027  (4.160328118006388)\n",
      "     | > loss: 4.274738788604736  (4.186132860183716)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss_text_ce: 0.029503319412469864  (0.02603593491949141)\n",
      "     | > loss_mel_ce: 4.428754806518555  (4.177104786038398)\n",
      "     | > loss: 4.458258152008057  (4.203140690922737)\n",
      "\n",
      "\u001b[1m   --> STEP: 17\u001b[0m\n",
      "     | > loss_text_ce: 0.024240462109446526  (0.02593031887184171)\n",
      "     | > loss_mel_ce: 4.218018054962158  (4.179511448916266)\n",
      "     | > loss: 4.242258548736572  (4.205441741382375)\n",
      "\n",
      "\u001b[1m   --> STEP: 18\u001b[0m\n",
      "     | > loss_text_ce: 0.021510476246476173  (0.025684772059321404)\n",
      "     | > loss_mel_ce: 4.26738977432251  (4.184393578105501)\n",
      "     | > loss: 4.288900375366211  (4.210078332159254)\n",
      "\n",
      "\u001b[1m   --> STEP: 19\u001b[0m\n",
      "     | > loss_text_ce: 0.027884244918823242  (0.02580053378876887)\n",
      "     | > loss_mel_ce: 3.815401077270508  (4.164972920166817)\n",
      "     | > loss: 3.843285322189331  (4.190773436897679)\n",
      "\n",
      "\u001b[1m   --> STEP: 20\u001b[0m\n",
      "     | > loss_text_ce: 0.02070084773004055  (0.02554554948583245)\n",
      "     | > loss_mel_ce: 4.322951316833496  (4.172871840000151)\n",
      "     | > loss: 4.343652248382568  (4.198417377471924)\n",
      "\n",
      "\u001b[1m   --> STEP: 21\u001b[0m\n",
      "     | > loss_text_ce: 0.02628662995994091  (0.02558083903221857)\n",
      "     | > loss_mel_ce: 4.005584716796875  (4.1649057865142805)\n",
      "     | > loss: 4.031871318817139  (4.190486612774077)\n",
      "\n",
      "\u001b[1m   --> STEP: 22\u001b[0m\n",
      "     | > loss_text_ce: 0.02334888093173504  (0.0254793863912875)\n",
      "     | > loss_mel_ce: 3.840151309967041  (4.150144219398497)\n",
      "     | > loss: 3.8635001182556152  (4.175623590295965)\n",
      "\n",
      "\u001b[1m   --> STEP: 23\u001b[0m\n",
      "     | > loss_text_ce: 0.0262875035405159  (0.02551452191951482)\n",
      "     | > loss_mel_ce: 3.9938273429870605  (4.143347833467565)\n",
      "     | > loss: 4.020114898681641  (4.168862342834473)\n",
      "\n",
      "\u001b[1m   --> STEP: 24\u001b[0m\n",
      "     | > loss_text_ce: 0.02841067872941494  (0.025635195119927328)\n",
      "     | > loss_mel_ce: 3.9215428829193115  (4.134105960528054)\n",
      "     | > loss: 3.949953556060791  (4.1597411433855696)\n",
      "\n",
      "\u001b[1m   --> STEP: 25\u001b[0m\n",
      "     | > loss_text_ce: 0.020412994548678398  (0.02542630709707737)\n",
      "     | > loss_mel_ce: 4.009640693664551  (4.129127349853515)\n",
      "     | > loss: 4.030053615570068  (4.154553642272949)\n",
      "\n",
      "\u001b[1m   --> STEP: 26\u001b[0m\n",
      "     | > loss_text_ce: 0.0275257658213377  (0.02550705550954892)\n",
      "     | > loss_mel_ce: 4.48268461227417  (4.142725706100463)\n",
      "     | > loss: 4.5102105140686035  (4.168232752726628)\n",
      "\n",
      "\u001b[1m   --> STEP: 27\u001b[0m\n",
      "     | > loss_text_ce: 0.025937670841813087  (0.025523004225558706)\n",
      "     | > loss_mel_ce: 3.8973472118377686  (4.133637613720363)\n",
      "     | > loss: 3.9232847690582275  (4.159160605183354)\n",
      "\n",
      "\u001b[1m   --> STEP: 28\u001b[0m\n",
      "     | > loss_text_ce: 0.026734329760074615  (0.025566265851791416)\n",
      "     | > loss_mel_ce: 4.245726585388184  (4.137640791279928)\n",
      "     | > loss: 4.2724609375  (4.163207045623234)\n",
      "\n",
      "\u001b[1m   --> STEP: 29\u001b[0m\n",
      "     | > loss_text_ce: 0.026065444573760033  (0.025583478911169643)\n",
      "     | > loss_mel_ce: 4.333691596984863  (4.144401163890443)\n",
      "     | > loss: 4.359756946563721  (4.169984628414285)\n",
      "\n",
      "\u001b[1m   --> STEP: 30\u001b[0m\n",
      "     | > loss_text_ce: 0.029331926256418228  (0.025708427156011262)\n",
      "     | > loss_mel_ce: 4.765378475189209  (4.165100407600402)\n",
      "     | > loss: 4.794710636138916  (4.1908088286717735)\n",
      "\n",
      "\u001b[1m   --> STEP: 31\u001b[0m\n",
      "     | > loss_text_ce: 0.022756662219762802  (0.02561320893226131)\n",
      "     | > loss_mel_ce: 4.3169708251953125  (4.16999945332927)\n",
      "     | > loss: 4.339727401733398  (4.195612653609245)\n",
      "\n",
      "\u001b[1m   --> STEP: 32\u001b[0m\n",
      "     | > loss_text_ce: 0.029011718928813934  (0.025719412369653583)\n",
      "     | > loss_mel_ce: 3.3777999877929688  (4.145243220031261)\n",
      "     | > loss: 3.4068117141723633  (4.1709626242518425)\n",
      "\n",
      "\u001b[1m   --> STEP: 33\u001b[0m\n",
      "     | > loss_text_ce: 0.025210723280906677  (0.025703997548782463)\n",
      "     | > loss_mel_ce: 4.298224925994873  (4.149879029302885)\n",
      "     | > loss: 4.3234357833862305  (4.17558302301349)\n",
      "\n",
      "\u001b[1m   --> STEP: 34\u001b[0m\n",
      "     | > loss_text_ce: 0.02821725234389305  (0.02577791680746219)\n",
      "     | > loss_mel_ce: 4.204695701599121  (4.1514912843704215)\n",
      "     | > loss: 4.232913017272949  (4.17726919931524)\n",
      "\n",
      "\u001b[1m   --> STEP: 35\u001b[0m\n",
      "     | > loss_text_ce: 0.02095675654709339  (0.02564016937145165)\n",
      "     | > loss_mel_ce: 4.017526626586914  (4.147663722719464)\n",
      "     | > loss: 4.038483619689941  (4.173303897040231)\n",
      "\n",
      "\u001b[1m   --> STEP: 36\u001b[0m\n",
      "     | > loss_text_ce: 0.021769125014543533  (0.025532640361537535)\n",
      "     | > loss_mel_ce: 4.331515789031982  (4.152770724561479)\n",
      "     | > loss: 4.35328483581543  (4.178303367561764)\n",
      "\n",
      "\u001b[1m   --> STEP: 37\u001b[0m\n",
      "     | > loss_text_ce: 0.026605308055877686  (0.025561631380303484)\n",
      "     | > loss_mel_ce: 4.3077592849731445  (4.156959604572605)\n",
      "     | > loss: 4.334364414215088  (4.182521233687529)\n",
      "\n",
      "\u001b[1m   --> STEP: 38\u001b[0m\n",
      "     | > loss_text_ce: 0.024238841608166695  (0.02552682112314199)\n",
      "     | > loss_mel_ce: 4.735090255737305  (4.172173569076939)\n",
      "     | > loss: 4.759329319000244  (4.197700393827337)\n",
      "\n",
      "\u001b[1m   --> STEP: 39\u001b[0m\n",
      "     | > loss_text_ce: 0.024868186563253403  (0.025509933057503823)\n",
      "     | > loss_mel_ce: 4.3644022941589355  (4.1771025107457085)\n",
      "     | > loss: 4.389270305633545  (4.202612442848009)\n",
      "\n",
      "\u001b[1m   --> STEP: 40\u001b[0m\n",
      "     | > loss_text_ce: 0.023932499811053276  (0.025470497226342557)\n",
      "     | > loss_mel_ce: 4.211084365844727  (4.177952057123184)\n",
      "     | > loss: 4.235016822814941  (4.203422552347183)\n",
      "\n",
      "\u001b[1m   --> STEP: 41\u001b[0m\n",
      "     | > loss_text_ce: 0.024894151836633682  (0.02545644002171551)\n",
      "     | > loss_mel_ce: 3.912122964859009  (4.171468420726497)\n",
      "     | > loss: 3.9370172023773193  (4.196924860884503)\n",
      "\n",
      "\u001b[1m   --> STEP: 42\u001b[0m\n",
      "     | > loss_text_ce: 0.0239222664386034  (0.025419912079260462)\n",
      "     | > loss_mel_ce: 4.092085838317871  (4.169578359240577)\n",
      "     | > loss: 4.116008281707764  (4.19499827566601)\n",
      "\n",
      "\u001b[1m   --> STEP: 43\u001b[0m\n",
      "     | > loss_text_ce: 0.024197204038500786  (0.025391477008545122)\n",
      "     | > loss_mel_ce: 4.191395282745361  (4.170085729554642)\n",
      "     | > loss: 4.215592384338379  (4.1954772084258325)\n",
      "\n",
      "\u001b[1m   --> STEP: 44\u001b[0m\n",
      "     | > loss_text_ce: 0.022943437099456787  (0.025335839737884024)\n",
      "     | > loss_mel_ce: 4.512812614440918  (4.177874976938421)\n",
      "     | > loss: 4.5357561111450195  (4.203210819851268)\n",
      "\n",
      "\u001b[1m   --> STEP: 45\u001b[0m\n",
      "     | > loss_text_ce: 0.027383236214518547  (0.02538133743736479)\n",
      "     | > loss_mel_ce: 3.888608694076538  (4.171446837319268)\n",
      "     | > loss: 3.915992021560669  (4.1968281798892555)\n",
      "\n",
      "\u001b[1m   --> STEP: 46\u001b[0m\n",
      "     | > loss_text_ce: 0.03719445317983627  (0.025638144301331562)\n",
      "     | > loss_mel_ce: 4.453364372253418  (4.177575479383053)\n",
      "     | > loss: 4.490558624267578  (4.203213624332263)\n",
      "\n",
      "\u001b[1m   --> STEP: 47\u001b[0m\n",
      "     | > loss_text_ce: 0.022509293630719185  (0.025571573010467467)\n",
      "     | > loss_mel_ce: 4.037238121032715  (4.174589578141557)\n",
      "     | > loss: 4.059747219085693  (4.20016114762489)\n",
      "\n",
      "\u001b[1m   --> STEP: 48\u001b[0m\n",
      "     | > loss_text_ce: 0.026667701080441475  (0.02559440901192526)\n",
      "     | > loss_mel_ce: 4.3409624099731445  (4.178055678804715)\n",
      "     | > loss: 4.3676300048828125  (4.203650082151096)\n",
      "\n",
      "\u001b[1m   --> STEP: 49\u001b[0m\n",
      "     | > loss_text_ce: 0.024501953274011612  (0.0255721139968658)\n",
      "     | > loss_mel_ce: 4.310519218444824  (4.180759016348391)\n",
      "     | > loss: 4.335021018981934  (4.206331121678256)\n",
      "\n",
      "\u001b[1m   --> STEP: 50\u001b[0m\n",
      "     | > loss_text_ce: 0.02415468730032444  (0.02554376546293497)\n",
      "     | > loss_mel_ce: 3.6589670181274414  (4.170323176383972)\n",
      "     | > loss: 3.683121681213379  (4.195866932868959)\n",
      "\n",
      "\u001b[1m   --> STEP: 51\u001b[0m\n",
      "     | > loss_text_ce: 0.023784883320331573  (0.025509277577785885)\n",
      "     | > loss_mel_ce: 4.003493785858154  (4.167052011863858)\n",
      "     | > loss: 4.027278900146484  (4.192561285168518)\n",
      "\n",
      "\u001b[1m   --> STEP: 52\u001b[0m\n",
      "     | > loss_text_ce: 0.02515219710767269  (0.025502410645668324)\n",
      "     | > loss_mel_ce: 4.083771705627441  (4.165450467513158)\n",
      "     | > loss: 4.10892391204834  (4.1909528741469755)\n",
      "\n",
      "\u001b[1m   --> STEP: 53\u001b[0m\n",
      "     | > loss_text_ce: 0.024245643988251686  (0.0254786980672265)\n",
      "     | > loss_mel_ce: 3.7123241424560547  (4.156900914210193)\n",
      "     | > loss: 3.736569881439209  (4.182379610133621)\n",
      "\n",
      "\u001b[1m   --> STEP: 54\u001b[0m\n",
      "     | > loss_text_ce: 0.023691177368164062  (0.025445595832058677)\n",
      "     | > loss_mel_ce: 4.487429618835449  (4.1630218161476975)\n",
      "     | > loss: 4.511120796203613  (4.188467409875658)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time: 0.020982216905664514 \u001b[0m(+0)\n",
      "     | > avg_loss_text_ce: 0.025445595832058677 \u001b[0m(+0)\n",
      "     | > avg_loss_mel_ce: 4.1630218161476975 \u001b[0m(+0)\n",
      "     | > avg_loss: 4.188467409875658 \u001b[0m(+0)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 1/1000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/xttsv2_checkpoint/tyler1_xttsv2-February-28-2024_10+12AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-02-28 10:14:01) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Sampling by language: dict_keys(['en'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 10:14:02 -- STEP: 0/503 -- GLOBAL_STEP: 0\u001b[0m\n",
      "     | > loss_text_ce: 0.02602170594036579  (0.02602170594036579)\n",
      "     | > loss_mel_ce: 3.3024559020996094  (3.3024559020996094)\n",
      "     | > loss: 0.013001865707337856  (0.013001865707337856)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.3264  (0.32635974884033203)\n",
      "     | > loader_time: 0.7926  (0.792572021484375)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 10:14:16 -- STEP: 50/503 -- GLOBAL_STEP: 50\u001b[0m\n",
      "     | > loss_text_ce: 0.029459068551659584  (0.026212509870529175)\n",
      "     | > loss_mel_ce: 4.78672456741333  (nan)\n",
      "     | > loss: 0.01881321705877781  (nan)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2741  (0.2664296293258668)\n",
      "     | > loader_time: 0.0104  (0.018505811691284187)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 10:14:30 -- STEP: 100/503 -- GLOBAL_STEP: 100\u001b[0m\n",
      "     | > loss_text_ce: 0.029689673334360123  (0.02601445695385337)\n",
      "     | > loss_mel_ce: 6.378173828125  (nan)\n",
      "     | > loss: 0.025030717253684998  (nan)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2254  (0.2661931657791138)\n",
      "     | > loader_time: 0.0104  (0.017970209121704092)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 10:14:45 -- STEP: 150/503 -- GLOBAL_STEP: 150\u001b[0m\n",
      "     | > loss_text_ce: 0.0282137468457222  (0.02594503377874692)\n",
      "     | > loss_mel_ce: 3.9667372703552246  (nan)\n",
      "     | > loss: 0.015605277381837368  (nan)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2558  (0.26627882003784187)\n",
      "     | > loader_time: 0.0105  (0.016861945788065588)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 10:14:58 -- STEP: 200/503 -- GLOBAL_STEP: 200\u001b[0m\n",
      "     | > loss_text_ce: 0.02459115721285343  (0.02600614904426038)\n",
      "     | > loss_mel_ce: 3.6305742263793945  (nan)\n",
      "     | > loss: 0.014277989976108074  (nan)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2092  (0.2619948208332062)\n",
      "     | > loader_time: 0.0254  (0.016711181402206426)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 10:15:12 -- STEP: 250/503 -- GLOBAL_STEP: 250\u001b[0m\n",
      "     | > loss_text_ce: 0.028121313080191612  (0.02605893825739622)\n",
      "     | > loss_mel_ce: 5.619438648223877  (nan)\n",
      "     | > loss: 0.022060781717300415  (nan)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2371  (0.2615603132247923)\n",
      "     | > loader_time: 0.011  (0.01619324207305909)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 10:15:26 -- STEP: 300/503 -- GLOBAL_STEP: 300\u001b[0m\n",
      "     | > loss_text_ce: 0.024285005405545235  (0.026107611836244663)\n",
      "     | > loss_mel_ce: 4.042064189910889  (nan)\n",
      "     | > loss: 0.015884175896644592  (nan)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2439  (0.261762042045593)\n",
      "     | > loader_time: 0.0185  (0.015921896298726403)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-02-28 10:15:39 -- STEP: 350/503 -- GLOBAL_STEP: 350\u001b[0m\n",
      "     | > loss_text_ce: 0.021400436758995056  (0.02617893968309675)\n",
      "     | > loss_mel_ce: 4.303030967712402  (nan)\n",
      "     | > loss: 0.016892310231924057  (nan)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2747  (0.26106614112854004)\n",
      "     | > loader_time: 0.0126  (0.01572558471134732)\n",
      "\n",
      " > Keyboard interrupt detected.\n",
      " > Saving model before exiting...\n",
      "\n",
      " > CHECKPOINT : /home/sagemaker-user/dist/main/xttsv2_checkpoint/tyler1_xttsv2-February-28-2024_10+12AM-e526ca1/checkpoint_394.pth\n",
      " ! Run is kept in /home/sagemaker-user/dist/main/xttsv2_checkpoint/tyler1_xttsv2-February-28-2024_10+12AM-e526ca1\n"
     ]
    }
   ],
   "source": [
    "trainer.fit() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b94610e-09a9-4db2-89cd-924dcc1e2f22",
   "metadata": {},
   "source": [
    "##  Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21649c2a-0d88-446d-a6c4-c93abe354d53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from TTS.api import TTS\n",
    "from subprocess import getoutput\n",
    "from IPython.display import Audio\n",
    "\n",
    "# using the default version set in 🐸TTS\n",
    "# tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\", gpu=True)\n",
    "\n",
    "# using a specific version\n",
    "# 👀 see the branch names for versions on https://huggingface.co/coqui/XTTS-v2/tree/main\n",
    "# ❗some versions might be incompatible with the API\n",
    "# tts = TTS(\"xtts_v2.0.2\", gpu=True)\n",
    "\n",
    "# getting the latest XTTS_v2\n",
    "tts = TTS(\"xtts\").to(\"cuda\")\n",
    "\n",
    "SPEAKER_REFERENCE = [\"data/wavs/\" + wav for wav in os.listdir('data/wavs/') if \"wav\" in wav]\n",
    "\n",
    "tts.tts_to_file(text= \"What's up? What's up?! It's Tyler1 baby! Back with the voice\",\n",
    "                file_path=\"generated_audio/xtts_output.wav\",\n",
    "                speaker_wav=SPEAKER_REFERENCE,\n",
    "                language=\"en\"\n",
    "               )\n",
    "\n",
    "Audio(\"generated_audio/xtts_output.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b1097-dbba-417d-aec3-ac89ae2afe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from TTS.tts.configs.xtts_config import XttsConfig\n",
    "from TTS.tts.models.xtts import Xtts\n",
    "from subprocess import getoutput\n",
    "from IPython.display import Audio\n",
    "import time\n",
    "\n",
    "\n",
    "# Add here the xtts_config path\n",
    "CONFIG_PATH = \"xttsv2_checkpoint/tyler1_xttsv2-February-28-2024_01+16PM-e526ca1/config.json\"\n",
    "# Add here the vocab file that you have used to train the model\n",
    "TOKENIZER_PATH = \"xttsv2_checkpoint/XTTS_v2.0_original_model_files/vocab.json\"\n",
    "# Add here the checkpoint that you want to do inference with\n",
    "XTTS_CHECKPOINT = \"xttsv2_checkpoint/tyler1_xttsv2-February-28-2024_01+16PM-e526ca1/best_model.pth\"\n",
    "\n",
    "# List of all wavs for speaker reference\n",
    "wavs = getoutput(\"ls data/wavs/*.wav\").split(\"\\n\")\n",
    "# Add here the speaker reference\n",
    "SPEAKER_REFERENCE = [\"data/wavs/\" + wav for wav in os.listdir('data/wavs/') if \"wav\" in wav]\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "config = XttsConfig()\n",
    "config.load_json(CONFIG_PATH)\n",
    "model = Xtts.init_from_config(config)\n",
    "model.load_checkpoint(config, checkpoint_path=XTTS_CHECKPOINT, vocab_path=TOKENIZER_PATH, use_deepspeed=False)\n",
    "model.to(\"cuda\")\n",
    "\n",
    "gpt_cond_latent, speaker_embedding = model.get_conditioning_latents(audio_path= SPEAKER_REFERENCE)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4e669-289d-4241-8cfc-c729a820a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences=[\"So he starts off level one just doing this. Like oh he's gonna like bro he losing, doesn't hit a single thing. Look at it like- what the fuck. Like bro okay whatever. Watch this top dive bro. I solo made Vayne one HP, right? Just wait out and fucking ghost, you twat.\",\n",
    "            \"Okay whatever you're auto-ing a ward sure it's fine. Bro what are you d- just wait you fucking freak. Where's he walking to by the way? What the fuck! It's not a win-trade this guy played as our Jarvan too. He's a one-trick like bro.\",\n",
    "            \"Hey! Sup? It's me, Tyler1 ready for the pre-alpha. We're back baby!\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1b424f-41cd-47cf-a204-cdd152b8084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "sample = 0\n",
    "\n",
    "start = time.time()\n",
    "out = model.inference(\n",
    "    test_sentences[sample],\n",
    "    \"en\",\n",
    "    gpt_cond_latent,\n",
    "    speaker_embedding,\n",
    "    temperature=0.2, # Add custom parameters here\n",
    "    top_k = model.config.top_k,\n",
    "    top_p = model.config.top_p,\n",
    "    # length_penalty = model.config.length_penalty,\n",
    ")\n",
    "\n",
    "# output wav path\n",
    "OUTPUT_WAV_PATH = \"generated_audio/xtts_output{}.wav\".format(sample)\n",
    "\n",
    "torchaudio.save(OUTPUT_WAV_PATH, torch.tensor(out[\"wav\"]).unsqueeze(0), 22050)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "\n",
    "Audio(OUTPUT_WAV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e399b8cc-9282-4146-9953-24534edf69d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sentences[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
