{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6e9e570-24e1-4239-8162-47475e41b681",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffe75366-4b79-4574-a2ef-04d573160ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 14:15:08.344124: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-07 14:15:08.397726: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "from TTS.config.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.layers.xtts.trainer.gpt_trainer import GPTArgs, GPTTrainer, GPTTrainerConfig, XttsAudioConfig\n",
    "from TTS.utils.manage import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "156bf601-5971-49d9-81f4-b2c5b938fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "config_dataset = BaseDatasetConfig(\n",
    "    formatter=\"ljspeech\",\n",
    "    meta_file_train=\"Mixed_formatted.txt\",\n",
    "    # meta_file_train = \"No_Shouting_formatted.txt\",\n",
    "    path=os.path.join(OUT_PATH, \"data/\"),\n",
    "    language = \"en\"\n",
    ")\n",
    "# Define here the dataset that you want to use for the fine-tuning on.\n",
    "# config_dataset = BaseDatasetConfig(\n",
    "#     formatter=\"ljspeech\",\n",
    "#     dataset_name=\"ljspeech\",\n",
    "#     path=\"/raid/datasets/LJSpeech-1.1_24khz/\",\n",
    "#     meta_file_train=\"/raid/datasets/LJSpeech-1.1_24khz/metadata.csv\",\n",
    "#     language=\"en\",\n",
    "# )\n",
    "\n",
    "# Add here the configs of the datasets\n",
    "DATASETS_CONFIG_LIST = [config_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f46e491-967e-4976-8a10-1c2630adee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define audio config\n",
    "audio_config = XttsAudioConfig(sample_rate=22050, dvae_sample_rate=22050, output_sample_rate=24000)\n",
    "# training parameters config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6df6ece-5546-4f78-a848-9b6972bd1f78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Downloading DVAE files!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0.00/1.07k [00:00<?, ?iB/s]\n",
      "100%|██████████| 1.07k/1.07k [00:00<00:00, 3.73kiB/s]\n",
      "\n",
      "  5%|▌         | 11.1M/211M [00:00<00:01, 111MiB/s]\u001b[A\n",
      " 11%|█         | 22.1M/211M [00:00<00:02, 86.5MiB/s]\u001b[A\n",
      " 16%|█▌        | 33.4M/211M [00:00<00:01, 97.0MiB/s]\u001b[A\n",
      " 21%|██▏       | 44.8M/211M [00:00<00:01, 103MiB/s] \u001b[A\n",
      " 27%|██▋       | 57.3M/211M [00:00<00:01, 111MiB/s]\u001b[A\n",
      " 33%|███▎      | 69.8M/211M [00:00<00:01, 115MiB/s]\u001b[A\n",
      " 39%|███▊      | 81.5M/211M [00:00<00:01, 91.6MiB/s]\u001b[A\n",
      " 44%|████▍     | 93.4M/211M [00:00<00:01, 98.8MiB/s]\u001b[A\n",
      " 50%|█████     | 105M/211M [00:01<00:01, 104MiB/s]  \u001b[A\n",
      " 55%|█████▌    | 116M/211M [00:01<00:00, 102MiB/s]\u001b[A\n",
      " 60%|██████    | 127M/211M [00:01<00:00, 98.9MiB/s]\u001b[A\n",
      " 65%|██████▌   | 137M/211M [00:01<00:00, 78.7MiB/s]\u001b[A\n",
      " 71%|███████   | 149M/211M [00:01<00:00, 87.8MiB/s]\u001b[A\n",
      " 76%|███████▋  | 161M/211M [00:01<00:00, 96.5MiB/s]\u001b[A\n",
      " 82%|████████▏ | 173M/211M [00:01<00:00, 103MiB/s] \u001b[A\n",
      " 88%|████████▊ | 185M/211M [00:01<00:00, 108MiB/s]\u001b[A\n",
      " 94%|█████████▎| 197M/211M [00:01<00:00, 112MiB/s]\u001b[A\n",
      " 99%|█████████▉| 209M/211M [00:02<00:00, 113MiB/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Downloading XTTS v2.0 files!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211M/211M [00:02<00:00, 90.3MiB/s]\n",
      "\n",
      "100%|██████████| 361k/361k [00:00<00:00, 1.18MiB/s]\n",
      "\n",
      "  1%|          | 11.0M/1.87G [00:00<00:16, 110MiB/s]\u001b[A\n",
      "  1%|          | 22.9M/1.87G [00:00<00:16, 115MiB/s]\u001b[A\n",
      "  2%|▏         | 35.7M/1.87G [00:00<00:15, 121MiB/s]\u001b[A\n",
      "  3%|▎         | 47.8M/1.87G [00:00<00:15, 118MiB/s]\u001b[A\n",
      "  3%|▎         | 59.7M/1.87G [00:00<00:15, 117MiB/s]\u001b[A\n",
      "  4%|▍         | 71.4M/1.87G [00:00<00:15, 117MiB/s]\u001b[A\n",
      "  4%|▍         | 83.1M/1.87G [00:00<00:15, 115MiB/s]\u001b[A\n",
      "  5%|▌         | 94.7M/1.87G [00:00<00:15, 115MiB/s]\u001b[A\n",
      "  6%|▌         | 107M/1.87G [00:00<00:14, 118MiB/s] \u001b[A\n",
      "  6%|▋         | 119M/1.87G [00:01<00:14, 118MiB/s]\u001b[A\n",
      "  7%|▋         | 131M/1.87G [00:01<00:14, 119MiB/s]\u001b[A\n",
      "  8%|▊         | 144M/1.87G [00:01<00:14, 122MiB/s]\u001b[A\n",
      "  8%|▊         | 156M/1.87G [00:01<00:13, 123MiB/s]\u001b[A\n",
      "  9%|▉         | 169M/1.87G [00:01<00:13, 124MiB/s]\u001b[A\n",
      " 10%|▉         | 182M/1.87G [00:01<00:13, 125MiB/s]\u001b[A\n",
      " 10%|█         | 195M/1.87G [00:01<00:13, 125MiB/s]\u001b[A\n",
      " 11%|█         | 207M/1.87G [00:01<00:13, 126MiB/s]\u001b[A\n",
      " 12%|█▏        | 220M/1.87G [00:01<00:13, 124MiB/s]\u001b[A\n",
      " 12%|█▏        | 232M/1.87G [00:01<00:13, 124MiB/s]\u001b[A\n",
      " 13%|█▎        | 245M/1.87G [00:02<00:13, 125MiB/s]\u001b[A\n",
      " 14%|█▍        | 257M/1.87G [00:02<00:13, 123MiB/s]\u001b[A\n",
      " 14%|█▍        | 270M/1.87G [00:02<00:13, 122MiB/s]\u001b[A\n",
      " 15%|█▌        | 283M/1.87G [00:02<00:12, 124MiB/s]\u001b[A\n",
      " 16%|█▌        | 295M/1.87G [00:02<00:12, 124MiB/s]\u001b[A\n",
      " 16%|█▋        | 308M/1.87G [00:02<00:12, 125MiB/s]\u001b[A\n",
      " 17%|█▋        | 320M/1.87G [00:02<00:12, 122MiB/s]\u001b[A\n",
      " 18%|█▊        | 332M/1.87G [00:02<00:12, 118MiB/s]\u001b[A\n",
      " 18%|█▊        | 345M/1.87G [00:02<00:12, 121MiB/s]\u001b[A\n",
      " 19%|█▉        | 357M/1.87G [00:02<00:12, 121MiB/s]\u001b[A\n",
      " 20%|█▉        | 370M/1.87G [00:03<00:12, 122MiB/s]\u001b[A\n",
      " 20%|██        | 382M/1.87G [00:03<00:12, 120MiB/s]\u001b[A\n",
      " 21%|██        | 395M/1.87G [00:03<00:12, 122MiB/s]\u001b[A\n",
      " 22%|██▏       | 408M/1.87G [00:03<00:11, 124MiB/s]\u001b[A\n",
      " 22%|██▏       | 420M/1.87G [00:03<00:11, 122MiB/s]\u001b[A\n",
      " 23%|██▎       | 432M/1.87G [00:03<00:12, 119MiB/s]\u001b[A\n",
      " 24%|██▍       | 444M/1.87G [00:03<00:12, 117MiB/s]\u001b[A\n",
      " 24%|██▍       | 456M/1.87G [00:03<00:12, 117MiB/s]\u001b[A\n",
      " 25%|██▌       | 468M/1.87G [00:03<00:11, 117MiB/s]\u001b[A\n",
      " 26%|██▌       | 480M/1.87G [00:03<00:11, 116MiB/s]\u001b[A\n",
      " 26%|██▋       | 491M/1.87G [00:04<00:11, 115MiB/s]\u001b[A\n",
      " 27%|██▋       | 503M/1.87G [00:04<00:11, 114MiB/s]\u001b[A\n",
      " 28%|██▊       | 514M/1.87G [00:04<00:11, 114MiB/s]\u001b[A\n",
      " 28%|██▊       | 527M/1.87G [00:04<00:11, 117MiB/s]\u001b[A\n",
      " 29%|██▉       | 538M/1.87G [00:04<00:11, 116MiB/s]\u001b[A\n",
      " 29%|██▉       | 551M/1.87G [00:04<00:11, 119MiB/s]\u001b[A\n",
      " 30%|███       | 563M/1.87G [00:04<00:10, 120MiB/s]\u001b[A\n",
      " 31%|███       | 575M/1.87G [00:04<00:11, 117MiB/s]\u001b[A\n",
      " 31%|███▏      | 587M/1.87G [00:04<00:11, 116MiB/s]\u001b[A\n",
      " 32%|███▏      | 599M/1.87G [00:05<00:10, 116MiB/s]\u001b[A\n",
      " 33%|███▎      | 610M/1.87G [00:05<00:10, 115MiB/s]\u001b[A\n",
      " 33%|███▎      | 622M/1.87G [00:05<00:10, 114MiB/s]\u001b[A\n",
      " 34%|███▍      | 633M/1.87G [00:05<00:10, 113MiB/s]\u001b[A\n",
      " 34%|███▍      | 644M/1.87G [00:05<00:11, 110MiB/s]\u001b[A\n",
      " 35%|███▌      | 656M/1.87G [00:05<00:10, 111MiB/s]\u001b[A\n",
      " 36%|███▌      | 667M/1.87G [00:05<00:10, 111MiB/s]\u001b[A\n",
      " 36%|███▋      | 678M/1.87G [00:05<00:10, 111MiB/s]\u001b[A\n",
      " 37%|███▋      | 689M/1.87G [00:05<00:10, 111MiB/s]\u001b[A\n",
      " 38%|███▊      | 702M/1.87G [00:05<00:10, 116MiB/s]\u001b[A\n",
      " 38%|███▊      | 715M/1.87G [00:06<00:09, 119MiB/s]\u001b[A\n",
      " 39%|███▉      | 727M/1.87G [00:06<00:09, 121MiB/s]\u001b[A\n",
      " 40%|███▉      | 740M/1.87G [00:06<00:09, 122MiB/s]\u001b[A\n",
      " 40%|████      | 752M/1.87G [00:06<00:09, 120MiB/s]\u001b[A\n",
      " 41%|████      | 764M/1.87G [00:06<00:09, 118MiB/s]\u001b[A\n",
      " 42%|████▏     | 776M/1.87G [00:06<00:09, 116MiB/s]\u001b[A\n",
      " 42%|████▏     | 788M/1.87G [00:06<00:09, 119MiB/s]\u001b[A\n",
      " 43%|████▎     | 801M/1.87G [00:06<00:08, 121MiB/s]\u001b[A\n",
      " 44%|████▎     | 813M/1.87G [00:06<00:08, 119MiB/s]\u001b[A\n",
      " 44%|████▍     | 825M/1.87G [00:06<00:08, 121MiB/s]\u001b[A\n",
      " 45%|████▍     | 838M/1.87G [00:07<00:08, 121MiB/s]\u001b[A\n",
      " 45%|████▌     | 850M/1.87G [00:07<00:08, 118MiB/s]\u001b[A\n",
      " 46%|████▌     | 862M/1.87G [00:07<00:08, 120MiB/s]\u001b[A\n",
      " 47%|████▋     | 875M/1.87G [00:07<00:08, 121MiB/s]\u001b[A\n",
      " 47%|████▋     | 887M/1.87G [00:07<00:08, 122MiB/s]\u001b[A\n",
      " 48%|████▊     | 900M/1.87G [00:07<00:07, 123MiB/s]\u001b[A\n",
      " 49%|████▉     | 912M/1.87G [00:07<00:07, 123MiB/s]\u001b[A\n",
      " 49%|████▉     | 924M/1.87G [00:07<00:07, 123MiB/s]\u001b[A\n",
      " 50%|█████     | 937M/1.87G [00:07<00:07, 123MiB/s]\u001b[A\n",
      " 51%|█████     | 949M/1.87G [00:07<00:07, 123MiB/s]\u001b[A\n",
      " 51%|█████▏    | 961M/1.87G [00:08<00:07, 120MiB/s]\u001b[A\n",
      " 52%|█████▏    | 974M/1.87G [00:08<00:07, 120MiB/s]\u001b[A\n",
      " 53%|█████▎    | 986M/1.87G [00:08<00:07, 121MiB/s]\u001b[A\n",
      " 53%|█████▎    | 998M/1.87G [00:08<00:07, 121MiB/s]\u001b[A\n",
      " 54%|█████▍    | 1.01G/1.87G [00:08<00:06, 123MiB/s]\u001b[A\n",
      " 55%|█████▍    | 1.02G/1.87G [00:08<00:06, 124MiB/s]\u001b[A\n",
      " 55%|█████▌    | 1.04G/1.87G [00:08<00:06, 124MiB/s]\u001b[A\n",
      " 56%|█████▌    | 1.05G/1.87G [00:08<00:06, 119MiB/s]\u001b[A\n",
      " 57%|█████▋    | 1.06G/1.87G [00:08<00:06, 118MiB/s]\u001b[A\n",
      " 57%|█████▋    | 1.07G/1.87G [00:08<00:06, 120MiB/s]\u001b[A\n",
      " 58%|█████▊    | 1.08G/1.87G [00:09<00:06, 117MiB/s]\u001b[A\n",
      " 59%|█████▊    | 1.10G/1.87G [00:09<00:06, 115MiB/s]\u001b[A\n",
      " 59%|█████▉    | 1.11G/1.87G [00:09<00:06, 113MiB/s]\u001b[A\n",
      " 60%|█████▉    | 1.12G/1.87G [00:09<00:06, 113MiB/s]\u001b[A\n",
      " 61%|██████    | 1.13G/1.87G [00:09<00:06, 113MiB/s]\u001b[A\n",
      " 61%|██████    | 1.14G/1.87G [00:09<00:06, 112MiB/s]\u001b[A\n",
      " 62%|██████▏   | 1.15G/1.87G [00:09<00:06, 112MiB/s]\u001b[A\n",
      " 62%|██████▏   | 1.17G/1.87G [00:09<00:06, 116MiB/s]\u001b[A\n",
      " 63%|██████▎   | 1.18G/1.87G [00:09<00:05, 120MiB/s]\u001b[A\n",
      " 64%|██████▎   | 1.19G/1.87G [00:10<00:05, 119MiB/s]\u001b[A\n",
      " 64%|██████▍   | 1.20G/1.87G [00:10<00:06, 111MiB/s]\u001b[A\n",
      " 65%|██████▍   | 1.21G/1.87G [00:10<00:06, 103MiB/s]\u001b[A\n",
      " 66%|██████▌   | 1.22G/1.87G [00:10<00:06, 105MiB/s]\u001b[A\n",
      " 66%|██████▌   | 1.24G/1.87G [00:10<00:05, 107MiB/s]\u001b[A\n",
      " 67%|██████▋   | 1.25G/1.87G [00:10<00:05, 107MiB/s]\u001b[A\n",
      " 67%|██████▋   | 1.26G/1.87G [00:10<00:05, 108MiB/s]\u001b[A\n",
      " 68%|██████▊   | 1.27G/1.87G [00:10<00:05, 100MiB/s]\u001b[A\n",
      " 68%|██████▊   | 1.28G/1.87G [00:11<00:08, 71.4MiB/s]\u001b[A\n",
      " 69%|██████▉   | 1.29G/1.87G [00:11<00:06, 82.9MiB/s]\u001b[A\n",
      " 70%|██████▉   | 1.30G/1.87G [00:11<00:06, 92.4MiB/s]\u001b[A\n",
      " 70%|███████   | 1.31G/1.87G [00:11<00:05, 96.7MiB/s]\u001b[A\n",
      " 71%|███████   | 1.33G/1.87G [00:11<00:05, 104MiB/s] \u001b[A\n",
      " 72%|███████▏  | 1.34G/1.87G [00:11<00:04, 107MiB/s]\u001b[A\n",
      " 72%|███████▏  | 1.35G/1.87G [00:11<00:04, 109MiB/s]\u001b[A\n",
      " 73%|███████▎  | 1.36G/1.87G [00:11<00:04, 109MiB/s]\u001b[A\n",
      " 73%|███████▎  | 1.37G/1.87G [00:11<00:04, 109MiB/s]\u001b[A\n",
      " 74%|███████▍  | 1.38G/1.87G [00:11<00:04, 109MiB/s]\u001b[A\n",
      " 75%|███████▍  | 1.39G/1.87G [00:12<00:04, 109MiB/s]\u001b[A\n",
      " 75%|███████▌  | 1.41G/1.87G [00:12<00:04, 110MiB/s]\u001b[A\n",
      " 76%|███████▌  | 1.42G/1.87G [00:12<00:04, 111MiB/s]\u001b[A\n",
      " 77%|███████▋  | 1.43G/1.87G [00:12<00:03, 115MiB/s]\u001b[A\n",
      " 77%|███████▋  | 1.44G/1.87G [00:12<00:03, 118MiB/s]\u001b[A\n",
      " 78%|███████▊  | 1.45G/1.87G [00:12<00:03, 120MiB/s]\u001b[A\n",
      " 79%|███████▊  | 1.47G/1.87G [00:12<00:03, 122MiB/s]\u001b[A\n",
      " 79%|███████▉  | 1.48G/1.87G [00:12<00:03, 118MiB/s]\u001b[A\n",
      " 80%|███████▉  | 1.49G/1.87G [00:12<00:03, 117MiB/s]\u001b[A\n",
      " 80%|████████  | 1.50G/1.87G [00:12<00:03, 119MiB/s]\u001b[A\n",
      " 81%|████████  | 1.52G/1.87G [00:13<00:03, 117MiB/s]\u001b[A\n",
      " 82%|████████▏ | 1.53G/1.87G [00:13<00:02, 116MiB/s]\u001b[A\n",
      " 82%|████████▏ | 1.54G/1.87G [00:13<00:02, 120MiB/s]\u001b[A\n",
      " 83%|████████▎ | 1.55G/1.87G [00:13<00:02, 117MiB/s]\u001b[A\n",
      " 84%|████████▎ | 1.56G/1.87G [00:13<00:02, 116MiB/s]\u001b[A\n",
      " 84%|████████▍ | 1.58G/1.87G [00:13<00:02, 116MiB/s]\u001b[A\n",
      " 85%|████████▍ | 1.59G/1.87G [00:13<00:02, 118MiB/s]\u001b[A\n",
      " 86%|████████▌ | 1.60G/1.87G [00:13<00:02, 116MiB/s]\u001b[A\n",
      " 86%|████████▌ | 1.61G/1.87G [00:13<00:02, 115MiB/s]\u001b[A\n",
      " 87%|████████▋ | 1.62G/1.87G [00:13<00:02, 115MiB/s]\u001b[A\n",
      " 87%|████████▋ | 1.63G/1.87G [00:14<00:02, 113MiB/s]\u001b[A\n",
      " 88%|████████▊ | 1.65G/1.87G [00:14<00:01, 112MiB/s]\u001b[A\n",
      " 89%|████████▊ | 1.66G/1.87G [00:14<00:01, 115MiB/s]\u001b[A\n",
      " 89%|████████▉ | 1.67G/1.87G [00:14<00:01, 114MiB/s]\u001b[A\n",
      " 90%|████████▉ | 1.68G/1.87G [00:14<00:01, 113MiB/s]\u001b[A\n",
      " 91%|█████████ | 1.69G/1.87G [00:14<00:01, 110MiB/s]\u001b[A\n",
      " 91%|█████████ | 1.70G/1.87G [00:14<00:01, 109MiB/s]\u001b[A\n",
      " 92%|█████████▏| 1.71G/1.87G [00:14<00:01, 110MiB/s]\u001b[A\n",
      " 92%|█████████▏| 1.73G/1.87G [00:14<00:01, 111MiB/s]\u001b[A\n",
      " 93%|█████████▎| 1.74G/1.87G [00:15<00:01, 111MiB/s]\u001b[A\n",
      " 94%|█████████▎| 1.75G/1.87G [00:15<00:01, 110MiB/s]\u001b[A\n",
      " 94%|█████████▍| 1.76G/1.87G [00:15<00:00, 109MiB/s]\u001b[A\n",
      " 95%|█████████▍| 1.77G/1.87G [00:15<00:00, 109MiB/s]\u001b[A\n",
      " 95%|█████████▌| 1.78G/1.87G [00:15<00:00, 109MiB/s]\u001b[A\n",
      " 96%|█████████▌| 1.79G/1.87G [00:15<00:00, 109MiB/s]\u001b[A\n",
      " 97%|█████████▋| 1.80G/1.87G [00:15<00:00, 109MiB/s]\u001b[A\n",
      " 97%|█████████▋| 1.81G/1.87G [00:15<00:00, 111MiB/s]\u001b[A\n",
      " 98%|█████████▊| 1.83G/1.87G [00:15<00:00, 115MiB/s]\u001b[A\n",
      " 98%|█████████▊| 1.84G/1.87G [00:15<00:00, 115MiB/s]\u001b[A\n",
      " 99%|█████████▉| 1.85G/1.87G [00:16<00:00, 114MiB/s]\u001b[A\n",
      "100%|█████████▉| 1.86G/1.87G [00:16<00:00, 113MiB/s]\u001b[A\n",
      "100%|██████████| 1.87G/1.87G [00:27<00:00, 113MiB/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "# Define the path where XTTS v1.1.1 files will be downloaded\n",
    "CHECKPOINTS_OUT_PATH = os.path.join(OUT_PATH, \"xttsv2_checkpoint\", \"XTTS_v2.0_original_model_files/\")\n",
    "os.makedirs(CHECKPOINTS_OUT_PATH, exist_ok=True)\n",
    "\n",
    "\n",
    "# DVAE files\n",
    "DVAE_CHECKPOINT_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/dvae.pth\"\n",
    "MEL_NORM_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/mel_stats.pth\"\n",
    "\n",
    "# Set the path to the downloaded files\n",
    "DVAE_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(DVAE_CHECKPOINT_LINK))\n",
    "MEL_NORM_FILE = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(MEL_NORM_LINK))\n",
    "\n",
    "# download DVAE files if needed\n",
    "if not os.path.isfile(DVAE_CHECKPOINT) or not os.path.isfile(MEL_NORM_FILE):\n",
    "    print(\" > Downloading DVAE files!\")\n",
    "    ModelManager._download_model_files([MEL_NORM_LINK, DVAE_CHECKPOINT_LINK], CHECKPOINTS_OUT_PATH, progress_bar=True)\n",
    "\n",
    "# Download XTTS v2.0 checkpoint if needed\n",
    "TOKENIZER_FILE_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/vocab.json\"\n",
    "XTTS_CHECKPOINT_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/model.pth\"\n",
    "\n",
    "# XTTS transfer learning parameters: You we need to provide the paths of XTTS model checkpoint that you want to do the fine tuning.\n",
    "TOKENIZER_FILE = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(TOKENIZER_FILE_LINK))  # vocab.json file\n",
    "XTTS_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(XTTS_CHECKPOINT_LINK))  # model.pth file\n",
    "\n",
    "# download XTTS v2.0 files if needed\n",
    "if not os.path.isfile(TOKENIZER_FILE) or not os.path.isfile(XTTS_CHECKPOINT):\n",
    "    print(\" > Downloading XTTS v2.0 files!\")\n",
    "    ModelManager._download_model_files(\n",
    "        [TOKENIZER_FILE_LINK, XTTS_CHECKPOINT_LINK], CHECKPOINTS_OUT_PATH, progress_bar=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68f02965-cd37-4e27-af80-5996efec877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init args and config\n",
    "model_args = GPTArgs(\n",
    "    max_conditioning_length=132300*2,  # 6 secs\n",
    "    min_conditioning_length=66150*2,  # 3 secs\n",
    "    debug_loading_failures=False,\n",
    "    max_wav_length=255995*4,  # ~11.6 seconds\n",
    "    max_text_length=700,\n",
    "    # mel_norm_file=MEL_NORM_FILE,\n",
    "    # dvae_checkpoint=DVAE_CHECKPOINT,\n",
    "    # xtts_checkpoint=XTTS_CHECKPOINT,  # checkpoint path of the model that you want to fine-tune\n",
    "    # tokenizer_file=TOKENIZER_FILE,\n",
    "    gpt_num_audio_tokens=1026,\n",
    "    gpt_start_audio_token=1024,\n",
    "    gpt_stop_audio_token=1025,\n",
    "    gpt_use_masking_gt_prompt_approach=True,\n",
    "    gpt_use_perceiver_resampler=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f1249d2-ba61-4372-bffb-b2f128dead68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training sentences generations\n",
    "SPEAKER_REFERENCE = [\n",
    "    \"data/wavs/1. Tyler1_THE_WORST_JUNGLER_EVER.wav\"  # speaker reference to be used in training test sentences\n",
    "]\n",
    "LANGUAGE = config_dataset.language\n",
    "\n",
    "config = GPTTrainerConfig(\n",
    "    output_path=OUT_PATH,\n",
    "    model_args=model_args,\n",
    "    run_name=\"tyler1_xttsv2\",\n",
    "    project_name=\"tyler1\",\n",
    "    dashboard_logger=\"tensorboard\",\n",
    "    # logger_uri=None,\n",
    "    audio=audio_config,\n",
    "    batch_size=2,\n",
    "    batch_group_size=48,\n",
    "    eval_batch_size=2,\n",
    "    num_loader_workers=2,\n",
    "    # eval_split_max_size=256,\n",
    "    print_step=50,\n",
    "    plot_step=100,\n",
    "    log_model_step=1000,\n",
    "    save_step=10000,\n",
    "    save_n_checkpoints=1,\n",
    "    save_checkpoints=True,\n",
    "    # target_loss=\"loss\",\n",
    "    print_eval=True,\n",
    "    # Optimizer values like tortoise, pytorch implementation with modifications to not apply WD to non-weight parameters.\n",
    "    optimizer=\"AdamW\",\n",
    "    optimizer_wd_only_on_weights=True, # for multi-gpu training please make it False\n",
    "    optimizer_params={\"betas\": [0.9, 0.96], \"eps\": 1e-8, \"weight_decay\": 1e-2},\n",
    "    lr=5e-06,  # learning rate\n",
    "    lr_scheduler=\"MultiStepLR\",\n",
    "    # it was adjusted accordly for the new step scheme\n",
    "    lr_scheduler_params={\"milestones\": [50000 * 18, 150000 * 18, 300000 * 18], \"gamma\": 0.5, \"last_epoch\": -1},\n",
    "    test_sentences=[\n",
    "        {\n",
    "            \"text\": \"It took me quite a long time to develop a voice, and now that I have it I'm not going to be silent.\",\n",
    "            \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "            \"language\": LANGUAGE,\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"This cake is great. It's so delicious and moist.\",\n",
    "            \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "            \"language\": LANGUAGE,\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "698da81d-da4f-4500-8e45-a7a99a344cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Found 76 files in /home/sagemaker-user/voiceclone/data\n"
     ]
    }
   ],
   "source": [
    "def formatter(root_path, manifest_file, **kwargs):  # pylint: disable=unused-argument\n",
    "    \"\"\"Assumes each line as ```<filename>|<transcription>```\n",
    "    \"\"\"\n",
    "    txt_file = os.path.join(root_path, manifest_file)\n",
    "    items = []\n",
    "    speaker_name = \"Tyler1\"\n",
    "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
    "        for line in ttf:\n",
    "            cols = line.split(\"|\")\n",
    "            wav_file = os.path.dirname(os.path.abspath('__file__')) + f\"/data/wavs/{cols[0]}.wav\"\n",
    "            text = cols[1]\n",
    "            # print(text)\n",
    "            items.append({\"text\":text, \"audio_file\":wav_file, \"speaker_name\":speaker_name, \"root_path\": root_path})\n",
    "    return items\n",
    "\n",
    "# load training samples\n",
    "# train_samples, eval_samples = load_tts_samples(\n",
    "#     DATASETS_CONFIG_LIST,\n",
    "#     eval_split=True,\n",
    "#     eval_split_max_size=config.eval_split_max_size,\n",
    "#     eval_split_size=config.eval_split_size,\n",
    "# )\n",
    "\n",
    "train_samples, eval_samples = load_tts_samples(\n",
    "    # config_dataset,\n",
    "    DATASETS_CONFIG_LIST,\n",
    "    eval_split=True,\n",
    "    # eval_split_max_size=config.eval_split_max_size,\n",
    "    eval_split_size=0.2,\n",
    "    formatter = formatter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "737adcb9-c5f1-4b24-8bc1-5649609a56f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: False\n",
      " | > Precision: float32\n",
      " | > Current device: 0\n",
      " | > Num. of GPUs: 1\n",
      " | > Num. of CPUs: 4\n",
      " | > Num. of Torch Threads: 1\n",
      " | > Torch seed: 1\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      " > Start Tensorboard: tensorboard --logdir=/home/sagemaker-user/voiceclone/tyler1_xttsv2-February-07-2024_03+13PM-7e6c2b3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> DVAE weights restored from: /home/sagemaker-user/voiceclone/xttsv2_checkpoint/XTTS_v2.0_original_model_files/dvae.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " > Model has 518442047 parameters\n"
     ]
    }
   ],
   "source": [
    "# init the model from config\n",
    "model = GPTTrainer.init_from_config(config)\n",
    "\n",
    "# init the trainer and 🚀\n",
    "trainer = Trainer(\n",
    "    TrainerArgs(\n",
    "        restore_path=None,  # xtts checkpoint is restored via xtts_checkpoint key so no need of restore it using Trainer restore_path parameter\n",
    "        skip_train_epoch=False,\n",
    "        start_with_eval=True,\n",
    "        grad_accum_steps=128, # batch_size * grad_accum_steps >= 256\n",
    "    ),\n",
    "    config,\n",
    "    output_path=OUT_PATH,\n",
    "    model=model,\n",
    "    train_samples=train_samples,\n",
    "    eval_samples=eval_samples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c14467b7-4e84-4c3c-ad89-845a1f760d60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/1000\u001b[0m\n",
      " --> /home/sagemaker-user/voiceclone/tyler1_xttsv2-February-07-2024_03+13PM-7e6c2b3\n",
      " ! Run is removed from /home/sagemaker-user/voiceclone/tyler1_xttsv2-February-07-2024_03+13PM-7e6c2b3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Filtering invalid eval samples!!\n",
      " > Total eval samples after filtering: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/trainer/trainer.py\", line 1833, in fit\n",
      "    self._fit()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/trainer/trainer.py\", line 1787, in _fit\n",
      "    self.eval_epoch()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/trainer/trainer.py\", line 1628, in eval_epoch\n",
      "    self.get_eval_dataloader(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/trainer/trainer.py\", line 990, in get_eval_dataloader\n",
      "    return self._get_loader(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/trainer/trainer.py\", line 914, in _get_loader\n",
      "    len(loader) > 0\n",
      "AssertionError:  ❗ len(DataLoader) returns 0. Make sure your dataset is not empty or len(dataset) > 0. \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trainer/trainer.py:1833\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1832\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1833\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trainer/trainer.py:1787\u001b[0m, in \u001b[0;36mTrainer._fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrun_eval:\n\u001b[0;32m-> 1787\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtest_delay_epochs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trainer/trainer.py:1628\u001b[0m, in \u001b[0;36mTrainer.eval_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_loader \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1628\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_eval_dataloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_assets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1633\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrun_eval\n\u001b[1;32m   1634\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1635\u001b[0m     )\n\u001b[1;32m   1637\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trainer/trainer.py:990\u001b[0m, in \u001b[0;36mTrainer.get_eval_dataloader\u001b[0;34m(self, training_assets, samples, verbose)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m loader\n\u001b[0;32m--> 990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_loader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_assets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trainer/trainer.py:914\u001b[0m, in \u001b[0;36mTrainer._get_loader\u001b[0;34m(self, model, config, assets, is_eval, samples, verbose, num_gpus)\u001b[0m\n\u001b[1;32m    909\u001b[0m         loader \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_data_loader(\n\u001b[1;32m    910\u001b[0m             config\u001b[38;5;241m=\u001b[39mconfig, assets\u001b[38;5;241m=\u001b[39massets, is_eval\u001b[38;5;241m=\u001b[39mis_eval, samples\u001b[38;5;241m=\u001b[39msamples, verbose\u001b[38;5;241m=\u001b[39mverbose, num_gpus\u001b[38;5;241m=\u001b[39mnum_gpus\n\u001b[1;32m    911\u001b[0m         )\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m--> 914\u001b[0m     \u001b[38;5;28mlen\u001b[39m(loader) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    915\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ❗ len(DataLoader) returns 0. Make sure your dataset is not empty or len(dataset) > 0. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loader\n",
      "\u001b[0;31mAssertionError\u001b[0m:  ❗ len(DataLoader) returns 0. Make sure your dataset is not empty or len(dataset) > 0. ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trainer/trainer.py:1862\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1861\u001b[0m traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n\u001b[0;32m-> 1862\u001b[0m \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2121\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   2119\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2120\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 2121\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2122\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2125\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 568\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py:1435\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[0;32m-> 1435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py:1326\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1323\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py:1173\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1166\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   1171\u001b[0m ):\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py:1063\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m   1061\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[1;32m   1062\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1063\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m   1064\u001b[0m )\n\u001b[1;32m   1066\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1067\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py:1131\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b94610e-09a9-4db2-89cd-924dcc1e2f22",
   "metadata": {},
   "source": [
    "##  Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21649c2a-0d88-446d-a6c4-c93abe354d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.api import TTS\n",
    "\n",
    "# using the default version set in 🐸TTS\n",
    "# tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\", gpu=True)\n",
    "\n",
    "# using a specific version\n",
    "# 👀 see the branch names for versions on https://huggingface.co/coqui/XTTS-v2/tree/main\n",
    "# ❗some versions might be incompatible with the API\n",
    "# tts = TTS(\"xtts_v2.0.2\", gpu=True)\n",
    "\n",
    "# getting the latest XTTS_v2\n",
    "tts = TTS(\"xtts\").to(\"cuda\")\n",
    "\n",
    "# tts = TTS(\"tts_models/en/ljspeech/vits\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383b70cf-ee8d-4c3e-9949-1af34c24ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import getoutput\n",
    "wavs = getoutput(\"ls data/wavs/*.wav\").split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030aba39-7110-4e27-b459-0bba4310665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate speech by cloning a voice using default settings\n",
    "tts.tts_to_file(text=\"It's Tyler 1 baby! Finally with the voice!\",\n",
    "                file_path=\"generated_audio/output.wav\",\n",
    "                speaker_wav=wavs,\n",
    "                language=\"en\"\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e3830a-8702-4a25-9f89-ecd86a1962af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(\"generated_audio/output.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
