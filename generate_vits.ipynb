{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2c7a00d-d94f-4d0b-ab48-df5f8977b19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook runs on TTS\n",
    "\n",
    "# !pip install TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b39bb760-943c-43df-afb2-502935e54d5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      " > tts_models/en/ljspeech/vits is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Text: This is the default text to speech model!!!\n",
      " > Text splitted to sentences.\n",
      "['This is the default text to speech model!!!']\n",
      " > Processing time: 0.2549149990081787\n",
      " > Real-time factor: 0.08815677114382592\n",
      " > Saving output to ./generated_audio/test.wav\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# We can run commands on the terminal\n",
    "# This cell generates an audio\n",
    "# It downloads the default model if you don't have it. Take note of where it is downloaded and copy the folder to somewhere more easily found\n",
    "\n",
    "# !tts --text \"This is the default text to speech model!!!\" --model_name \"tts_models/en/ljspeech/vits\" --out_path \"./generated_audio/test.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05d1cf47-7fd8-4004-9c7d-a3816a1f0b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: xtts\n",
      " > Text splitted to sentences.\n",
      "['Sup?', 'Sup?', \"It's Tyler 1 baby!\", 'Back with the voice']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'speakers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSup? Sup? It\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Tyler 1 baby! Back with the voice\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m synthesizer \u001b[38;5;241m=\u001b[39m Synthesizer(model_path, config_path, use_cuda \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 18\u001b[0m wav \u001b[38;5;241m=\u001b[39m \u001b[43msynthesizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m synthesizer\u001b[38;5;241m.\u001b[39msave_wav(wav, out_path)\n\u001b[1;32m     21\u001b[0m Audio(out_path)\n",
      "File \u001b[0;32m~/tts/TTS/TTS/utils/synthesizer.py:386\u001b[0m, in \u001b[0;36mSynthesizer.tts\u001b[0;34m(self, text, speaker_name, language_name, speaker_wav, style_wav, style_text, reference_wav, reference_speaker_name, split_sentences, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sen \u001b[38;5;129;01min\u001b[39;00m sens:\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msynthesize\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 386\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtts_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthesize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtts_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspeaker_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvoice_dirs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvoice_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m            \u001b[49m\u001b[43md_vector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspeaker_wav\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker_wav\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguage_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;66;03m# synthesize voice\u001b[39;00m\n\u001b[1;32m    398\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m synthesis(\n\u001b[1;32m    399\u001b[0m             model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts_model,\n\u001b[1;32m    400\u001b[0m             text\u001b[38;5;241m=\u001b[39msen,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    408\u001b[0m             language_id\u001b[38;5;241m=\u001b[39mlanguage_id,\n\u001b[1;32m    409\u001b[0m         )\n",
      "File \u001b[0;32m~/tts/TTS/TTS/tts/models/xtts.py:411\u001b[0m, in \u001b[0;36mXtts.synthesize\u001b[0;34m(self, text, config, speaker_wav, language, speaker_id, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m settings\u001b[38;5;241m.\u001b[39mupdate(kwargs)  \u001b[38;5;66;03m# allow overriding of preset settings with kwargs\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m speaker_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 411\u001b[0m     gpt_cond_latent, speaker_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspeaker_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspeakers\u001b[49m[speaker_id]\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(text, language, gpt_cond_latent, speaker_embedding, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings)\n\u001b[1;32m    413\u001b[0m settings\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt_cond_len\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mgpt_cond_len,\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt_cond_chunk_len\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mgpt_cond_chunk_len,\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_ref_len\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mmax_ref_len,\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msound_norm_refs\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39msound_norm_refs,\n\u001b[1;32m    418\u001b[0m })\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'speakers'"
     ]
    }
   ],
   "source": [
    "# This cell generates it programmatically\n",
    "# I've moved the pretrained model to the pretrained folder\n",
    "\n",
    "from TTS.utils.synthesizer import Synthesizer\n",
    "from IPython.display import Audio\n",
    "\n",
    "# model_path =  \"vitstts_checkpoint/vits_tyler1_noshouting_phonemes-January-30-2024_12+17PM-7e6c2b3/best_model_4981.pth\" # phonemes no shouting\n",
    "# config_path = \"vitstts_checkpoint/vits_tyler1_noshouting_phonemes-January-30-2024_12+17PM-7e6c2b3/config.json\" # phonemes no shouting\n",
    "out_path = \"generated_audio/test1.wav\"\n",
    "\n",
    "model_path = \"xttsv2_checkpoint/tyler1_xttsv2-February-19-2024_05+30AM-2b31060/\"\n",
    "config_path = \"xttsv2_checkpoint/tyler1_xttsv2-February-19-2024_05+30AM-2b31060/config.json\"\n",
    "\n",
    "text = \"Sup? Sup? It's Tyler 1 baby! Back with the voice\"\n",
    "\n",
    "synthesizer = Synthesizer(model_path, config_path, use_cuda = True)\n",
    "\n",
    "wav = synthesizer.tts(text\n",
    "synthesizer.save_wav(wav, out_path)\n",
    "\n",
    "Audio(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
