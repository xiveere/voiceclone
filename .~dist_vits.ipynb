{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f28fb199-18c3-40b6-a0e6-40085920b023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flush CUDA cache\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82b468c8-f92e-411b-83cd-35c9f20e05f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change continue_path in vits_tts.py to match --continue_path arg if needed\n",
    "# !CUDA_VISIBLE_DEVICES=\"0,1,2,3\"  python -m trainer.distribute --script vits_tts.py --continue_path \"vitstts_checkpoint/vits_tyler1_phonemes-February-29-2024_09+00AM-e526ca1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4587b9-c0bd-4ae6-a504-59f9ba1137fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vits_tts.py', '--continue_path=', '--restore_path=vitstts_checkpoint/tts_models--en--ljspeech--vits/model_file.pth', '--group_id=group_2024_03_01-073840', '--use_ddp=true', '--rank=0']\n",
      "['vits_tts.py', '--continue_path=', '--restore_path=vitstts_checkpoint/tts_models--en--ljspeech--vits/model_file.pth', '--group_id=group_2024_03_01-073840', '--use_ddp=true', '--rank=1']\n",
      "['vits_tts.py', '--continue_path=', '--restore_path=vitstts_checkpoint/tts_models--en--ljspeech--vits/model_file.pth', '--group_id=group_2024_03_01-073840', '--use_ddp=true', '--rank=2']\n",
      "['vits_tts.py', '--continue_path=', '--restore_path=vitstts_checkpoint/tts_models--en--ljspeech--vits/model_file.pth', '--group_id=group_2024_03_01-073840', '--use_ddp=true', '--rank=3']\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " | > Found 558 files in /home/sagemaker-user/dist/main/data\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " | > Found 558 files in /home/sagemaker-user/dist/main/data\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " | > Found 558 files in /home/sagemaker-user/dist/main/data\n",
      " | > Found 558 files in /home/sagemaker-user/dist/main/data\n",
      "[W socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:54321 (errno: 99 - Cannot assign requested address).\n",
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: True\n",
      " | > Precision: fp16\n",
      " | > Current device: 0\n",
      " | > Num. of GPUs: 4\n",
      " | > Num. of CPUs: 48\n",
      " | > Num. of Torch Threads: 24\n",
      " | > Torch seed: 54321\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      "[W socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:54321 (errno: 99 - Cannot assign requested address).\n",
      "[W socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:54321 (errno: 99 - Cannot assign requested address).\n",
      "2024-03-01 07:38:48.058838: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[W socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:54321 (errno: 99 - Cannot assign requested address).\n",
      "[W socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:54321 (errno: 99 - Cannot assign requested address).\n",
      "[W socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:54321 (errno: 99 - Cannot assign requested address).\n",
      "[W socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:54321 (errno: 99 - Cannot assign requested address).\n",
      " > Start Tensorboard: tensorboard --logdir=/home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      " > Using PyTorch DDP\n",
      " > Restoring from model_file.pth ...\n",
      " > Restoring Model...\n",
      " > Partial model initialization...\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.0.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.0.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.1.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.1.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.2.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.2.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.3.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.3.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.4.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.4.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.5.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.5.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.6.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.6.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.7.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.7.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.8.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.8.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.9.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.9.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.10.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.10.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.11.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.11.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.12.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.12.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.13.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.13.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.14.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.14.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.15.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.15.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.0.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.0.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.1.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.1.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.2.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.2.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.3.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.3.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.4.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.4.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.5.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.5.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.6.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.6.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.7.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.7.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.8.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.8.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.9.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.9.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.10.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.10.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.11.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.11.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.12.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.12.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.13.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.13.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.14.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.14.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.15.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.15.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.in_layers.0.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.in_layers.0.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.in_layers.1.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.in_layers.1.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.in_layers.2.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.in_layers.2.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.in_layers.3.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.in_layers.3.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.0.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.0.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.1.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.1.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.2.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.2.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.3.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.3.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.in_layers.0.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.in_layers.0.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.in_layers.1.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.in_layers.1.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.in_layers.2.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.in_layers.2.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.in_layers.3.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.in_layers.3.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.0.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.0.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.1.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.1.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.2.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.2.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.3.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.3.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.in_layers.0.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.in_layers.0.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.in_layers.1.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.in_layers.1.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.in_layers.2.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.in_layers.2.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.in_layers.3.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.in_layers.3.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.0.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.0.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.1.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.1.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.2.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.2.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.3.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.3.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.in_layers.0.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.in_layers.0.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.in_layers.1.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.in_layers.1.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.in_layers.2.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.in_layers.2.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.in_layers.3.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.in_layers.3.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.0.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.0.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.1.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.1.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.2.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.2.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.3.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.3.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.ups.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.ups.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.ups.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.ups.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.ups.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.ups.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.ups.3.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.ups.3.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs2.2.weight_v\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.4.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.4.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.5.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.5.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.6.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.6.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.7.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.7.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.8.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.8.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.9.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.9.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.10.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.10.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.11.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.11.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.12.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.12.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.13.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.13.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.14.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.14.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.15.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.15.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.4.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.4.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.5.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.5.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.6.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.6.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.7.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.7.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.8.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.8.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.9.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.9.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.10.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.10.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.11.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.11.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.12.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.12.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.13.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.13.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.14.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.14.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.15.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.15.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.ups.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.ups.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.ups.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.ups.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.ups.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.ups.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.ups.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.ups.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.0.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.1.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.2.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.3.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.4.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.4.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.4.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.5.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.5.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.5.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.0.conv_post.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.0.conv_post.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.0.conv_post.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.0.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.1.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.2.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.3.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.4.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.4.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.4.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.1.conv_post.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.1.conv_post.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.1.conv_post.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.0.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.1.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.2.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.3.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.4.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.4.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.4.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.2.conv_post.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.2.conv_post.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.2.conv_post.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.0.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.1.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.2.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.3.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.4.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.4.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.4.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.3.conv_post.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.3.conv_post.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.3.conv_post.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.0.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.1.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.2.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.3.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.4.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.4.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.4.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.4.conv_post.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.4.conv_post.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.4.conv_post.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.0.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.1.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.2.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.3.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.4.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.4.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.4.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.5.conv_post.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.5.conv_post.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.5.conv_post.parametrizations.weight.original1\n",
      " | > Layer dimention missmatch between model definition and checkpoint: text_encoder.emb.weight\n",
      " | > 557 / 949 layers are restored.\n",
      " > Model restored from step 1000000\n",
      "\n",
      " > Model has 83059180 parameters\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\n",
      "\n",
      "\t| > use_phonemes: True\n",
      "\n",
      "\n",
      "> DataLoader initialization> DataLoader initialization\t| > phonemizer:\n",
      "\n",
      "\n",
      "| > Tokenizer:| > Tokenizer:\n",
      "\n",
      "\t\t| > phoneme language: en-us\t| > add_blank: True\n",
      "\n",
      "\t| > add_blank: True\t| > use_eos_bos: False\t\t| > phoneme backend: espeak\n",
      "\n",
      "\n",
      "\t| > use_phonemes: True\t| > use_eos_bos: False\n",
      "| > Number of instances : 503\n",
      "\t| > phonemizer:\n",
      "\t| > use_phonemes: True\n",
      "\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\t\t| > phoneme language: en-us\n",
      "\n",
      "\t\t| > phoneme backend: espeak\t\t| > phoneme backend: espeak\n",
      "\n",
      "| > Number of instances : 503| > Number of instances : 503\n",
      "\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: espeak\n",
      "| > Number of instances : 503\n",
      " | > Preprocessing samples | > Preprocessing samples\n",
      "\n",
      " | > Max text length: 400 | > Max text length: 400\n",
      "\n",
      " | > Min text length: 26 | > Min text length: 26\n",
      "\n",
      " | > Preprocessing samples\n",
      " | > Avg text length: 178.0854870775348 | > Avg text length: 178.0854870775348\n",
      "\n",
      " |  | \n",
      "\n",
      " | > Max text length: 400\n",
      " | > Max audio length: 606879 | > Max audio length: 606879\n",
      "\n",
      " | > Min audio length: 72765 | > Min audio length: 72765 | > Min text length: 26\n",
      "\n",
      "\n",
      " | > Avg audio length: 206187.1829025845 | > Avg audio length: 206187.1829025845\n",
      "\n",
      " | > Num. instances discarded samples: 0 | > Num. instances discarded samples: 0\n",
      "\n",
      " | > Batch group size: 0. | > Batch group size: 0.\n",
      "\n",
      " | > Avg text length: 178.0854870775348\n",
      " | \n",
      " | > Max audio length: 606879\n",
      " | > Min audio length: 72765\n",
      " | > Avg audio length: 206187.1829025845\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 400\n",
      " | > Min text length: 26\n",
      " | > Avg text length: 178.0854870775348\n",
      " | \n",
      " | > Max audio length: 606879\n",
      " | > Min audio length: 72765\n",
      " | > Avg audio length: 206187.1829025845\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:38:52) \u001b[0m\n",
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:660: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:874.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:660: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:874.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:660: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:874.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:660: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:874.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:39:06 -- STEP: 24/32 -- GLOBAL_STEP: 1000025\u001b[0m\n",
      "     | > loss_disc: 3.0187196731567383  (3.4308770298957825)\n",
      "     | > loss_disc_real_0: 0.27963292598724365  (0.33689315896481276)\n",
      "     | > loss_disc_real_1: 0.22012177109718323  (0.3454773100093007)\n",
      "     | > loss_disc_real_2: 0.24871718883514404  (0.34778113042314845)\n",
      "     | > loss_disc_real_3: 0.21944139897823334  (0.35164113777379197)\n",
      "     | > loss_disc_real_4: 0.23728272318840027  (0.3746634215737383)\n",
      "     | > loss_disc_real_5: 0.21140600740909576  (0.3661355885366599)\n",
      "     | > loss_0: 3.0187196731567383  (3.4308770298957825)\n",
      "     | > grad_norm_0: tensor(1.4548, device='cuda:0')  (tensor(2.4630, device='cuda:0'))\n",
      "     | > loss_gen: 1.656968593597412  (1.9772588908672333)\n",
      "     | > loss_kl: 5.8259100914001465  (12.981624027093254)\n",
      "     | > loss_feat: 1.1817665100097656  (0.6226706200589737)\n",
      "     | > loss_mel: 23.974361419677734  (24.815733273824055)\n",
      "     | > loss_duration: 0.836958646774292  (3.4617550149559975)\n",
      "     | > amp_scaler: 512.0  (1728.0)\n",
      "     | > loss_1: 33.47596740722656  (43.859041929244995)\n",
      "     | > grad_norm_1: tensor(213.7095, device='cuda:0')  (tensor(199.4677, device='cuda:0'))\n",
      "     | > current_lr_0: 0.0002 \n",
      "     | > current_lr_1: 0.0002 \n",
      "     | > step_time: 0.3881  (0.46228774388631183)\n",
      "     | > loader_time: 0.0028  (0.0037464300791422525)\n",
      "\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: espeak\n",
      "| > Number of instances : 55\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: espeak\n",
      "| > Number of instances : 55\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: espeak\n",
      "| > Number of instances : 55\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: espeak\n",
      "| > Number of instances : 55\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 397\n",
      " | > Min text length: 72\n",
      " | > Avg text length: 170.8909090909091\n",
      " |  | > Preprocessing samples\n",
      "\n",
      " | > Max audio length: 447245\n",
      " | > Min audio length: 115395\n",
      " | > Preprocessing samples | > Max text length: 397\n",
      "\n",
      " | > Preprocessing samples | > Avg audio length: 190971.58181818182 | > Min text length: 72\n",
      "\n",
      "\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      " | > Max text length: 397\n",
      " | > Max text length: 397 | > Min text length: 72\n",
      "\n",
      " | > Avg text length: 170.8909090909091\n",
      " | \n",
      " | > Min text length: 72 | > Max audio length: 447245\n",
      "\n",
      " | > Min audio length: 115395\n",
      " | > Avg text length: 170.8909090909091\n",
      " | \n",
      " | > Max audio length: 447245 | > Avg audio length: 190971.58181818182 | > Avg text length: 170.8909090909091\n",
      "\n",
      "\n",
      " | > Num. instances discarded samples: 0 | \n",
      "\n",
      " | > Batch group size: 0. | > Min audio length: 115395\n",
      "\n",
      " | > Max audio length: 447245 | > Avg audio length: 190971.58181818182\n",
      "\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      " | > Min audio length: 115395\n",
      " | > Avg audio length: 190971.58181818182\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "so a wz ktuli, so hi t t old, so hi wz ktuli dd t ll dmd.  kezi pt z hi fmd bat tu aznd v t  t  vi nd v em. jh. hi lli wznt ple. a hv no adi wa. ma btlen ktuli tuvid nd hi hd  wn tp len.  js, mdlen wz dt, bt wi hd wn kndnz.\n",
      " [!] Character '' not found in the vocabulary. Discarding it.\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 3.044276714324951  (3.044276714324951)\n",
      "     | > loss_disc_real_0: 0.25449055433273315  (0.25449055433273315)\n",
      "     | > loss_disc_real_1: 0.21323829889297485  (0.21323829889297485)\n",
      "     | > loss_disc_real_2: 0.2276454120874405  (0.2276454120874405)\n",
      "     | > loss_disc_real_3: 0.21287348866462708  (0.21287348866462708)\n",
      "     | > loss_disc_real_4: 0.21392902731895447  (0.21392902731895447)\n",
      "     | > loss_disc_real_5: 0.16915225982666016  (0.16915225982666016)\n",
      "     | > loss_0: 3.044276714324951  (3.044276714324951)\n",
      "     | > loss_gen: 1.3143295049667358  (1.3143295049667358)\n",
      "     | > loss_kl: 5.614052772521973  (5.614052772521973)\n",
      "     | > loss_feat: 0.6975724101066589  (0.6975724101066589)\n",
      "     | > loss_mel: 23.010780334472656  (23.010780334472656)\n",
      "     | > loss_duration: 1.2800872325897217  (1.2800872325897217)\n",
      "     | > loss_1: 31.916820526123047  (31.916820526123047)\n",
      "\n",
      "hi kld hm. hi wz dd nwe, bkz f a, f a wznt , hi wz da dls.\n",
      " [!] Character '' not found in the vocabulary. Discarding it.\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 3.02241849899292  (3.02241849899292)\n",
      "     | > loss_disc_real_0: 0.255789190530777  (0.255789190530777)\n",
      "     | > loss_disc_real_1: 0.21919775009155273  (0.21919775009155273)\n",
      "     | > loss_disc_real_2: 0.23037667572498322  (0.23037667572498322)\n",
      "     | > loss_disc_real_3: 0.21502481400966644  (0.21502481400966644)\n",
      "     | > loss_disc_real_4: 0.21585866808891296  (0.21585866808891296)\n",
      "     | > loss_disc_real_5: 0.18040530383586884  (0.18040530383586884)\n",
      "     | > loss_0: 3.02241849899292  (3.02241849899292)\n",
      "     | > loss_gen: 1.3486888408660889  (1.3486888408660889)\n",
      "     | > loss_kl: 7.1741533279418945  (7.1741533279418945)\n",
      "     | > loss_feat: 0.5357404351234436  (0.5357404351234436)\n",
      "     | > loss_mel: 30.643774032592773  (30.643774032592773)\n",
      "     | > loss_duration: 1.1663860082626343  (1.1663860082626343)\n",
      "     | > loss_1: 40.868743896484375  (40.868743896484375)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 3.0503735542297363  (3.036396026611328)\n",
      "     | > loss_disc_real_0: 0.25530123710632324  (0.2555452138185501)\n",
      "     | > loss_disc_real_1: 0.21688628196716309  (0.2180420160293579)\n",
      "     | > loss_disc_real_2: 0.22985535860061646  (0.23011601716279984)\n",
      "     | > loss_disc_real_3: 0.21516084671020508  (0.21509283035993576)\n",
      "     | > loss_disc_real_4: 0.21683600544929504  (0.216347336769104)\n",
      "     | > loss_disc_real_5: 0.17795133590698242  (0.17917831987142563)\n",
      "     | > loss_0: 3.0503735542297363  (3.036396026611328)\n",
      "     | > loss_gen: 1.3292125463485718  (1.3389506936073303)\n",
      "     | > loss_kl: 5.084502696990967  (6.129328012466431)\n",
      "     | > loss_feat: 0.4043891727924347  (0.47006480395793915)\n",
      "     | > loss_mel: 21.995895385742188  (26.31983470916748)\n",
      "     | > loss_duration: 1.4402456283569336  (1.303315818309784)\n",
      "     | > loss_1: 30.25424575805664  (35.56149482727051)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 3.032165050506592  (3.0349857012430825)\n",
      "     | > loss_disc_real_0: 0.24833132326602936  (0.2531405836343765)\n",
      "     | > loss_disc_real_1: 0.1837085336446762  (0.20659752190113068)\n",
      "     | > loss_disc_real_2: 0.1993688941001892  (0.21986697614192963)\n",
      "     | > loss_disc_real_3: 0.1789192259311676  (0.20303496221701303)\n",
      "     | > loss_disc_real_4: 0.17056381702423096  (0.201086163520813)\n",
      "     | > loss_disc_real_5: 0.1324714720249176  (0.1636093705892563)\n",
      "     | > loss_0: 3.032165050506592  (3.0349857012430825)\n",
      "     | > loss_gen: 1.196753740310669  (1.2915517091751099)\n",
      "     | > loss_kl: 5.825119972229004  (6.027925332387288)\n",
      "     | > loss_feat: 1.2556519508361816  (0.7319271862506866)\n",
      "     | > loss_mel: 24.108379364013672  (25.582682927449543)\n",
      "     | > loss_duration: 0.8117091059684753  (1.1394469141960144)\n",
      "     | > loss_1: 33.19761657714844  (34.77353541056315)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 3.0210022926330566  (3.031489849090576)\n",
      "     | > loss_disc_real_0: 0.2537226378917694  (0.25328609719872475)\n",
      "     | > loss_disc_real_1: 0.20601814985275269  (0.20645267888903618)\n",
      "     | > loss_disc_real_2: 0.2216888815164566  (0.22032245248556137)\n",
      "     | > loss_disc_real_3: 0.20429928600788116  (0.20335104316473007)\n",
      "     | > loss_disc_real_4: 0.20430795848369598  (0.20189161226153374)\n",
      "     | > loss_disc_real_5: 0.16414965689182281  (0.16374444216489792)\n",
      "     | > loss_0: 3.0210022926330566  (3.031489849090576)\n",
      "     | > loss_gen: 1.3039346933364868  (1.294647455215454)\n",
      "     | > loss_kl: 6.140231132507324  (6.056001782417297)\n",
      "     | > loss_feat: 0.7352138757705688  (0.7327488586306572)\n",
      "     | > loss_mel: 22.391494750976562  (24.7848858833313)\n",
      "     | > loss_duration: 1.0056824684143066  (1.1060058027505875)\n",
      "     | > loss_1: 31.576555252075195  (33.97429037094116)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 3.059900999069214  (3.0371720790863037)\n",
      "     | > loss_disc_real_0: 0.2487555891275406  (0.2523799955844879)\n",
      "     | > loss_disc_real_1: 0.18621285259723663  (0.20240471363067628)\n",
      "     | > loss_disc_real_2: 0.20206955075263977  (0.21667187213897704)\n",
      "     | > loss_disc_real_3: 0.1825876086950302  (0.1991983562707901)\n",
      "     | > loss_disc_real_4: 0.17738379538059235  (0.19699004888534546)\n",
      "     | > loss_disc_real_5: 0.1331881582736969  (0.15763318538665771)\n",
      "     | > loss_0: 3.059900999069214  (3.0371720790863037)\n",
      "     | > loss_gen: 1.1879125833511353  (1.2733004808425903)\n",
      "     | > loss_kl: 4.909700393676758  (5.826741504669189)\n",
      "     | > loss_feat: 1.136431097984314  (0.8134853065013885)\n",
      "     | > loss_mel: 23.22458839416504  (24.472826385498045)\n",
      "     | > loss_duration: 1.228395700454712  (1.1304837822914124)\n",
      "     | > loss_1: 31.687026977539062  (33.516837692260744)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 2.985161304473877  (3.0285036166508994)\n",
      "     | > loss_disc_real_0: 0.24468401074409485  (0.2510973314444224)\n",
      "     | > loss_disc_real_1: 0.16530129313468933  (0.19622081021467844)\n",
      "     | > loss_disc_real_2: 0.1808946579694748  (0.21070900311072668)\n",
      "     | > loss_disc_real_3: 0.16109919548034668  (0.19284849613904953)\n",
      "     | > loss_disc_real_4: 0.1490204930305481  (0.1889951229095459)\n",
      "     | > loss_disc_real_5: 0.10382258892059326  (0.14866475264231363)\n",
      "     | > loss_0: 2.985161304473877  (3.0285036166508994)\n",
      "     | > loss_gen: 1.1527189016342163  (1.253203550974528)\n",
      "     | > loss_kl: 5.509315490722656  (5.773837169011434)\n",
      "     | > loss_feat: 1.7788665294647217  (0.9743821769952774)\n",
      "     | > loss_mel: 26.444908142089844  (24.801506678263348)\n",
      "     | > loss_duration: 1.036780834197998  (1.1148666242758434)\n",
      "     | > loss_1: 35.92258834838867  (33.91779613494873)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "/home/sagemaker-user/TTS/TTS/tts/models/vits.py:1455: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  test_figures[\"{}-alignment\".format(idx)] = plot_alignment(alignment.T, output_fig=False)\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time: 0.0026081005732218423 \u001b[0m(+0)\n",
      "     | > avg_loss_disc: 3.0285036166508994 \u001b[0m(+0)\n",
      "     | > avg_loss_disc_real_0: 0.2510973314444224 \u001b[0m(+0)\n",
      "     | > avg_loss_disc_real_1: 0.19622081021467844 \u001b[0m(+0)\n",
      "     | > avg_loss_disc_real_2: 0.21070900311072668 \u001b[0m(+0)\n",
      "     | > avg_loss_disc_real_3: 0.19284849613904953 \u001b[0m(+0)\n",
      "     | > avg_loss_disc_real_4: 0.1889951229095459 \u001b[0m(+0)\n",
      "     | > avg_loss_disc_real_5: 0.14866475264231363 \u001b[0m(+0)\n",
      "     | > avg_loss_0: 3.0285036166508994 \u001b[0m(+0)\n",
      "     | > avg_loss_gen: 1.253203550974528 \u001b[0m(+0)\n",
      "     | > avg_loss_kl: 5.773837169011434 \u001b[0m(+0)\n",
      "     | > avg_loss_feat: 0.9743821769952774 \u001b[0m(+0)\n",
      "     | > avg_loss_mel: 24.801506678263348 \u001b[0m(+0)\n",
      "     | > avg_loss_duration: 1.1148666242758434 \u001b[0m(+0)\n",
      "     | > avg_loss_1: 33.91779613494873 \u001b[0m(+0)\n",
      "\n",
      " > BEST MODEL : /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1/best_model_1000033.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 1/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:39:16) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:39:24 -- STEP: 17/32 -- GLOBAL_STEP: 1000050\u001b[0m\n",
      "     | > loss_disc: 2.8677048683166504  (2.979074015336878)\n",
      "     | > loss_disc_real_0: 0.23235924541950226  (0.2506859022028306)\n",
      "     | > loss_disc_real_1: 0.19216720759868622  (0.25798408599460826)\n",
      "     | > loss_disc_real_2: 0.20806927978992462  (0.2588070438188665)\n",
      "     | > loss_disc_real_3: 0.18293210864067078  (0.2601036061258877)\n",
      "     | > loss_disc_real_4: 0.19206108152866364  (0.2596072317922817)\n",
      "     | > loss_disc_real_5: 0.1835060566663742  (0.259416161214604)\n",
      "     | > loss_0: 2.8677048683166504  (2.979074015336878)\n",
      "     | > grad_norm_0: tensor(1.7556, device='cuda:0')  (tensor(1.3138, device='cuda:0'))\n",
      "     | > loss_gen: 1.3815150260925293  (1.6030570829615873)\n",
      "     | > loss_kl: 4.933537006378174  (5.363025973824894)\n",
      "     | > loss_feat: 1.2717946767807007  (0.8265933482085958)\n",
      "     | > loss_mel: 23.520647048950195  (24.306531008552103)\n",
      "     | > loss_duration: 1.45330011844635  (3.3060932019177605)\n",
      "     | > amp_scaler: 256.0  (316.2352941176471)\n",
      "     | > loss_1: 32.560794830322266  (35.40530115015367)\n",
      "     | > grad_norm_1: tensor(202.1695, device='cuda:0')  (tensor(253.1747, device='cuda:0'))\n",
      "     | > current_lr_0: 0.000199975 \n",
      "     | > current_lr_1: 0.000199975 \n",
      "     | > step_time: 0.367  (0.371138053781846)\n",
      "     | > loader_time: 0.0033  (0.003455975476433249)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.9944801330566406  (2.9944801330566406)\n",
      "     | > loss_disc_real_0: 0.202688068151474  (0.202688068151474)\n",
      "     | > loss_disc_real_1: 0.2745203971862793  (0.2745203971862793)\n",
      "     | > loss_disc_real_2: 0.2848358154296875  (0.2848358154296875)\n",
      "     | > loss_disc_real_3: 0.28583621978759766  (0.28583621978759766)\n",
      "     | > loss_disc_real_4: 0.2535483241081238  (0.2535483241081238)\n",
      "     | > loss_disc_real_5: 0.24026411771774292  (0.24026411771774292)\n",
      "     | > loss_0: 2.9944801330566406  (2.9944801330566406)\n",
      "     | > loss_gen: 1.5699691772460938  (1.5699691772460938)\n",
      "     | > loss_kl: 4.786034107208252  (4.786034107208252)\n",
      "     | > loss_feat: 0.7218202352523804  (0.7218202352523804)\n",
      "     | > loss_mel: 23.845983505249023  (23.845983505249023)\n",
      "     | > loss_duration: 1.4161252975463867  (1.4161252975463867)\n",
      "     | > loss_1: 32.33993148803711  (32.33993148803711)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.9449563026428223  (2.9449563026428223)\n",
      "     | > loss_disc_real_0: 0.18340782821178436  (0.18340782821178436)\n",
      "     | > loss_disc_real_1: 0.2759050130844116  (0.2759050130844116)\n",
      "     | > loss_disc_real_2: 0.2821822762489319  (0.2821822762489319)\n",
      "     | > loss_disc_real_3: 0.2850534915924072  (0.2850534915924072)\n",
      "     | > loss_disc_real_4: 0.2529771029949188  (0.2529771029949188)\n",
      "     | > loss_disc_real_5: 0.2355494201183319  (0.2355494201183319)\n",
      "     | > loss_0: 2.9449563026428223  (2.9449563026428223)\n",
      "     | > loss_gen: 1.5918747186660767  (1.5918747186660767)\n",
      "     | > loss_kl: 5.86736536026001  (5.86736536026001)\n",
      "     | > loss_feat: 0.8801179528236389  (0.8801179528236389)\n",
      "     | > loss_mel: 41.03133773803711  (41.03133773803711)\n",
      "     | > loss_duration: 1.2973079681396484  (1.2973079681396484)\n",
      "     | > loss_1: 50.667999267578125  (50.667999267578125)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 3.0149383544921875  (2.979947328567505)\n",
      "     | > loss_disc_real_0: 0.21727845072746277  (0.20034313946962357)\n",
      "     | > loss_disc_real_1: 0.28090739250183105  (0.27840620279312134)\n",
      "     | > loss_disc_real_2: 0.2979668974876404  (0.29007458686828613)\n",
      "     | > loss_disc_real_3: 0.295072466135025  (0.2900629788637161)\n",
      "     | > loss_disc_real_4: 0.26485586166381836  (0.2589164823293686)\n",
      "     | > loss_disc_real_5: 0.2497950941324234  (0.24267225712537766)\n",
      "     | > loss_0: 3.0149383544921875  (2.979947328567505)\n",
      "     | > loss_gen: 1.611722707748413  (1.6017987132072449)\n",
      "     | > loss_kl: 3.9857394695281982  (4.926552414894104)\n",
      "     | > loss_feat: 0.3039797246456146  (0.5920488387346268)\n",
      "     | > loss_mel: 20.581701278686523  (30.806519508361816)\n",
      "     | > loss_duration: 1.5827730894088745  (1.4400405287742615)\n",
      "     | > loss_1: 28.065916061401367  (39.366957664489746)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 2.9929237365722656  (2.9842727979024253)\n",
      "     | > loss_disc_real_0: 0.2151174247264862  (0.2052679012219111)\n",
      "     | > loss_disc_real_1: 0.273794025182724  (0.2768688102563222)\n",
      "     | > loss_disc_real_2: 0.2935962677001953  (0.29124848047892254)\n",
      "     | > loss_disc_real_3: 0.2917022109031677  (0.2906093895435333)\n",
      "     | > loss_disc_real_4: 0.26150742173194885  (0.2597801287968953)\n",
      "     | > loss_disc_real_5: 0.23868833482265472  (0.24134428302447)\n",
      "     | > loss_0: 2.9929237365722656  (2.9842727979024253)\n",
      "     | > loss_gen: 1.6004197597503662  (1.601339062054952)\n",
      "     | > loss_kl: 5.599498271942139  (5.150867700576782)\n",
      "     | > loss_feat: 0.37697434425354004  (0.5203573405742645)\n",
      "     | > loss_mel: 23.196041107177734  (28.26969337463379)\n",
      "     | > loss_duration: 0.9549682140350342  (1.278349757194519)\n",
      "     | > loss_1: 31.727901458740234  (36.82060559590658)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 3.0247256755828857  (2.9943860173225403)\n",
      "     | > loss_disc_real_0: 0.21271982789039612  (0.20713088288903236)\n",
      "     | > loss_disc_real_1: 0.28189799189567566  (0.2781261056661606)\n",
      "     | > loss_disc_real_2: 0.295494943857193  (0.29231009632349014)\n",
      "     | > loss_disc_real_3: 0.2934161424636841  (0.291311077773571)\n",
      "     | > loss_disc_real_4: 0.2641741931438446  (0.26087864488363266)\n",
      "     | > loss_disc_real_5: 0.24281497299671173  (0.24171195551753044)\n",
      "     | > loss_0: 3.0247256755828857  (2.9943860173225403)\n",
      "     | > loss_gen: 1.5889818668365479  (1.598249763250351)\n",
      "     | > loss_kl: 4.656607151031494  (5.02730256319046)\n",
      "     | > loss_feat: 0.5507495999336243  (0.5279554054141045)\n",
      "     | > loss_mel: 21.142446517944336  (26.487881660461426)\n",
      "     | > loss_duration: 1.137006163597107  (1.243013858795166)\n",
      "     | > loss_1: 29.07579231262207  (34.88440227508545)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 2.985424041748047  (2.9925936222076417)\n",
      "     | > loss_disc_real_0: 0.2143874168395996  (0.20858218967914582)\n",
      "     | > loss_disc_real_1: 0.2776387929916382  (0.2780286431312561)\n",
      "     | > loss_disc_real_2: 0.29485100507736206  (0.2928182780742645)\n",
      "     | > loss_disc_real_3: 0.29332324862480164  (0.2917135119438171)\n",
      "     | > loss_disc_real_4: 0.26186999678611755  (0.2610769152641296)\n",
      "     | > loss_disc_real_5: 0.24593348801136017  (0.24255626201629638)\n",
      "     | > loss_0: 2.985424041748047  (2.9925936222076417)\n",
      "     | > loss_gen: 1.6219761371612549  (1.6029950380325317)\n",
      "     | > loss_kl: 4.798611164093018  (4.981564283370972)\n",
      "     | > loss_feat: 0.35238897800445557  (0.4928421199321747)\n",
      "     | > loss_mel: 23.358009338378906  (25.86190719604492)\n",
      "     | > loss_duration: 1.4110468626022339  (1.2766204595565795)\n",
      "     | > loss_1: 31.542034149169922  (34.215928649902345)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 3.0120527744293213  (2.9958368142445884)\n",
      "     | > loss_disc_real_0: 0.22474469244480133  (0.2112759401400884)\n",
      "     | > loss_disc_real_1: 0.2821527123451233  (0.27871598800023395)\n",
      "     | > loss_disc_real_2: 0.30070582032203674  (0.29413286844889325)\n",
      "     | > loss_disc_real_3: 0.2988668978214264  (0.2929057429234187)\n",
      "     | > loss_disc_real_4: 0.2684995234012604  (0.2623140166203181)\n",
      "     | > loss_disc_real_5: 0.2530919909477234  (0.2443122168382009)\n",
      "     | > loss_0: 3.0120527744293213  (2.9958368142445884)\n",
      "     | > loss_gen: 1.6348810195922852  (1.6083093682924907)\n",
      "     | > loss_kl: 4.346102714538574  (4.875654021898906)\n",
      "     | > loss_feat: 0.17048099637031555  (0.4391152660051982)\n",
      "     | > loss_mel: 23.410675048828125  (25.45336850484212)\n",
      "     | > loss_duration: 1.175898790359497  (1.2598335146903992)\n",
      "     | > loss_1: 30.738040924072266  (33.63628069559733)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0025005340576171875 \u001b[0m(-0.0001075665156046548)\n",
      "     | > avg_loss_disc:\u001b[92m 2.9958368142445884 \u001b[0m(-0.032666802406311035)\n",
      "     | > avg_loss_disc_real_0:\u001b[92m 0.2112759401400884 \u001b[0m(-0.039821391304334014)\n",
      "     | > avg_loss_disc_real_1:\u001b[91m 0.27871598800023395 \u001b[0m(+0.08249517778555551)\n",
      "     | > avg_loss_disc_real_2:\u001b[91m 0.29413286844889325 \u001b[0m(+0.08342386533816656)\n",
      "     | > avg_loss_disc_real_3:\u001b[91m 0.2929057429234187 \u001b[0m(+0.10005724678436917)\n",
      "     | > avg_loss_disc_real_4:\u001b[91m 0.2623140166203181 \u001b[0m(+0.07331889371077221)\n",
      "     | > avg_loss_disc_real_5:\u001b[91m 0.2443122168382009 \u001b[0m(+0.09564746419588727)\n",
      "     | > avg_loss_0:\u001b[92m 2.9958368142445884 \u001b[0m(-0.032666802406311035)\n",
      "     | > avg_loss_gen:\u001b[91m 1.6083093682924907 \u001b[0m(+0.35510581731796265)\n",
      "     | > avg_loss_kl:\u001b[92m 4.875654021898906 \u001b[0m(-0.8981831471125279)\n",
      "     | > avg_loss_feat:\u001b[92m 0.4391152660051982 \u001b[0m(-0.5352669109900792)\n",
      "     | > avg_loss_mel:\u001b[91m 25.45336850484212 \u001b[0m(+0.6518618265787737)\n",
      "     | > avg_loss_duration:\u001b[91m 1.2598335146903992 \u001b[0m(+0.1449668904145558)\n",
      "     | > avg_loss_1:\u001b[92m 33.63628069559733 \u001b[0m(-0.2815154393514021)\n",
      "\n",
      " > BEST MODEL : /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1/best_model_1000065.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 2/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:39:35) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:39:39 -- STEP: 10/32 -- GLOBAL_STEP: 1000075\u001b[0m\n",
      "     | > loss_disc: 3.031365394592285  (2.9496742486953735)\n",
      "     | > loss_disc_real_0: 0.31021255254745483  (0.25385855585336686)\n",
      "     | > loss_disc_real_1: 0.26809635758399963  (0.25569315552711486)\n",
      "     | > loss_disc_real_2: 0.26779916882514954  (0.2513489663600922)\n",
      "     | > loss_disc_real_3: 0.26816093921661377  (0.24888477325439454)\n",
      "     | > loss_disc_real_4: 0.2872309982776642  (0.26182751506567004)\n",
      "     | > loss_disc_real_5: 0.2963058352470398  (0.26319791823625566)\n",
      "     | > loss_0: 3.031365394592285  (2.9496742486953735)\n",
      "     | > grad_norm_0: tensor(1.1379, device='cuda:0')  (tensor(1.4302, device='cuda:0'))\n",
      "     | > loss_gen: 1.4787211418151855  (1.5960845589637755)\n",
      "     | > loss_kl: 4.069777965545654  (4.761947441101074)\n",
      "     | > loss_feat: 0.41939249634742737  (0.8120949149131775)\n",
      "     | > loss_mel: 22.018117904663086  (23.188201713562012)\n",
      "     | > loss_duration: 1.3890557289123535  (4.452674698829651)\n",
      "     | > amp_scaler: 256.0  (256.0)\n",
      "     | > loss_1: 29.375064849853516  (34.81100292205811)\n",
      "     | > grad_norm_1: tensor(115.7579, device='cuda:0')  (tensor(164.0002, device='cuda:0'))\n",
      "     | > current_lr_0: 0.000199950003125 \n",
      "     | > current_lr_1: 0.000199950003125 \n",
      "     | > step_time: 0.3666  (0.3745719432830811)\n",
      "     | > loader_time: 0.003  (0.003545188903808594)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.95879864692688  (2.95879864692688)\n",
      "     | > loss_disc_real_0: 0.28076672554016113  (0.28076672554016113)\n",
      "     | > loss_disc_real_1: 0.23914861679077148  (0.23914861679077148)\n",
      "     | > loss_disc_real_2: 0.21677470207214355  (0.21677470207214355)\n",
      "     | > loss_disc_real_3: 0.24079017341136932  (0.24079017341136932)\n",
      "     | > loss_disc_real_4: 0.23634931445121765  (0.23634931445121765)\n",
      "     | > loss_disc_real_5: 0.267622709274292  (0.267622709274292)\n",
      "     | > loss_0: 2.95879864692688  (2.95879864692688)\n",
      "     | > loss_gen: 1.53231680393219  (1.53231680393219)\n",
      "     | > loss_kl: 4.323696136474609  (4.323696136474609)\n",
      "     | > loss_feat: 0.4463096857070923  (0.4463096857070923)\n",
      "     | > loss_mel: 24.03934669494629  (24.03934669494629)\n",
      "     | > loss_duration: 1.4337419271469116  (1.4337419271469116)\n",
      "     | > loss_1: 31.77541160583496  (31.77541160583496)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.891322135925293  (2.891322135925293)\n",
      "     | > loss_disc_real_0: 0.24754703044891357  (0.24754703044891357)\n",
      "     | > loss_disc_real_1: 0.23200786113739014  (0.23200786113739014)\n",
      "     | > loss_disc_real_2: 0.19149616360664368  (0.19149616360664368)\n",
      "     | > loss_disc_real_3: 0.21214637160301208  (0.21214637160301208)\n",
      "     | > loss_disc_real_4: 0.20938259363174438  (0.20938259363174438)\n",
      "     | > loss_disc_real_5: 0.22119130194187164  (0.22119130194187164)\n",
      "     | > loss_0: 2.891322135925293  (2.891322135925293)\n",
      "     | > loss_gen: 1.4364540576934814  (1.4364540576934814)\n",
      "     | > loss_kl: 5.418540954589844  (5.418540954589844)\n",
      "     | > loss_feat: 1.0922260284423828  (1.0922260284423828)\n",
      "     | > loss_mel: 29.160480499267578  (29.160480499267578)\n",
      "     | > loss_duration: 1.3412694931030273  (1.3412694931030273)\n",
      "     | > loss_1: 38.448974609375  (38.448974609375)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 2.9223647117614746  (2.906843423843384)\n",
      "     | > loss_disc_real_0: 0.22149120271205902  (0.2345191165804863)\n",
      "     | > loss_disc_real_1: 0.21304304897785187  (0.222525455057621)\n",
      "     | > loss_disc_real_2: 0.18058714270591736  (0.18604165315628052)\n",
      "     | > loss_disc_real_3: 0.19715918600559235  (0.20465277880430222)\n",
      "     | > loss_disc_real_4: 0.1863640695810318  (0.1978733316063881)\n",
      "     | > loss_disc_real_5: 0.20191292464733124  (0.21155211329460144)\n",
      "     | > loss_0: 2.9223647117614746  (2.906843423843384)\n",
      "     | > loss_gen: 1.3428800106048584  (1.38966703414917)\n",
      "     | > loss_kl: 3.858241081237793  (4.638391017913818)\n",
      "     | > loss_feat: 1.3088324069976807  (1.2005292177200317)\n",
      "     | > loss_mel: 25.746854782104492  (27.453667640686035)\n",
      "     | > loss_duration: 1.7000089883804321  (1.5206392407417297)\n",
      "     | > loss_1: 33.956817626953125  (36.20289611816406)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 2.907383918762207  (2.9070235888163247)\n",
      "     | > loss_disc_real_0: 0.21654021739959717  (0.2285261501868566)\n",
      "     | > loss_disc_real_1: 0.19207565486431122  (0.21237552165985107)\n",
      "     | > loss_disc_real_2: 0.17353005707263947  (0.18187112112840018)\n",
      "     | > loss_disc_real_3: 0.19641201198101044  (0.2019058565298716)\n",
      "     | > loss_disc_real_4: 0.1772458851337433  (0.1909975161155065)\n",
      "     | > loss_disc_real_5: 0.17477957904338837  (0.19929460187753043)\n",
      "     | > loss_0: 2.907383918762207  (2.9070235888163247)\n",
      "     | > loss_gen: 1.2898907661437988  (1.3564082781473796)\n",
      "     | > loss_kl: 4.519428730010986  (4.598736921946208)\n",
      "     | > loss_feat: 1.5469170808792114  (1.3159918387730916)\n",
      "     | > loss_mel: 26.37386131286621  (27.093732198079426)\n",
      "     | > loss_duration: 0.9482707381248474  (1.3298497398694356)\n",
      "     | > loss_1: 34.678367614746094  (35.69471995035807)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 2.8924288749694824  (2.9033749103546143)\n",
      "     | > loss_disc_real_0: 0.23815524578094482  (0.23093342408537865)\n",
      "     | > loss_disc_real_1: 0.21646444499492645  (0.21339775249361992)\n",
      "     | > loss_disc_real_2: 0.18967033922672272  (0.1838209256529808)\n",
      "     | > loss_disc_real_3: 0.20544171333312988  (0.2027898207306862)\n",
      "     | > loss_disc_real_4: 0.19062462449073792  (0.19090429320931435)\n",
      "     | > loss_disc_real_5: 0.21785996854305267  (0.20393594354391098)\n",
      "     | > loss_0: 2.8924288749694824  (2.9033749103546143)\n",
      "     | > loss_gen: 1.39545476436615  (1.3661698997020721)\n",
      "     | > loss_kl: 4.467488765716553  (4.565924882888794)\n",
      "     | > loss_feat: 1.147383451461792  (1.2738397419452667)\n",
      "     | > loss_mel: 26.9592227935791  (27.060104846954346)\n",
      "     | > loss_duration: 1.150639533996582  (1.2850471884012222)\n",
      "     | > loss_1: 35.12018966674805  (35.551087379455566)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 2.8868722915649414  (2.9000743865966796)\n",
      "     | > loss_disc_real_0: 0.24227650463581085  (0.2332020401954651)\n",
      "     | > loss_disc_real_1: 0.22231270372867584  (0.2151807427406311)\n",
      "     | > loss_disc_real_2: 0.1971382349729538  (0.1864843875169754)\n",
      "     | > loss_disc_real_3: 0.22196510434150696  (0.20662487745285035)\n",
      "     | > loss_disc_real_4: 0.2037700116634369  (0.19347743690013885)\n",
      "     | > loss_disc_real_5: 0.21922695636749268  (0.20699414610862732)\n",
      "     | > loss_0: 2.8868722915649414  (2.9000743865966796)\n",
      "     | > loss_gen: 1.4336835145950317  (1.3796726226806642)\n",
      "     | > loss_kl: 3.917745590209961  (4.4362890243530275)\n",
      "     | > loss_feat: 0.9914090037345886  (1.217353594303131)\n",
      "     | > loss_mel: 23.108686447143555  (26.269821166992188)\n",
      "     | > loss_duration: 1.4418535232543945  (1.3164084553718567)\n",
      "     | > loss_1: 30.89337921142578  (34.61954574584961)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 2.9519898891448975  (2.908726970354716)\n",
      "     | > loss_disc_real_0: 0.26957398653030396  (0.23926403125127158)\n",
      "     | > loss_disc_real_1: 0.24415850639343262  (0.22001037001609802)\n",
      "     | > loss_disc_real_2: 0.2115764319896698  (0.19066639492909113)\n",
      "     | > loss_disc_real_3: 0.23395724594593048  (0.21118027220169702)\n",
      "     | > loss_disc_real_4: 0.2298867404460907  (0.1995456541577975)\n",
      "     | > loss_disc_real_5: 0.2445600926876068  (0.2132551372051239)\n",
      "     | > loss_0: 2.9519898891448975  (2.908726970354716)\n",
      "     | > loss_gen: 1.4935485124588013  (1.398651937643687)\n",
      "     | > loss_kl: 4.156071186065674  (4.389586051305135)\n",
      "     | > loss_feat: 0.6093010306358337  (1.1160115003585815)\n",
      "     | > loss_mel: 23.3363094329834  (25.78090254465739)\n",
      "     | > loss_duration: 1.17374587059021  (1.292631357908249)\n",
      "     | > loss_1: 30.76897621154785  (33.977784156799316)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.002406438191731771 \u001b[0m(-9.409586588541652e-05)\n",
      "     | > avg_loss_disc:\u001b[92m 2.908726970354716 \u001b[0m(-0.08710984388987253)\n",
      "     | > avg_loss_disc_real_0:\u001b[91m 0.23926403125127158 \u001b[0m(+0.027988091111183167)\n",
      "     | > avg_loss_disc_real_1:\u001b[92m 0.22001037001609802 \u001b[0m(-0.05870561798413593)\n",
      "     | > avg_loss_disc_real_2:\u001b[92m 0.19066639492909113 \u001b[0m(-0.10346647351980212)\n",
      "     | > avg_loss_disc_real_3:\u001b[92m 0.21118027220169702 \u001b[0m(-0.08172547072172168)\n",
      "     | > avg_loss_disc_real_4:\u001b[92m 0.1995456541577975 \u001b[0m(-0.06276836246252063)\n",
      "     | > avg_loss_disc_real_5:\u001b[92m 0.2132551372051239 \u001b[0m(-0.031057079633076995)\n",
      "     | > avg_loss_0:\u001b[92m 2.908726970354716 \u001b[0m(-0.08710984388987253)\n",
      "     | > avg_loss_gen:\u001b[92m 1.398651937643687 \u001b[0m(-0.2096574306488037)\n",
      "     | > avg_loss_kl:\u001b[92m 4.389586051305135 \u001b[0m(-0.48606797059377094)\n",
      "     | > avg_loss_feat:\u001b[91m 1.1160115003585815 \u001b[0m(+0.6768962343533833)\n",
      "     | > avg_loss_mel:\u001b[91m 25.78090254465739 \u001b[0m(+0.3275340398152693)\n",
      "     | > avg_loss_duration:\u001b[91m 1.292631357908249 \u001b[0m(+0.03279784321784973)\n",
      "     | > avg_loss_1:\u001b[91m 33.977784156799316 \u001b[0m(+0.34150346120198805)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 3/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:39:51) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:39:53 -- STEP: 3/32 -- GLOBAL_STEP: 1000100\u001b[0m\n",
      "     | > loss_disc: 3.124021053314209  (3.029479742050171)\n",
      "     | > loss_disc_real_0: 0.17262041568756104  (0.23371572295824686)\n",
      "     | > loss_disc_real_1: 0.1162162646651268  (0.2844756717483203)\n",
      "     | > loss_disc_real_2: 0.22606457769870758  (0.27239451309045154)\n",
      "     | > loss_disc_real_3: 0.21104395389556885  (0.2594993809858958)\n",
      "     | > loss_disc_real_4: 0.21446795761585236  (0.27156733969847363)\n",
      "     | > loss_disc_real_5: 0.17569641768932343  (0.23557595908641815)\n",
      "     | > loss_0: 3.124021053314209  (3.029479742050171)\n",
      "     | > grad_norm_0: tensor(5.4391, device='cuda:0')  (tensor(3.5127, device='cuda:0'))\n",
      "     | > loss_gen: 1.5528134107589722  (1.6232942740122478)\n",
      "     | > loss_kl: 5.052215576171875  (4.7732768058776855)\n",
      "     | > loss_feat: 1.531136155128479  (0.962914228439331)\n",
      "     | > loss_mel: 26.21868133544922  (24.60630734761556)\n",
      "     | > loss_duration: 10.70669937133789  (8.062211275100708)\n",
      "     | > amp_scaler: 256.0  (256.0)\n",
      "     | > loss_1: 45.061546325683594  (40.02800432840983)\n",
      "     | > grad_norm_1: tensor(279.8502, device='cuda:0')  (tensor(211.7299, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019992500937460937 \n",
      "     | > current_lr_1: 0.00019992500937460937 \n",
      "     | > step_time: 0.3733  (0.3734448750813802)\n",
      "     | > loader_time: 0.0031  (0.0032672882080078125)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:40:03 -- STEP: 28/32 -- GLOBAL_STEP: 1000125\u001b[0m\n",
      "     | > loss_disc: 2.964106321334839  (2.951759764126369)\n",
      "     | > loss_disc_real_0: 0.2696360647678375  (0.24762347447020666)\n",
      "     | > loss_disc_real_1: 0.30647146701812744  (0.25634948510144423)\n",
      "     | > loss_disc_real_2: 0.23429785668849945  (0.2546628415584565)\n",
      "     | > loss_disc_real_3: 0.2415585219860077  (0.251648552183594)\n",
      "     | > loss_disc_real_4: 0.2605613172054291  (0.2519646845757962)\n",
      "     | > loss_disc_real_5: 0.28280287981033325  (0.251491721187319)\n",
      "     | > loss_0: 2.964106321334839  (2.951759764126369)\n",
      "     | > grad_norm_0: tensor(1.3522, device='cuda:0')  (tensor(1.9201, device='cuda:0'))\n",
      "     | > loss_gen: 1.652567982673645  (1.6021306940487452)\n",
      "     | > loss_kl: 4.0427350997924805  (4.187199618135181)\n",
      "     | > loss_feat: 0.6769453287124634  (0.8625883300389562)\n",
      "     | > loss_mel: 22.935009002685547  (23.532341684613908)\n",
      "     | > loss_duration: 1.5062774419784546  (3.338189418826784)\n",
      "     | > amp_scaler: 256.0  (256.0)\n",
      "     | > loss_1: 30.813535690307617  (33.52244935716901)\n",
      "     | > grad_norm_1: tensor(130.8898, device='cuda:0')  (tensor(180.4328, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019992500937460937 \n",
      "     | > current_lr_1: 0.00019992500937460937 \n",
      "     | > step_time: 0.3545  (0.3917512893676758)\n",
      "     | > loader_time: 0.0028  (0.0034258365631103516)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 3.0196361541748047  (3.0196361541748047)\n",
      "     | > loss_disc_real_0: 0.26668062806129456  (0.26668062806129456)\n",
      "     | > loss_disc_real_1: 0.3273454010486603  (0.3273454010486603)\n",
      "     | > loss_disc_real_2: 0.25242069363594055  (0.25242069363594055)\n",
      "     | > loss_disc_real_3: 0.2749352753162384  (0.2749352753162384)\n",
      "     | > loss_disc_real_4: 0.2952856123447418  (0.2952856123447418)\n",
      "     | > loss_disc_real_5: 0.28177228569984436  (0.28177228569984436)\n",
      "     | > loss_0: 3.0196361541748047  (3.0196361541748047)\n",
      "     | > loss_gen: 1.6970124244689941  (1.6970124244689941)\n",
      "     | > loss_kl: 4.329864501953125  (4.329864501953125)\n",
      "     | > loss_feat: 0.04825405031442642  (0.04825405031442642)\n",
      "     | > loss_mel: 21.09493064880371  (21.09493064880371)\n",
      "     | > loss_duration: 1.4495491981506348  (1.4495491981506348)\n",
      "     | > loss_1: 28.619609832763672  (28.619609832763672)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.9048261642456055  (2.9048261642456055)\n",
      "     | > loss_disc_real_0: 0.21959154307842255  (0.21959154307842255)\n",
      "     | > loss_disc_real_1: 0.3348305821418762  (0.3348305821418762)\n",
      "     | > loss_disc_real_2: 0.23018380999565125  (0.23018380999565125)\n",
      "     | > loss_disc_real_3: 0.24671399593353271  (0.24671399593353271)\n",
      "     | > loss_disc_real_4: 0.26950106024742126  (0.26950106024742126)\n",
      "     | > loss_disc_real_5: 0.24079617857933044  (0.24079617857933044)\n",
      "     | > loss_0: 2.9048261642456055  (2.9048261642456055)\n",
      "     | > loss_gen: 1.6641895771026611  (1.6641895771026611)\n",
      "     | > loss_kl: 5.180713653564453  (5.180713653564453)\n",
      "     | > loss_feat: 0.9158511757850647  (0.9158511757850647)\n",
      "     | > loss_mel: 29.490880966186523  (29.490880966186523)\n",
      "     | > loss_duration: 1.362220048904419  (1.362220048904419)\n",
      "     | > loss_1: 38.613853454589844  (38.613853454589844)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 3.023757219314575  (2.9642916917800903)\n",
      "     | > loss_disc_real_0: 0.23317241668701172  (0.22638197988271713)\n",
      "     | > loss_disc_real_1: 0.3156276047229767  (0.32522909343242645)\n",
      "     | > loss_disc_real_2: 0.23647882044315338  (0.2333313152194023)\n",
      "     | > loss_disc_real_3: 0.2528393864631653  (0.249776691198349)\n",
      "     | > loss_disc_real_4: 0.27095770835876465  (0.27022938430309296)\n",
      "     | > loss_disc_real_5: 0.24463212490081787  (0.24271415174007416)\n",
      "     | > loss_0: 3.023757219314575  (2.9642916917800903)\n",
      "     | > loss_gen: 1.5701788663864136  (1.6171842217445374)\n",
      "     | > loss_kl: 3.7904908657073975  (4.485602259635925)\n",
      "     | > loss_feat: 0.572493314743042  (0.7441722452640533)\n",
      "     | > loss_mel: 20.624372482299805  (25.057626724243164)\n",
      "     | > loss_duration: 1.6607847213745117  (1.5115023851394653)\n",
      "     | > loss_1: 28.218318939208984  (33.416086196899414)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 3.019890308380127  (2.9828245639801025)\n",
      "     | > loss_disc_real_0: 0.1907782107591629  (0.21451405684153238)\n",
      "     | > loss_disc_real_1: 0.2877500057220459  (0.31273606419563293)\n",
      "     | > loss_disc_real_2: 0.20999298989772797  (0.22555187344551086)\n",
      "     | > loss_disc_real_3: 0.2186967432498932  (0.23941670854886374)\n",
      "     | > loss_disc_real_4: 0.22119995951652527  (0.2538862427075704)\n",
      "     | > loss_disc_real_5: 0.2036084085702896  (0.22967890401681265)\n",
      "     | > loss_0: 3.019890308380127  (2.9828245639801025)\n",
      "     | > loss_gen: 1.4349305629730225  (1.5564330021540325)\n",
      "     | > loss_kl: 4.541592121124268  (4.504265546798706)\n",
      "     | > loss_feat: 1.0873525142669678  (0.8585656682650248)\n",
      "     | > loss_mel: 24.279903411865234  (24.798385620117188)\n",
      "     | > loss_duration: 0.933220624923706  (1.318741798400879)\n",
      "     | > loss_1: 32.277000427246094  (33.036390940348305)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 3.01920223236084  (2.991918981075287)\n",
      "     | > loss_disc_real_0: 0.16639026999473572  (0.20248311012983322)\n",
      "     | > loss_disc_real_1: 0.2875515818595886  (0.30643994361162186)\n",
      "     | > loss_disc_real_2: 0.20207440853118896  (0.2196825072169304)\n",
      "     | > loss_disc_real_3: 0.21055981516838074  (0.23220248520374298)\n",
      "     | > loss_disc_real_4: 0.19444598257541656  (0.23902617767453194)\n",
      "     | > loss_disc_real_5: 0.17562644183635712  (0.21616578847169876)\n",
      "     | > loss_0: 3.01920223236084  (2.991918981075287)\n",
      "     | > loss_gen: 1.3258652687072754  (1.4987910687923431)\n",
      "     | > loss_kl: 3.7929327487945557  (4.3264323472976685)\n",
      "     | > loss_feat: 1.4155569076538086  (0.9978134781122208)\n",
      "     | > loss_mel: 21.343647003173828  (23.934700965881348)\n",
      "     | > loss_duration: 1.166002869606018  (1.2805570662021637)\n",
      "     | > loss_1: 29.044002532958984  (32.03829383850098)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 3.026094913482666  (2.9987541675567626)\n",
      "     | > loss_disc_real_0: 0.23927411437034607  (0.2098413109779358)\n",
      "     | > loss_disc_real_1: 0.30720391869544983  (0.30659273862838743)\n",
      "     | > loss_disc_real_2: 0.2379056066274643  (0.22332712709903718)\n",
      "     | > loss_disc_real_3: 0.25991424918174744  (0.23774483799934387)\n",
      "     | > loss_disc_real_4: 0.2837793827056885  (0.24797681868076324)\n",
      "     | > loss_disc_real_5: 0.25284355878829956  (0.2235013425350189)\n",
      "     | > loss_0: 3.026094913482666  (2.9987541675567626)\n",
      "     | > loss_gen: 1.5912009477615356  (1.5172730445861817)\n",
      "     | > loss_kl: 4.0508928298950195  (4.2713244438171385)\n",
      "     | > loss_feat: 0.8561108708381653  (0.9694729566574096)\n",
      "     | > loss_mel: 22.34130859375  (23.616022491455077)\n",
      "     | > loss_duration: 1.4019681215286255  (1.304839277267456)\n",
      "     | > loss_1: 30.24148178100586  (31.678931427001952)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 2.9819090366363525  (2.9959466457366943)\n",
      "     | > loss_disc_real_0: 0.23642489314079285  (0.21427190800507864)\n",
      "     | > loss_disc_real_1: 0.3263908624649048  (0.3098924259344737)\n",
      "     | > loss_disc_real_2: 0.2341742068529129  (0.22513497372468314)\n",
      "     | > loss_disc_real_3: 0.25411930680274963  (0.24047391613324484)\n",
      "     | > loss_disc_real_4: 0.2676226496696472  (0.25125112384557724)\n",
      "     | > loss_disc_real_5: 0.2419341653585434  (0.226573479672273)\n",
      "     | > loss_0: 2.9819090366363525  (2.9959466457366943)\n",
      "     | > loss_gen: 1.6170189380645752  (1.5338973601659138)\n",
      "     | > loss_kl: 3.729874610900879  (4.181082804997762)\n",
      "     | > loss_feat: 0.7002752423286438  (0.9246066709359487)\n",
      "     | > loss_mel: 23.956125259399414  (23.67270628611247)\n",
      "     | > loss_duration: 1.1592553853988647  (1.2805752952893574)\n",
      "     | > loss_1: 31.162551879882812  (31.592868169148762)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.002472519874572754 \u001b[0m(+6.608168284098293e-05)\n",
      "     | > avg_loss_disc:\u001b[91m 2.9959466457366943 \u001b[0m(+0.0872196753819785)\n",
      "     | > avg_loss_disc_real_0:\u001b[92m 0.21427190800507864 \u001b[0m(-0.024992123246192932)\n",
      "     | > avg_loss_disc_real_1:\u001b[91m 0.3098924259344737 \u001b[0m(+0.08988205591837567)\n",
      "     | > avg_loss_disc_real_2:\u001b[91m 0.22513497372468314 \u001b[0m(+0.03446857879559201)\n",
      "     | > avg_loss_disc_real_3:\u001b[91m 0.24047391613324484 \u001b[0m(+0.02929364393154782)\n",
      "     | > avg_loss_disc_real_4:\u001b[91m 0.25125112384557724 \u001b[0m(+0.051705469687779754)\n",
      "     | > avg_loss_disc_real_5:\u001b[91m 0.226573479672273 \u001b[0m(+0.013318342467149108)\n",
      "     | > avg_loss_0:\u001b[91m 2.9959466457366943 \u001b[0m(+0.0872196753819785)\n",
      "     | > avg_loss_gen:\u001b[91m 1.5338973601659138 \u001b[0m(+0.13524542252222682)\n",
      "     | > avg_loss_kl:\u001b[92m 4.181082804997762 \u001b[0m(-0.20850324630737305)\n",
      "     | > avg_loss_feat:\u001b[92m 0.9246066709359487 \u001b[0m(-0.19140482942263282)\n",
      "     | > avg_loss_mel:\u001b[92m 23.67270628611247 \u001b[0m(-2.108196258544922)\n",
      "     | > avg_loss_duration:\u001b[92m 1.2805752952893574 \u001b[0m(-0.012056062618891472)\n",
      "     | > avg_loss_1:\u001b[92m 31.592868169148762 \u001b[0m(-2.3849159876505546)\n",
      "\n",
      " > BEST MODEL : /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1/best_model_1000129.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 4/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:40:10) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:40:19 -- STEP: 21/32 -- GLOBAL_STEP: 1000150\u001b[0m\n",
      "     | > loss_disc: 3.027101516723633  (2.956196353549049)\n",
      "     | > loss_disc_real_0: 0.3629564046859741  (0.2555331488450368)\n",
      "     | > loss_disc_real_1: 0.1563989222049713  (0.24257337053616843)\n",
      "     | > loss_disc_real_2: 0.19108712673187256  (0.25491852845464436)\n",
      "     | > loss_disc_real_3: 0.24009744822978973  (0.25925340184143614)\n",
      "     | > loss_disc_real_4: 0.2865941524505615  (0.2597384431532451)\n",
      "     | > loss_disc_real_5: 0.33302080631256104  (0.2611646226474217)\n",
      "     | > loss_0: 3.027101516723633  (2.956196353549049)\n",
      "     | > grad_norm_0: tensor(3.3173, device='cuda:0')  (tensor(2.5490, device='cuda:0'))\n",
      "     | > loss_gen: 1.2342694997787476  (1.6279514914467221)\n",
      "     | > loss_kl: 3.640594720840454  (4.037272544134231)\n",
      "     | > loss_feat: 0.4334413409233093  (0.94321513459796)\n",
      "     | > loss_mel: 21.79864501953125  (23.15546026683989)\n",
      "     | > loss_duration: 1.1506667137145996  (2.7839512314115247)\n",
      "     | > amp_scaler: 128.0  (170.66666666666666)\n",
      "     | > loss_1: 28.257617950439453  (32.5478504725865)\n",
      "     | > grad_norm_1: tensor(139.3747, device='cuda:0')  (tensor(176.1371, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019990001874843754 \n",
      "     | > current_lr_1: 0.00019990001874843754 \n",
      "     | > step_time: 0.3771  (0.37981932503836496)\n",
      "     | > loader_time: 0.0039  (0.0035423778352283294)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.975355386734009  (2.975355386734009)\n",
      "     | > loss_disc_real_0: 0.21523568034172058  (0.21523568034172058)\n",
      "     | > loss_disc_real_1: 0.19374608993530273  (0.19374608993530273)\n",
      "     | > loss_disc_real_2: 0.2379871904850006  (0.2379871904850006)\n",
      "     | > loss_disc_real_3: 0.289067804813385  (0.289067804813385)\n",
      "     | > loss_disc_real_4: 0.30303165316581726  (0.30303165316581726)\n",
      "     | > loss_disc_real_5: 0.2711739242076874  (0.2711739242076874)\n",
      "     | > loss_0: 2.975355386734009  (2.975355386734009)\n",
      "     | > loss_gen: 1.551741600036621  (1.551741600036621)\n",
      "     | > loss_kl: 4.118799209594727  (4.118799209594727)\n",
      "     | > loss_feat: 0.4398926794528961  (0.4398926794528961)\n",
      "     | > loss_mel: 20.315351486206055  (20.315351486206055)\n",
      "     | > loss_duration: 1.453473448753357  (1.453473448753357)\n",
      "     | > loss_1: 27.87925910949707  (27.87925910949707)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.982753038406372  (2.982753038406372)\n",
      "     | > loss_disc_real_0: 0.22103674709796906  (0.22103674709796906)\n",
      "     | > loss_disc_real_1: 0.20977862179279327  (0.20977862179279327)\n",
      "     | > loss_disc_real_2: 0.23648832738399506  (0.23648832738399506)\n",
      "     | > loss_disc_real_3: 0.2867172658443451  (0.2867172658443451)\n",
      "     | > loss_disc_real_4: 0.29961690306663513  (0.29961690306663513)\n",
      "     | > loss_disc_real_5: 0.2677326202392578  (0.2677326202392578)\n",
      "     | > loss_0: 2.982753038406372  (2.982753038406372)\n",
      "     | > loss_gen: 1.5550085306167603  (1.5550085306167603)\n",
      "     | > loss_kl: 4.132559776306152  (4.132559776306152)\n",
      "     | > loss_feat: 0.5181386470794678  (0.5181386470794678)\n",
      "     | > loss_mel: 29.032838821411133  (29.032838821411133)\n",
      "     | > loss_duration: 1.365670084953308  (1.365670084953308)\n",
      "     | > loss_1: 36.60421371459961  (36.60421371459961)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 3.017284870147705  (3.0000189542770386)\n",
      "     | > loss_disc_real_0: 0.22422869503498077  (0.22263272106647491)\n",
      "     | > loss_disc_real_1: 0.20774854719638824  (0.20876358449459076)\n",
      "     | > loss_disc_real_2: 0.24660681188106537  (0.2415475696325302)\n",
      "     | > loss_disc_real_3: 0.29347696900367737  (0.29009711742401123)\n",
      "     | > loss_disc_real_4: 0.30603957176208496  (0.30282823741436005)\n",
      "     | > loss_disc_real_5: 0.27950990200042725  (0.27362126111984253)\n",
      "     | > loss_0: 3.017284870147705  (3.0000189542770386)\n",
      "     | > loss_gen: 1.5575482845306396  (1.5562784075737)\n",
      "     | > loss_kl: 3.0452675819396973  (3.588913679122925)\n",
      "     | > loss_feat: 0.027415664866566658  (0.2727771559730172)\n",
      "     | > loss_mel: 20.66156005859375  (24.84719944000244)\n",
      "     | > loss_duration: 1.736194133758545  (1.5509321093559265)\n",
      "     | > loss_1: 27.027986526489258  (31.816100120544434)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 2.8828108310699463  (2.9609495798746743)\n",
      "     | > loss_disc_real_0: 0.17692576348781586  (0.20739706854025522)\n",
      "     | > loss_disc_real_1: 0.17330551147460938  (0.19694422682126364)\n",
      "     | > loss_disc_real_2: 0.20759879052639008  (0.2302313099304835)\n",
      "     | > loss_disc_real_3: 0.2523864805698395  (0.2775269051392873)\n",
      "     | > loss_disc_real_4: 0.2631755471229553  (0.2896106739838918)\n",
      "     | > loss_disc_real_5: 0.23481275141239166  (0.2606850912173589)\n",
      "     | > loss_0: 2.8828108310699463  (2.9609495798746743)\n",
      "     | > loss_gen: 1.4562792778015137  (1.5229453643163045)\n",
      "     | > loss_kl: 4.374770641326904  (3.8508659998575845)\n",
      "     | > loss_feat: 1.1246399879455566  (0.556731433297197)\n",
      "     | > loss_mel: 25.706653594970703  (25.133684158325195)\n",
      "     | > loss_duration: 0.9164242744445801  (1.339429497718811)\n",
      "     | > loss_1: 33.578765869140625  (32.4036553700765)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 2.8797736167907715  (2.9406555891036987)\n",
      "     | > loss_disc_real_0: 0.19911238551139832  (0.205325897783041)\n",
      "     | > loss_disc_real_1: 0.19117805361747742  (0.19550268352031708)\n",
      "     | > loss_disc_real_2: 0.22147236764431  (0.22804157435894012)\n",
      "     | > loss_disc_real_3: 0.26852285861968994  (0.27527589350938797)\n",
      "     | > loss_disc_real_4: 0.2783026695251465  (0.2867836728692055)\n",
      "     | > loss_disc_real_5: 0.24730727076530457  (0.2573406361043453)\n",
      "     | > loss_0: 2.8797736167907715  (2.9406555891036987)\n",
      "     | > loss_gen: 1.545839548110962  (1.5286689102649689)\n",
      "     | > loss_kl: 3.9747555255889893  (3.881838381290436)\n",
      "     | > loss_feat: 1.065413236618042  (0.6839018841274083)\n",
      "     | > loss_mel: 24.159700393676758  (24.890188217163086)\n",
      "     | > loss_duration: 1.1507959365844727  (1.2922711074352264)\n",
      "     | > loss_1: 31.896503448486328  (32.276867389678955)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 2.9764890670776367  (2.9478222846984865)\n",
      "     | > loss_disc_real_0: 0.21863222122192383  (0.20798716247081755)\n",
      "     | > loss_disc_real_1: 0.19726303219795227  (0.19585475325584412)\n",
      "     | > loss_disc_real_2: 0.24002458155155182  (0.23043817579746245)\n",
      "     | > loss_disc_real_3: 0.28364622592926025  (0.2769499599933624)\n",
      "     | > loss_disc_real_4: 0.29780009388923645  (0.28898695707321165)\n",
      "     | > loss_disc_real_5: 0.26822879910469055  (0.25951826870441436)\n",
      "     | > loss_0: 2.9764890670776367  (2.9478222846984865)\n",
      "     | > loss_gen: 1.544113039970398  (1.5317577362060546)\n",
      "     | > loss_kl: 3.7996575832366943  (3.8654022216796875)\n",
      "     | > loss_feat: 0.3897586762905121  (0.625073242560029)\n",
      "     | > loss_mel: 21.555477142333984  (24.223246002197264)\n",
      "     | > loss_duration: 1.440542459487915  (1.3219253778457642)\n",
      "     | > loss_1: 28.729549407958984  (31.56740379333496)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 2.9418418407440186  (2.946825544039408)\n",
      "     | > loss_disc_real_0: 0.2006891369819641  (0.20677082488934198)\n",
      "     | > loss_disc_real_1: 0.22103583812713623  (0.2000516007343928)\n",
      "     | > loss_disc_real_2: 0.22514040768146515  (0.22955521444479624)\n",
      "     | > loss_disc_real_3: 0.26936304569244385  (0.27568547427654266)\n",
      "     | > loss_disc_real_4: 0.2835220694541931  (0.28807614247004193)\n",
      "     | > loss_disc_real_5: 0.2551864981651306  (0.2587963069478671)\n",
      "     | > loss_0: 2.9418418407440186  (2.946825544039408)\n",
      "     | > loss_gen: 1.5308184623718262  (1.5316011905670166)\n",
      "     | > loss_kl: 3.6350247859954834  (3.827005982398987)\n",
      "     | > loss_feat: 0.8705271482467651  (0.6659822268411517)\n",
      "     | > loss_mel: 23.91583824157715  (24.172011375427246)\n",
      "     | > loss_duration: 1.175458312034607  (1.2975142002105713)\n",
      "     | > loss_1: 31.127668380737305  (31.49411455790202)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0024175643920898438 \u001b[0m(-5.4955482482910156e-05)\n",
      "     | > avg_loss_disc:\u001b[92m 2.946825544039408 \u001b[0m(-0.04912110169728612)\n",
      "     | > avg_loss_disc_real_0:\u001b[92m 0.20677082488934198 \u001b[0m(-0.007501083115736662)\n",
      "     | > avg_loss_disc_real_1:\u001b[92m 0.2000516007343928 \u001b[0m(-0.1098408252000809)\n",
      "     | > avg_loss_disc_real_2:\u001b[91m 0.22955521444479624 \u001b[0m(+0.0044202407201131)\n",
      "     | > avg_loss_disc_real_3:\u001b[91m 0.27568547427654266 \u001b[0m(+0.03521155814329782)\n",
      "     | > avg_loss_disc_real_4:\u001b[91m 0.28807614247004193 \u001b[0m(+0.03682501862446469)\n",
      "     | > avg_loss_disc_real_5:\u001b[91m 0.2587963069478671 \u001b[0m(+0.032222827275594085)\n",
      "     | > avg_loss_0:\u001b[92m 2.946825544039408 \u001b[0m(-0.04912110169728612)\n",
      "     | > avg_loss_gen:\u001b[92m 1.5316011905670166 \u001b[0m(-0.002296169598897224)\n",
      "     | > avg_loss_kl:\u001b[92m 3.827005982398987 \u001b[0m(-0.35407682259877493)\n",
      "     | > avg_loss_feat:\u001b[92m 0.6659822268411517 \u001b[0m(-0.258624444094797)\n",
      "     | > avg_loss_mel:\u001b[91m 24.172011375427246 \u001b[0m(+0.49930508931477746)\n",
      "     | > avg_loss_duration:\u001b[91m 1.2975142002105713 \u001b[0m(+0.01693890492121386)\n",
      "     | > avg_loss_1:\u001b[92m 31.49411455790202 \u001b[0m(-0.09875361124674242)\n",
      "\n",
      " > BEST MODEL : /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1/best_model_1000161.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 5/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:40:29) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:40:35 -- STEP: 14/32 -- GLOBAL_STEP: 1000175\u001b[0m\n",
      "     | > loss_disc: 2.930220603942871  (2.93438948903765)\n",
      "     | > loss_disc_real_0: 0.2970041334629059  (0.2447775261742728)\n",
      "     | > loss_disc_real_1: 0.19750124216079712  (0.24048458146197454)\n",
      "     | > loss_disc_real_2: 0.2722987234592438  (0.2498033908861024)\n",
      "     | > loss_disc_real_3: 0.304342657327652  (0.25317678281239103)\n",
      "     | > loss_disc_real_4: 0.30701038241386414  (0.2534768932632038)\n",
      "     | > loss_disc_real_5: 0.2922857403755188  (0.25073162466287613)\n",
      "     | > loss_0: 2.930220603942871  (2.93438948903765)\n",
      "     | > grad_norm_0: tensor(2.1053, device='cuda:0')  (tensor(1.4486, device='cuda:0'))\n",
      "     | > loss_gen: 1.5608952045440674  (1.5898411273956299)\n",
      "     | > loss_kl: 3.7177786827087402  (3.8437716790608)\n",
      "     | > loss_feat: 0.7985731959342957  (0.863714836537838)\n",
      "     | > loss_mel: 23.504846572875977  (23.48477050236293)\n",
      "     | > loss_duration: 1.2994130849838257  (3.415778432573591)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 30.881507873535156  (33.197876657758435)\n",
      "     | > grad_norm_1: tensor(80.1689, device='cuda:0')  (tensor(150.7825, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019987503124609398 \n",
      "     | > current_lr_1: 0.00019987503124609398 \n",
      "     | > step_time: 0.3705  (0.3847872700010027)\n",
      "     | > loader_time: 0.0035  (0.0037055526460920063)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.9434828758239746  (2.9434828758239746)\n",
      "     | > loss_disc_real_0: 0.21442283689975739  (0.21442283689975739)\n",
      "     | > loss_disc_real_1: 0.26809412240982056  (0.26809412240982056)\n",
      "     | > loss_disc_real_2: 0.22949054837226868  (0.22949054837226868)\n",
      "     | > loss_disc_real_3: 0.2536161243915558  (0.2536161243915558)\n",
      "     | > loss_disc_real_4: 0.20678743720054626  (0.20678743720054626)\n",
      "     | > loss_disc_real_5: 0.1940770447254181  (0.1940770447254181)\n",
      "     | > loss_0: 2.9434828758239746  (2.9434828758239746)\n",
      "     | > loss_gen: 1.4426274299621582  (1.4426274299621582)\n",
      "     | > loss_kl: 3.606613874435425  (3.606613874435425)\n",
      "     | > loss_feat: 0.9130313992500305  (0.9130313992500305)\n",
      "     | > loss_mel: 24.018693923950195  (24.018693923950195)\n",
      "     | > loss_duration: 1.4574884176254272  (1.4574884176254272)\n",
      "     | > loss_1: 31.43845558166504  (31.43845558166504)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.9891116619110107  (2.9891116619110107)\n",
      "     | > loss_disc_real_0: 0.21780598163604736  (0.21780598163604736)\n",
      "     | > loss_disc_real_1: 0.29442298412323  (0.29442298412323)\n",
      "     | > loss_disc_real_2: 0.24496248364448547  (0.24496248364448547)\n",
      "     | > loss_disc_real_3: 0.26783138513565063  (0.26783138513565063)\n",
      "     | > loss_disc_real_4: 0.23475462198257446  (0.23475462198257446)\n",
      "     | > loss_disc_real_5: 0.22240246832370758  (0.22240246832370758)\n",
      "     | > loss_0: 2.9891116619110107  (2.9891116619110107)\n",
      "     | > loss_gen: 1.4984263181686401  (1.4984263181686401)\n",
      "     | > loss_kl: 4.13139533996582  (4.13139533996582)\n",
      "     | > loss_feat: 0.3618201017379761  (0.3618201017379761)\n",
      "     | > loss_mel: 23.65216636657715  (23.65216636657715)\n",
      "     | > loss_duration: 1.3419734239578247  (1.3419734239578247)\n",
      "     | > loss_1: 30.985782623291016  (30.985782623291016)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 2.9577550888061523  (2.9734333753585815)\n",
      "     | > loss_disc_real_0: 0.21898886561393738  (0.21839742362499237)\n",
      "     | > loss_disc_real_1: 0.27413249015808105  (0.2842777371406555)\n",
      "     | > loss_disc_real_2: 0.23853841423988342  (0.24175044894218445)\n",
      "     | > loss_disc_real_3: 0.26610639691352844  (0.26696889102458954)\n",
      "     | > loss_disc_real_4: 0.22960950434207916  (0.2321820631623268)\n",
      "     | > loss_disc_real_5: 0.21476709842681885  (0.21858478337526321)\n",
      "     | > loss_0: 2.9577550888061523  (2.9734333753585815)\n",
      "     | > loss_gen: 1.4954919815063477  (1.496959149837494)\n",
      "     | > loss_kl: 3.6333703994750977  (3.882382869720459)\n",
      "     | > loss_feat: 0.70027756690979  (0.5310488343238831)\n",
      "     | > loss_mel: 23.583480834960938  (23.617823600769043)\n",
      "     | > loss_duration: 1.6879936456680298  (1.5149835348129272)\n",
      "     | > loss_1: 31.100614547729492  (31.043198585510254)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 2.738050699234009  (2.894972483317057)\n",
      "     | > loss_disc_real_0: 0.15433840453624725  (0.19704441726207733)\n",
      "     | > loss_disc_real_1: 0.22537587583065033  (0.2646437833706538)\n",
      "     | > loss_disc_real_2: 0.20347364246845245  (0.22899151345094046)\n",
      "     | > loss_disc_real_3: 0.2272728830575943  (0.25373688836892444)\n",
      "     | > loss_disc_real_4: 0.17022033035755157  (0.21152815222740173)\n",
      "     | > loss_disc_real_5: 0.14929449558258057  (0.19548802077770233)\n",
      "     | > loss_0: 2.738050699234009  (2.894972483317057)\n",
      "     | > loss_gen: 1.4298862218856812  (1.4746015071868896)\n",
      "     | > loss_kl: 3.474860191345215  (3.746541976928711)\n",
      "     | > loss_feat: 1.839144229888916  (0.9670806328455607)\n",
      "     | > loss_mel: 28.336538314819336  (25.190728505452473)\n",
      "     | > loss_duration: 0.8970655202865601  (1.3090108633041382)\n",
      "     | > loss_1: 35.97749328613281  (32.68796348571777)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 2.9301960468292236  (2.903778374195099)\n",
      "     | > loss_disc_real_0: 0.19381748139858246  (0.1962376832962036)\n",
      "     | > loss_disc_real_1: 0.24783988296985626  (0.2604428082704544)\n",
      "     | > loss_disc_real_2: 0.2351076602935791  (0.2305205501616001)\n",
      "     | > loss_disc_real_3: 0.2670598030090332  (0.25706761702895164)\n",
      "     | > loss_disc_real_4: 0.22889754176139832  (0.21587049961090088)\n",
      "     | > loss_disc_real_5: 0.2095806747674942  (0.1990111842751503)\n",
      "     | > loss_0: 2.9301960468292236  (2.903778374195099)\n",
      "     | > loss_gen: 1.4630502462387085  (1.4717136919498444)\n",
      "     | > loss_kl: 3.562826633453369  (3.7006131410598755)\n",
      "     | > loss_feat: 0.5928137898445129  (0.8735139220952988)\n",
      "     | > loss_mel: 24.685937881469727  (25.064530849456787)\n",
      "     | > loss_duration: 1.1493638753890991  (1.2690991163253784)\n",
      "     | > loss_1: 31.453994750976562  (32.37947130203247)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 2.9242360591888428  (2.9078699111938477)\n",
      "     | > loss_disc_real_0: 0.20223960280418396  (0.1974380671977997)\n",
      "     | > loss_disc_real_1: 0.2731016278266907  (0.26297457218170167)\n",
      "     | > loss_disc_real_2: 0.23696602880954742  (0.23180964589118958)\n",
      "     | > loss_disc_real_3: 0.2621460556983948  (0.25808330476284025)\n",
      "     | > loss_disc_real_4: 0.2210654616355896  (0.21690949201583862)\n",
      "     | > loss_disc_real_5: 0.1999344527721405  (0.19919583797454835)\n",
      "     | > loss_0: 2.9242360591888428  (2.9078699111938477)\n",
      "     | > loss_gen: 1.4976255893707275  (1.476896071434021)\n",
      "     | > loss_kl: 3.7942616939544678  (3.719342851638794)\n",
      "     | > loss_feat: 0.7658509612083435  (0.8519813299179078)\n",
      "     | > loss_mel: 23.168460845947266  (24.685316848754884)\n",
      "     | > loss_duration: 1.4072208404541016  (1.2967234611511231)\n",
      "     | > loss_1: 30.633419036865234  (32.03026084899902)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 2.9735584259033203  (2.9188179969787598)\n",
      "     | > loss_disc_real_0: 0.22355908155441284  (0.20179156959056854)\n",
      "     | > loss_disc_real_1: 0.2461497038602829  (0.2601704274614652)\n",
      "     | > loss_disc_real_2: 0.2444474697113037  (0.2339159498612086)\n",
      "     | > loss_disc_real_3: 0.2713228464126587  (0.26028989503781)\n",
      "     | > loss_disc_real_4: 0.2414519488811493  (0.2209999014933904)\n",
      "     | > loss_disc_real_5: 0.22998589277267456  (0.20432751377423605)\n",
      "     | > loss_0: 2.9735584259033203  (2.9188179969787598)\n",
      "     | > loss_gen: 1.4876030683517456  (1.4786805709203084)\n",
      "     | > loss_kl: 3.4537312984466553  (3.675074259440104)\n",
      "     | > loss_feat: 0.3307355046272278  (0.7651070257027944)\n",
      "     | > loss_mel: 24.348894119262695  (24.62924639383952)\n",
      "     | > loss_duration: 1.1579761505126953  (1.2735989093780518)\n",
      "     | > loss_1: 30.778940200805664  (31.821707407633465)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.0024954875310262046 \u001b[0m(+7.792313893636082e-05)\n",
      "     | > avg_loss_disc:\u001b[92m 2.9188179969787598 \u001b[0m(-0.028007547060648452)\n",
      "     | > avg_loss_disc_real_0:\u001b[92m 0.20179156959056854 \u001b[0m(-0.004979255298773438)\n",
      "     | > avg_loss_disc_real_1:\u001b[91m 0.2601704274614652 \u001b[0m(+0.06011882672707239)\n",
      "     | > avg_loss_disc_real_2:\u001b[91m 0.2339159498612086 \u001b[0m(+0.0043607354164123535)\n",
      "     | > avg_loss_disc_real_3:\u001b[92m 0.26028989503781 \u001b[0m(-0.015395579238732637)\n",
      "     | > avg_loss_disc_real_4:\u001b[92m 0.2209999014933904 \u001b[0m(-0.06707624097665152)\n",
      "     | > avg_loss_disc_real_5:\u001b[92m 0.20432751377423605 \u001b[0m(-0.05446879317363104)\n",
      "     | > avg_loss_0:\u001b[92m 2.9188179969787598 \u001b[0m(-0.028007547060648452)\n",
      "     | > avg_loss_gen:\u001b[92m 1.4786805709203084 \u001b[0m(-0.052920619646708245)\n",
      "     | > avg_loss_kl:\u001b[92m 3.675074259440104 \u001b[0m(-0.1519317229588828)\n",
      "     | > avg_loss_feat:\u001b[91m 0.7651070257027944 \u001b[0m(+0.09912479886164272)\n",
      "     | > avg_loss_mel:\u001b[91m 24.62924639383952 \u001b[0m(+0.4572350184122733)\n",
      "     | > avg_loss_duration:\u001b[92m 1.2735989093780518 \u001b[0m(-0.02391529083251953)\n",
      "     | > avg_loss_1:\u001b[91m 31.821707407633465 \u001b[0m(+0.3275928497314453)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 6/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:40:46) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:40:49 -- STEP: 7/32 -- GLOBAL_STEP: 1000200\u001b[0m\n",
      "     | > loss_disc: 3.0627055168151855  (2.9742598874228343)\n",
      "     | > loss_disc_real_0: 0.21484898030757904  (0.2459966582911355)\n",
      "     | > loss_disc_real_1: 0.2207263559103012  (0.24351911033902848)\n",
      "     | > loss_disc_real_2: 0.2522617280483246  (0.2530612370797566)\n",
      "     | > loss_disc_real_3: 0.24375265836715698  (0.250107222369739)\n",
      "     | > loss_disc_real_4: 0.23556940257549286  (0.25377436195101055)\n",
      "     | > loss_disc_real_5: 0.2187199890613556  (0.25859355287892477)\n",
      "     | > loss_0: 3.0627055168151855  (2.9742598874228343)\n",
      "     | > grad_norm_0: tensor(2.4158, device='cuda:0')  (tensor(1.8594, device='cuda:0'))\n",
      "     | > loss_gen: 1.6320443153381348  (1.5681278364998954)\n",
      "     | > loss_kl: 3.9153947830200195  (3.853574173791068)\n",
      "     | > loss_feat: 0.6381932497024536  (0.6928973751408714)\n",
      "     | > loss_mel: 22.138126373291016  (23.297914232526505)\n",
      "     | > loss_duration: 1.3762608766555786  (3.9398380858557567)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 29.70001983642578  (33.35235186985561)\n",
      "     | > grad_norm_1: tensor(175.9729, device='cuda:0')  (tensor(181.7741, device='cuda:0'))\n",
      "     | > current_lr_0: 0.0001998500468671882 \n",
      "     | > current_lr_1: 0.0001998500468671882 \n",
      "     | > step_time: 0.3814  (0.3904059955051967)\n",
      "     | > loader_time: 0.0032  (0.0034342833927699496)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 3.0456273555755615  (3.0456273555755615)\n",
      "     | > loss_disc_real_0: 0.23386085033416748  (0.23386085033416748)\n",
      "     | > loss_disc_real_1: 0.20453287661075592  (0.20453287661075592)\n",
      "     | > loss_disc_real_2: 0.30649566650390625  (0.30649566650390625)\n",
      "     | > loss_disc_real_3: 0.25709962844848633  (0.25709962844848633)\n",
      "     | > loss_disc_real_4: 0.27908793091773987  (0.27908793091773987)\n",
      "     | > loss_disc_real_5: 0.2402380406856537  (0.2402380406856537)\n",
      "     | > loss_0: 3.0456273555755615  (3.0456273555755615)\n",
      "     | > loss_gen: 1.5097721815109253  (1.5097721815109253)\n",
      "     | > loss_kl: 3.698737144470215  (3.698737144470215)\n",
      "     | > loss_feat: 0.39103764295578003  (0.39103764295578003)\n",
      "     | > loss_mel: 18.171701431274414  (18.171701431274414)\n",
      "     | > loss_duration: 1.451106071472168  (1.451106071472168)\n",
      "     | > loss_1: 25.222354888916016  (25.222354888916016)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.958667278289795  (2.958667278289795)\n",
      "     | > loss_disc_real_0: 0.25404196977615356  (0.25404196977615356)\n",
      "     | > loss_disc_real_1: 0.19722217321395874  (0.19722217321395874)\n",
      "     | > loss_disc_real_2: 0.3044799566268921  (0.3044799566268921)\n",
      "     | > loss_disc_real_3: 0.259068101644516  (0.259068101644516)\n",
      "     | > loss_disc_real_4: 0.27993541955947876  (0.27993541955947876)\n",
      "     | > loss_disc_real_5: 0.24513426423072815  (0.24513426423072815)\n",
      "     | > loss_0: 2.958667278289795  (2.958667278289795)\n",
      "     | > loss_gen: 1.5965017080307007  (1.5965017080307007)\n",
      "     | > loss_kl: 3.8301730155944824  (3.8301730155944824)\n",
      "     | > loss_feat: 0.5740473866462708  (0.5740473866462708)\n",
      "     | > loss_mel: 29.325014114379883  (29.325014114379883)\n",
      "     | > loss_duration: 1.3578557968139648  (1.3578557968139648)\n",
      "     | > loss_1: 36.683589935302734  (36.683589935302734)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 3.0022425651550293  (2.980454921722412)\n",
      "     | > loss_disc_real_0: 0.26123368740081787  (0.2576378285884857)\n",
      "     | > loss_disc_real_1: 0.2303837686777115  (0.2138029709458351)\n",
      "     | > loss_disc_real_2: 0.3114124834537506  (0.30794622004032135)\n",
      "     | > loss_disc_real_3: 0.26836392283439636  (0.2637160122394562)\n",
      "     | > loss_disc_real_4: 0.28680384159088135  (0.28336963057518005)\n",
      "     | > loss_disc_real_5: 0.25946375727653503  (0.2522990107536316)\n",
      "     | > loss_0: 3.0022425651550293  (2.980454921722412)\n",
      "     | > loss_gen: 1.6285312175750732  (1.612516462802887)\n",
      "     | > loss_kl: 2.7778255939483643  (3.3039993047714233)\n",
      "     | > loss_feat: 0.1146322563290596  (0.3443398214876652)\n",
      "     | > loss_mel: 17.648223876953125  (23.486618995666504)\n",
      "     | > loss_duration: 1.7269610166549683  (1.5424084067344666)\n",
      "     | > loss_1: 23.89617347717285  (30.289881706237793)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 2.8854117393493652  (2.9487738609313965)\n",
      "     | > loss_disc_real_0: 0.2008916735649109  (0.23872244358062744)\n",
      "     | > loss_disc_real_1: 0.16782580316066742  (0.1984772483507792)\n",
      "     | > loss_disc_real_2: 0.2947167754173279  (0.3035364051659902)\n",
      "     | > loss_disc_real_3: 0.24166086316108704  (0.2563642958799998)\n",
      "     | > loss_disc_real_4: 0.25849151611328125  (0.2750769257545471)\n",
      "     | > loss_disc_real_5: 0.22485464811325073  (0.24315088987350464)\n",
      "     | > loss_0: 2.8854117393493652  (2.9487738609313965)\n",
      "     | > loss_gen: 1.5224487781524658  (1.5824939012527466)\n",
      "     | > loss_kl: 3.4251136779785156  (3.3443707625071206)\n",
      "     | > loss_feat: 0.92295902967453  (0.5372128908832868)\n",
      "     | > loss_mel: 24.127197265625  (23.700145085652668)\n",
      "     | > loss_duration: 0.9039188623428345  (1.3295785586039226)\n",
      "     | > loss_1: 30.90163803100586  (30.49380048116048)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 2.8469338417053223  (2.923313856124878)\n",
      "     | > loss_disc_real_0: 0.18644391000270844  (0.2256528101861477)\n",
      "     | > loss_disc_real_1: 0.13653728365898132  (0.18299225717782974)\n",
      "     | > loss_disc_real_2: 0.28586825728416443  (0.29911936819553375)\n",
      "     | > loss_disc_real_3: 0.23389892280101776  (0.2507479526102543)\n",
      "     | > loss_disc_real_4: 0.24878889322280884  (0.26850491762161255)\n",
      "     | > loss_disc_real_5: 0.19448044896125793  (0.23098327964544296)\n",
      "     | > loss_0: 2.8469338417053223  (2.923313856124878)\n",
      "     | > loss_gen: 1.4912652969360352  (1.5596867501735687)\n",
      "     | > loss_kl: 3.8379335403442383  (3.4677614569664)\n",
      "     | > loss_feat: 1.2382502555847168  (0.7124722320586443)\n",
      "     | > loss_mel: 25.743839263916016  (24.211068630218506)\n",
      "     | > loss_duration: 1.1500612497329712  (1.2846992313861847)\n",
      "     | > loss_1: 33.46134948730469  (31.235687732696533)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 2.746668815612793  (2.887984848022461)\n",
      "     | > loss_disc_real_0: 0.17955465614795685  (0.21643317937850953)\n",
      "     | > loss_disc_real_1: 0.15994451940059662  (0.17838270962238312)\n",
      "     | > loss_disc_real_2: 0.2785053849220276  (0.29499657154083253)\n",
      "     | > loss_disc_real_3: 0.22206461429595947  (0.24501128494739532)\n",
      "     | > loss_disc_real_4: 0.22226373851299286  (0.2592566817998886)\n",
      "     | > loss_disc_real_5: 0.19022029638290405  (0.22283068299293518)\n",
      "     | > loss_0: 2.746668815612793  (2.887984848022461)\n",
      "     | > loss_gen: 1.527266502380371  (1.5532027006149292)\n",
      "     | > loss_kl: 3.2254064083099365  (3.4192904472351073)\n",
      "     | > loss_feat: 1.4354437589645386  (0.8570665374398232)\n",
      "     | > loss_mel: 24.28972816467285  (24.226800537109376)\n",
      "     | > loss_duration: 1.412490725517273  (1.3102575302124024)\n",
      "     | > loss_1: 31.890335083007812  (31.36661720275879)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 3.015695095062256  (2.9092698891957602)\n",
      "     | > loss_disc_real_0: 0.26153481006622314  (0.2239501178264618)\n",
      "     | > loss_disc_real_1: 0.22685515880584717  (0.18646145115296045)\n",
      "     | > loss_disc_real_2: 0.3105742931365967  (0.2975928584734599)\n",
      "     | > loss_disc_real_3: 0.26632755994796753  (0.2485639974474907)\n",
      "     | > loss_disc_real_4: 0.2864631712436676  (0.2637910967071851)\n",
      "     | > loss_disc_real_5: 0.25652381777763367  (0.2284462054570516)\n",
      "     | > loss_0: 3.015695095062256  (2.9092698891957602)\n",
      "     | > loss_gen: 1.6062546968460083  (1.5620446999867756)\n",
      "     | > loss_kl: 3.7010507583618164  (3.466250499089559)\n",
      "     | > loss_feat: 0.18964700400829315  (0.7458299485345682)\n",
      "     | > loss_mel: 20.315265655517578  (23.574878056844074)\n",
      "     | > loss_duration: 1.151129126548767  (1.2837361296017964)\n",
      "     | > loss_1: 26.963346481323242  (30.6327387491862)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0024176438649495444 \u001b[0m(-7.784366607666016e-05)\n",
      "     | > avg_loss_disc:\u001b[92m 2.9092698891957602 \u001b[0m(-0.009548107782999526)\n",
      "     | > avg_loss_disc_real_0:\u001b[91m 0.2239501178264618 \u001b[0m(+0.02215854823589325)\n",
      "     | > avg_loss_disc_real_1:\u001b[92m 0.18646145115296045 \u001b[0m(-0.07370897630850473)\n",
      "     | > avg_loss_disc_real_2:\u001b[91m 0.2975928584734599 \u001b[0m(+0.06367690861225131)\n",
      "     | > avg_loss_disc_real_3:\u001b[92m 0.2485639974474907 \u001b[0m(-0.011725897590319334)\n",
      "     | > avg_loss_disc_real_4:\u001b[91m 0.2637910967071851 \u001b[0m(+0.04279119521379468)\n",
      "     | > avg_loss_disc_real_5:\u001b[91m 0.2284462054570516 \u001b[0m(+0.024118691682815552)\n",
      "     | > avg_loss_0:\u001b[92m 2.9092698891957602 \u001b[0m(-0.009548107782999526)\n",
      "     | > avg_loss_gen:\u001b[91m 1.5620446999867756 \u001b[0m(+0.08336412906646729)\n",
      "     | > avg_loss_kl:\u001b[92m 3.466250499089559 \u001b[0m(-0.20882376035054495)\n",
      "     | > avg_loss_feat:\u001b[92m 0.7458299485345682 \u001b[0m(-0.019277077168226242)\n",
      "     | > avg_loss_mel:\u001b[92m 23.574878056844074 \u001b[0m(-1.054368336995445)\n",
      "     | > avg_loss_duration:\u001b[91m 1.2837361296017964 \u001b[0m(+0.010137220223744636)\n",
      "     | > avg_loss_1:\u001b[92m 30.6327387491862 \u001b[0m(-1.1889686584472656)\n",
      "\n",
      " > BEST MODEL : /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1/best_model_1000225.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 7/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:41:05) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:41:06 -- STEP: 0/32 -- GLOBAL_STEP: 1000225\u001b[0m\n",
      "     | > loss_disc: 3.004987955093384  (3.004987955093384)\n",
      "     | > loss_disc_real_0: 0.2543531060218811  (0.2543531060218811)\n",
      "     | > loss_disc_real_1: 0.23232890665531158  (0.23232890665531158)\n",
      "     | > loss_disc_real_2: 0.31144171953201294  (0.31144171953201294)\n",
      "     | > loss_disc_real_3: 0.2670307457447052  (0.2670307457447052)\n",
      "     | > loss_disc_real_4: 0.28627458214759827  (0.28627458214759827)\n",
      "     | > loss_disc_real_5: 0.2579580843448639  (0.2579580843448639)\n",
      "     | > loss_0: 3.004987955093384  (3.004987955093384)\n",
      "     | > grad_norm_0: tensor(1.3573, device='cuda:0')  (tensor(1.3573, device='cuda:0'))\n",
      "     | > loss_gen: 1.380934476852417  (1.380934476852417)\n",
      "     | > loss_kl: 3.6417148113250732  (3.6417148113250732)\n",
      "     | > loss_feat: 0.11561083793640137  (0.11561083793640137)\n",
      "     | > loss_mel: 21.56520652770996  (21.56520652770996)\n",
      "     | > loss_duration: 1.2032297849655151  (1.2032297849655151)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 27.906696319580078  (27.906696319580078)\n",
      "     | > grad_norm_1: tensor(371.5889, device='cuda:0')  (tensor(371.5889, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019982506561132978 \n",
      "     | > current_lr_1: 0.00019982506561132978 \n",
      "     | > step_time: 0.5259  (0.5258965492248535)\n",
      "     | > loader_time: 0.3261  (0.3261406421661377)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:41:16 -- STEP: 25/32 -- GLOBAL_STEP: 1000250\u001b[0m\n",
      "     | > loss_disc: 2.9107041358947754  (2.9486232089996336)\n",
      "     | > loss_disc_real_0: 0.23418426513671875  (0.2430580335855484)\n",
      "     | > loss_disc_real_1: 0.20833644270896912  (0.24887344479560852)\n",
      "     | > loss_disc_real_2: 0.17076857388019562  (0.2449487715959549)\n",
      "     | > loss_disc_real_3: 0.18066345155239105  (0.2487698394060135)\n",
      "     | > loss_disc_real_4: 0.17414547502994537  (0.24616496741771698)\n",
      "     | > loss_disc_real_5: 0.1776999682188034  (0.24817283809185028)\n",
      "     | > loss_0: 2.9107041358947754  (2.9486232089996336)\n",
      "     | > grad_norm_0: tensor(3.1285, device='cuda:0')  (tensor(2.4997, device='cuda:0'))\n",
      "     | > loss_gen: 1.5575027465820312  (1.6036325550079347)\n",
      "     | > loss_kl: 3.461790084838867  (3.480578022003174)\n",
      "     | > loss_feat: 1.7411890029907227  (0.9346233063936233)\n",
      "     | > loss_mel: 24.878524780273438  (23.778636627197265)\n",
      "     | > loss_duration: 1.5818054676055908  (3.068570532798767)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 33.2208137512207  (32.86604103088379)\n",
      "     | > grad_norm_1: tensor(124.3196, device='cuda:0')  (tensor(137.9059, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019982506561132978 \n",
      "     | > current_lr_1: 0.00019982506561132978 \n",
      "     | > step_time: 0.3866  (0.3892708873748779)\n",
      "     | > loader_time: 0.0035  (0.0035591888427734374)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.9904427528381348  (2.9904427528381348)\n",
      "     | > loss_disc_real_0: 0.2036646455526352  (0.2036646455526352)\n",
      "     | > loss_disc_real_1: 0.2956775724887848  (0.2956775724887848)\n",
      "     | > loss_disc_real_2: 0.2928743362426758  (0.2928743362426758)\n",
      "     | > loss_disc_real_3: 0.28372621536254883  (0.28372621536254883)\n",
      "     | > loss_disc_real_4: 0.26849836111068726  (0.26849836111068726)\n",
      "     | > loss_disc_real_5: 0.2466055154800415  (0.2466055154800415)\n",
      "     | > loss_0: 2.9904427528381348  (2.9904427528381348)\n",
      "     | > loss_gen: 1.6230194568634033  (1.6230194568634033)\n",
      "     | > loss_kl: 3.6855316162109375  (3.6855316162109375)\n",
      "     | > loss_feat: 0.7513460516929626  (0.7513460516929626)\n",
      "     | > loss_mel: 20.881851196289062  (20.881851196289062)\n",
      "     | > loss_duration: 1.4715924263000488  (1.4715924263000488)\n",
      "     | > loss_1: 28.413341522216797  (28.413341522216797)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 3.0251030921936035  (3.0251030921936035)\n",
      "     | > loss_disc_real_0: 0.21681706607341766  (0.21681706607341766)\n",
      "     | > loss_disc_real_1: 0.30949556827545166  (0.30949556827545166)\n",
      "     | > loss_disc_real_2: 0.2996075451374054  (0.2996075451374054)\n",
      "     | > loss_disc_real_3: 0.30025696754455566  (0.30025696754455566)\n",
      "     | > loss_disc_real_4: 0.27623850107192993  (0.27623850107192993)\n",
      "     | > loss_disc_real_5: 0.27534016966819763  (0.27534016966819763)\n",
      "     | > loss_0: 3.0251030921936035  (3.0251030921936035)\n",
      "     | > loss_gen: 1.6749496459960938  (1.6749496459960938)\n",
      "     | > loss_kl: 4.157696723937988  (4.157696723937988)\n",
      "     | > loss_feat: 0.28035441040992737  (0.28035441040992737)\n",
      "     | > loss_mel: 30.618438720703125  (30.618438720703125)\n",
      "     | > loss_duration: 1.3531290292739868  (1.3531290292739868)\n",
      "     | > loss_1: 38.08456802368164  (38.08456802368164)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 3.0300118923187256  (3.0275574922561646)\n",
      "     | > loss_disc_real_0: 0.20193839073181152  (0.2093777284026146)\n",
      "     | > loss_disc_real_1: 0.31150057911872864  (0.31049807369709015)\n",
      "     | > loss_disc_real_2: 0.29963749647140503  (0.2996225208044052)\n",
      "     | > loss_disc_real_3: 0.3028239905834198  (0.30154047906398773)\n",
      "     | > loss_disc_real_4: 0.2752144932746887  (0.2757264971733093)\n",
      "     | > loss_disc_real_5: 0.27127647399902344  (0.27330832183361053)\n",
      "     | > loss_0: 3.0300118923187256  (3.0275574922561646)\n",
      "     | > loss_gen: 1.6579041481018066  (1.6664268970489502)\n",
      "     | > loss_kl: 3.2142298221588135  (3.685963273048401)\n",
      "     | > loss_feat: 0.10136260092258453  (0.19085850566625595)\n",
      "     | > loss_mel: 17.775470733642578  (24.19695472717285)\n",
      "     | > loss_duration: 1.6973345279693604  (1.5252317786216736)\n",
      "     | > loss_1: 24.446300506591797  (31.26543426513672)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 3.2858359813690186  (3.113650321960449)\n",
      "     | > loss_disc_real_0: 0.10778289288282394  (0.17551278322935104)\n",
      "     | > loss_disc_real_1: 0.22472262382507324  (0.28190625707308453)\n",
      "     | > loss_disc_real_2: 0.2507730722427368  (0.28333937128384906)\n",
      "     | > loss_disc_real_3: 0.2454151064157486  (0.2828320215145747)\n",
      "     | > loss_disc_real_4: 0.2165263295173645  (0.25599310795466107)\n",
      "     | > loss_disc_real_5: 0.1870959848165512  (0.24457087616125742)\n",
      "     | > loss_0: 3.2858359813690186  (3.113650321960449)\n",
      "     | > loss_gen: 1.2025580406188965  (1.5118039449055989)\n",
      "     | > loss_kl: 4.046238899230957  (3.8060551484425864)\n",
      "     | > loss_feat: 1.4570167064666748  (0.6129112392663956)\n",
      "     | > loss_mel: 24.195749282836914  (24.196552912394207)\n",
      "     | > loss_duration: 0.8951780200004578  (1.3152138590812683)\n",
      "     | > loss_1: 31.796741485595703  (31.44253667195638)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 2.9472861289978027  (3.0720592737197876)\n",
      "     | > loss_disc_real_0: 0.19132748246192932  (0.1794664580374956)\n",
      "     | > loss_disc_real_1: 0.269610196352005  (0.27883224189281464)\n",
      "     | > loss_disc_real_2: 0.2910875082015991  (0.2852764055132866)\n",
      "     | > loss_disc_real_3: 0.29357296228408813  (0.28551725670695305)\n",
      "     | > loss_disc_real_4: 0.2657109200954437  (0.2584225609898567)\n",
      "     | > loss_disc_real_5: 0.2657315135002136  (0.24986103549599648)\n",
      "     | > loss_0: 2.9472861289978027  (3.0720592737197876)\n",
      "     | > loss_gen: 1.6509926319122314  (1.546601116657257)\n",
      "     | > loss_kl: 3.584397315979004  (3.7506406903266907)\n",
      "     | > loss_feat: 0.5537367463111877  (0.5981176160275936)\n",
      "     | > loss_mel: 22.8804931640625  (23.86753797531128)\n",
      "     | > loss_duration: 1.1414330005645752  (1.271768644452095)\n",
      "     | > loss_1: 29.811054229736328  (31.034666061401367)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 3.022911548614502  (3.0622297286987306)\n",
      "     | > loss_disc_real_0: 0.1592240333557129  (0.17541797310113907)\n",
      "     | > loss_disc_real_1: 0.23666490614414215  (0.27039877474308016)\n",
      "     | > loss_disc_real_2: 0.22889243066310883  (0.27399961054325106)\n",
      "     | > loss_disc_real_3: 0.23828352987766266  (0.27607051134109495)\n",
      "     | > loss_disc_real_4: 0.20055758953094482  (0.24684956669807434)\n",
      "     | > loss_disc_real_5: 0.19021210074424744  (0.23793124854564668)\n",
      "     | > loss_0: 3.022911548614502  (3.0622297286987306)\n",
      "     | > loss_gen: 1.3822263479232788  (1.5137261629104615)\n",
      "     | > loss_kl: 3.5661957263946533  (3.713751697540283)\n",
      "     | > loss_feat: 1.1769969463348389  (0.7138934820890427)\n",
      "     | > loss_mel: 22.308147430419922  (23.55565986633301)\n",
      "     | > loss_duration: 1.4239619970321655  (1.302207314968109)\n",
      "     | > loss_1: 29.857528686523438  (30.79923858642578)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 3.025768280029297  (3.056152820587158)\n",
      "     | > loss_disc_real_0: 0.200461745262146  (0.17959193512797356)\n",
      "     | > loss_disc_real_1: 0.3067098557949066  (0.27645062158505124)\n",
      "     | > loss_disc_real_2: 0.29891419410705566  (0.2781520411372185)\n",
      "     | > loss_disc_real_3: 0.30246827006340027  (0.2804701377948125)\n",
      "     | > loss_disc_real_4: 0.276724249124527  (0.25182868043581647)\n",
      "     | > loss_disc_real_5: 0.2757466435432434  (0.24423381437857947)\n",
      "     | > loss_0: 3.025768280029297  (3.056152820587158)\n",
      "     | > loss_gen: 1.6601625680923462  (1.5381322304407756)\n",
      "     | > loss_kl: 3.6086175441741943  (3.696229338645935)\n",
      "     | > loss_feat: 0.1954280436038971  (0.6274825756748518)\n",
      "     | > loss_mel: 22.367591857910156  (23.357648531595867)\n",
      "     | > loss_duration: 1.1601022481918335  (1.2785231371720631)\n",
      "     | > loss_1: 28.99190330505371  (30.498016039530437)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0023780266443888345 \u001b[0m(-3.9617220560709925e-05)\n",
      "     | > avg_loss_disc:\u001b[91m 3.056152820587158 \u001b[0m(+0.14688293139139796)\n",
      "     | > avg_loss_disc_real_0:\u001b[92m 0.17959193512797356 \u001b[0m(-0.044358182698488235)\n",
      "     | > avg_loss_disc_real_1:\u001b[91m 0.27645062158505124 \u001b[0m(+0.08998917043209079)\n",
      "     | > avg_loss_disc_real_2:\u001b[92m 0.2781520411372185 \u001b[0m(-0.019440817336241423)\n",
      "     | > avg_loss_disc_real_3:\u001b[91m 0.2804701377948125 \u001b[0m(+0.03190614034732181)\n",
      "     | > avg_loss_disc_real_4:\u001b[92m 0.25182868043581647 \u001b[0m(-0.011962416271368626)\n",
      "     | > avg_loss_disc_real_5:\u001b[91m 0.24423381437857947 \u001b[0m(+0.015787608921527863)\n",
      "     | > avg_loss_0:\u001b[91m 3.056152820587158 \u001b[0m(+0.14688293139139796)\n",
      "     | > avg_loss_gen:\u001b[92m 1.5381322304407756 \u001b[0m(-0.023912469546000015)\n",
      "     | > avg_loss_kl:\u001b[91m 3.696229338645935 \u001b[0m(+0.229978839556376)\n",
      "     | > avg_loss_feat:\u001b[92m 0.6274825756748518 \u001b[0m(-0.11834737285971642)\n",
      "     | > avg_loss_mel:\u001b[92m 23.357648531595867 \u001b[0m(-0.21722952524820727)\n",
      "     | > avg_loss_duration:\u001b[92m 1.2785231371720631 \u001b[0m(-0.005212992429733276)\n",
      "     | > avg_loss_1:\u001b[92m 30.498016039530437 \u001b[0m(-0.13472270965576172)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 8/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:41:22) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:41:30 -- STEP: 18/32 -- GLOBAL_STEP: 1000275\u001b[0m\n",
      "     | > loss_disc: 2.896718740463257  (3.0774268176820545)\n",
      "     | > loss_disc_real_0: 0.2611241936683655  (0.27330398394001854)\n",
      "     | > loss_disc_real_1: 0.21130366623401642  (0.27658461613787544)\n",
      "     | > loss_disc_real_2: 0.20838966965675354  (0.28635971496502566)\n",
      "     | > loss_disc_real_3: 0.20358328521251678  (0.27127376364337075)\n",
      "     | > loss_disc_real_4: 0.2280571311712265  (0.2779991899927457)\n",
      "     | > loss_disc_real_5: 0.2675177752971649  (0.2829056398736106)\n",
      "     | > loss_0: 2.896718740463257  (3.0774268176820545)\n",
      "     | > grad_norm_0: tensor(1.4716, device='cuda:0')  (tensor(5.4565, device='cuda:0'))\n",
      "     | > loss_gen: 1.390794277191162  (1.7352637184990778)\n",
      "     | > loss_kl: 3.5866761207580566  (3.4509974585639105)\n",
      "     | > loss_feat: 0.8547067046165466  (0.9609731270207299)\n",
      "     | > loss_mel: 25.983287811279297  (24.572851816813152)\n",
      "     | > loss_duration: 1.291580080986023  (2.943094882700178)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 33.1070442199707  (33.6631809870402)\n",
      "     | > grad_norm_1: tensor(121.2481, device='cuda:0')  (tensor(179.2255, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019980008747812837 \n",
      "     | > current_lr_1: 0.00019980008747812837 \n",
      "     | > step_time: 0.3846  (0.3925167719523112)\n",
      "     | > loader_time: 0.0033  (0.0035044617123074)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 3.0057973861694336  (3.0057973861694336)\n",
      "     | > loss_disc_real_0: 0.2029632329940796  (0.2029632329940796)\n",
      "     | > loss_disc_real_1: 0.2002967894077301  (0.2002967894077301)\n",
      "     | > loss_disc_real_2: 0.2333889603614807  (0.2333889603614807)\n",
      "     | > loss_disc_real_3: 0.22044269740581512  (0.22044269740581512)\n",
      "     | > loss_disc_real_4: 0.23721030354499817  (0.23721030354499817)\n",
      "     | > loss_disc_real_5: 0.23193402588367462  (0.23193402588367462)\n",
      "     | > loss_0: 3.0057973861694336  (3.0057973861694336)\n",
      "     | > loss_gen: 1.3395462036132812  (1.3395462036132812)\n",
      "     | > loss_kl: 3.503066301345825  (3.503066301345825)\n",
      "     | > loss_feat: 0.44670259952545166  (0.44670259952545166)\n",
      "     | > loss_mel: 21.873247146606445  (21.873247146606445)\n",
      "     | > loss_duration: 1.460248589515686  (1.460248589515686)\n",
      "     | > loss_1: 28.622812271118164  (28.622812271118164)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.9588770866394043  (2.9588770866394043)\n",
      "     | > loss_disc_real_0: 0.1673825979232788  (0.1673825979232788)\n",
      "     | > loss_disc_real_1: 0.19963175058364868  (0.19963175058364868)\n",
      "     | > loss_disc_real_2: 0.23174335062503815  (0.23174335062503815)\n",
      "     | > loss_disc_real_3: 0.2205733060836792  (0.2205733060836792)\n",
      "     | > loss_disc_real_4: 0.22598682343959808  (0.22598682343959808)\n",
      "     | > loss_disc_real_5: 0.22733399271965027  (0.22733399271965027)\n",
      "     | > loss_0: 2.9588770866394043  (2.9588770866394043)\n",
      "     | > loss_gen: 1.334869146347046  (1.334869146347046)\n",
      "     | > loss_kl: 4.053879737854004  (4.053879737854004)\n",
      "     | > loss_feat: 0.4872298836708069  (0.4872298836708069)\n",
      "     | > loss_mel: 18.646995544433594  (18.646995544433594)\n",
      "     | > loss_duration: 1.3664772510528564  (1.3664772510528564)\n",
      "     | > loss_1: 25.88945198059082  (25.88945198059082)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 2.9507226943969727  (2.9547998905181885)\n",
      "     | > loss_disc_real_0: 0.17543578147888184  (0.17140918970108032)\n",
      "     | > loss_disc_real_1: 0.20083443820476532  (0.200233094394207)\n",
      "     | > loss_disc_real_2: 0.23114325106143951  (0.23144330084323883)\n",
      "     | > loss_disc_real_3: 0.21522225439548492  (0.21789778023958206)\n",
      "     | > loss_disc_real_4: 0.23001310229301453  (0.2279999628663063)\n",
      "     | > loss_disc_real_5: 0.22063465416431427  (0.22398432344198227)\n",
      "     | > loss_0: 2.9507226943969727  (2.9547998905181885)\n",
      "     | > loss_gen: 1.3454142808914185  (1.3401417136192322)\n",
      "     | > loss_kl: 3.2721850872039795  (3.6630324125289917)\n",
      "     | > loss_feat: 0.4931197762489319  (0.4901748299598694)\n",
      "     | > loss_mel: 21.409360885620117  (20.028178215026855)\n",
      "     | > loss_duration: 1.657170295715332  (1.5118237733840942)\n",
      "     | > loss_1: 28.177249908447266  (27.033350944519043)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 2.8062856197357178  (2.9052951335906982)\n",
      "     | > loss_disc_real_0: 0.13165558874607086  (0.15815798938274384)\n",
      "     | > loss_disc_real_1: 0.16985248029232025  (0.1901062230269114)\n",
      "     | > loss_disc_real_2: 0.21981513500213623  (0.2275672455628713)\n",
      "     | > loss_disc_real_3: 0.1722055971622467  (0.20266705254713693)\n",
      "     | > loss_disc_real_4: 0.19683624804019928  (0.21761205792427063)\n",
      "     | > loss_disc_real_5: 0.19393615424633026  (0.2139682670434316)\n",
      "     | > loss_0: 2.8062856197357178  (2.9052951335906982)\n",
      "     | > loss_gen: 1.3000659942626953  (1.3267831405003865)\n",
      "     | > loss_kl: 3.8994455337524414  (3.7418367862701416)\n",
      "     | > loss_feat: 1.5212407112121582  (0.8338634570439657)\n",
      "     | > loss_mel: 27.134580612182617  (22.396979014078777)\n",
      "     | > loss_duration: 0.8845553398132324  (1.3027342955271404)\n",
      "     | > loss_1: 34.73988723754883  (29.602196375528973)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 2.986149311065674  (2.925508677959442)\n",
      "     | > loss_disc_real_0: 0.19510947167873383  (0.16739585995674133)\n",
      "     | > loss_disc_real_1: 0.21228095889091492  (0.1956499069929123)\n",
      "     | > loss_disc_real_2: 0.23461388051509857  (0.22932890430092812)\n",
      "     | > loss_disc_real_3: 0.22614765167236328  (0.20853720232844353)\n",
      "     | > loss_disc_real_4: 0.24093927443027496  (0.2234438620507717)\n",
      "     | > loss_disc_real_5: 0.2400008887052536  (0.2204764224588871)\n",
      "     | > loss_0: 2.986149311065674  (2.925508677959442)\n",
      "     | > loss_gen: 1.3734216690063477  (1.3384427726268768)\n",
      "     | > loss_kl: 3.483607769012451  (3.677279531955719)\n",
      "     | > loss_feat: 0.26054373383522034  (0.6905335262417793)\n",
      "     | > loss_mel: 20.474769592285156  (21.91642665863037)\n",
      "     | > loss_duration: 1.1437355279922485  (1.2629846036434174)\n",
      "     | > loss_1: 26.7360782623291  (28.885666847229004)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 2.9490749835968018  (2.930221939086914)\n",
      "     | > loss_disc_real_0: 0.15815582871437073  (0.16554785370826722)\n",
      "     | > loss_disc_real_1: 0.19610176980495453  (0.19574027955532075)\n",
      "     | > loss_disc_real_2: 0.2244364470243454  (0.22835041284561158)\n",
      "     | > loss_disc_real_3: 0.18471971154212952  (0.20377370417118074)\n",
      "     | > loss_disc_real_4: 0.1962910294532776  (0.21801329553127288)\n",
      "     | > loss_disc_real_5: 0.19850237667560577  (0.21608161330223083)\n",
      "     | > loss_0: 2.9490749835968018  (2.930221939086914)\n",
      "     | > loss_gen: 1.2608299255371094  (1.3229202032089233)\n",
      "     | > loss_kl: 3.0523152351379395  (3.552286672592163)\n",
      "     | > loss_feat: 0.8800557851791382  (0.7284379780292511)\n",
      "     | > loss_mel: 20.971010208129883  (21.727343368530274)\n",
      "     | > loss_duration: 1.4084358215332031  (1.2920748472213746)\n",
      "     | > loss_1: 27.572647094726562  (28.623062896728516)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 2.9421546459198  (2.9322107235590615)\n",
      "     | > loss_disc_real_0: 0.1960395872592926  (0.17062980930010477)\n",
      "     | > loss_disc_real_1: 0.2078109085559845  (0.19775205105543137)\n",
      "     | > loss_disc_real_2: 0.2320518046617508  (0.22896731148163477)\n",
      "     | > loss_disc_real_3: 0.21151088178157806  (0.2050632337729136)\n",
      "     | > loss_disc_real_4: 0.2263903021812439  (0.21940946330626807)\n",
      "     | > loss_disc_real_5: 0.21995002031326294  (0.21672634780406952)\n",
      "     | > loss_0: 2.9421546459198  (2.9322107235590615)\n",
      "     | > loss_gen: 1.363328218460083  (1.32965487241745)\n",
      "     | > loss_kl: 3.37734317779541  (3.523129423459371)\n",
      "     | > loss_feat: 0.5313193202018738  (0.6955848683913549)\n",
      "     | > loss_mel: 22.819599151611328  (21.90938599904378)\n",
      "     | > loss_duration: 1.1527531147003174  (1.268854558467865)\n",
      "     | > loss_1: 29.24434471130371  (28.726609865824383)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.002464850743611654 \u001b[0m(+8.68240992228193e-05)\n",
      "     | > avg_loss_disc:\u001b[92m 2.9322107235590615 \u001b[0m(-0.12394209702809666)\n",
      "     | > avg_loss_disc_real_0:\u001b[92m 0.17062980930010477 \u001b[0m(-0.008962125827868789)\n",
      "     | > avg_loss_disc_real_1:\u001b[92m 0.19775205105543137 \u001b[0m(-0.07869857052961987)\n",
      "     | > avg_loss_disc_real_2:\u001b[92m 0.22896731148163477 \u001b[0m(-0.04918472965558371)\n",
      "     | > avg_loss_disc_real_3:\u001b[92m 0.2050632337729136 \u001b[0m(-0.0754069040218989)\n",
      "     | > avg_loss_disc_real_4:\u001b[92m 0.21940946330626807 \u001b[0m(-0.0324192171295484)\n",
      "     | > avg_loss_disc_real_5:\u001b[92m 0.21672634780406952 \u001b[0m(-0.027507466574509948)\n",
      "     | > avg_loss_0:\u001b[92m 2.9322107235590615 \u001b[0m(-0.12394209702809666)\n",
      "     | > avg_loss_gen:\u001b[92m 1.32965487241745 \u001b[0m(-0.20847735802332568)\n",
      "     | > avg_loss_kl:\u001b[92m 3.523129423459371 \u001b[0m(-0.17309991518656398)\n",
      "     | > avg_loss_feat:\u001b[91m 0.6955848683913549 \u001b[0m(+0.06810229271650314)\n",
      "     | > avg_loss_mel:\u001b[92m 21.90938599904378 \u001b[0m(-1.4482625325520857)\n",
      "     | > avg_loss_duration:\u001b[92m 1.268854558467865 \u001b[0m(-0.009668578704198127)\n",
      "     | > avg_loss_1:\u001b[92m 28.726609865824383 \u001b[0m(-1.7714061737060547)\n",
      "\n",
      " > BEST MODEL : /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1/best_model_1000289.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 9/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:41:42) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:41:48 -- STEP: 11/32 -- GLOBAL_STEP: 1000300\u001b[0m\n",
      "     | > loss_disc: 2.8307363986968994  (2.9432595643130215)\n",
      "     | > loss_disc_real_0: 0.23796014487743378  (0.2379658411849629)\n",
      "     | > loss_disc_real_1: 0.26695898175239563  (0.26071669974110345)\n",
      "     | > loss_disc_real_2: 0.24546486139297485  (0.2511845989660783)\n",
      "     | > loss_disc_real_3: 0.2604740858078003  (0.2666909843683243)\n",
      "     | > loss_disc_real_4: 0.25994282960891724  (0.26729237085038965)\n",
      "     | > loss_disc_real_5: 0.25698304176330566  (0.25363856283101166)\n",
      "     | > loss_0: 2.8307363986968994  (2.9432595643130215)\n",
      "     | > grad_norm_0: tensor(1.3800, device='cuda:0')  (tensor(1.9140, device='cuda:0'))\n",
      "     | > loss_gen: 1.5397452116012573  (1.6414571783759377)\n",
      "     | > loss_kl: 3.1238515377044678  (3.4373865127563477)\n",
      "     | > loss_feat: 1.1187664270401  (0.8150636445392262)\n",
      "     | > loss_mel: 20.73832130432129  (22.76845221085982)\n",
      "     | > loss_duration: 1.9400925636291504  (4.00836845961484)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 28.460777282714844  (32.67072868347168)\n",
      "     | > grad_norm_1: tensor(129.5682, device='cuda:0')  (tensor(119.2582, device='cuda:0'))\n",
      "     | > current_lr_0: 0.0001997751124671936 \n",
      "     | > current_lr_1: 0.0001997751124671936 \n",
      "     | > step_time: 0.3939  (0.4132918661290949)\n",
      "     | > loader_time: 0.0028  (0.0035093047402121806)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.970571279525757  (2.970571279525757)\n",
      "     | > loss_disc_real_0: 0.2549435794353485  (0.2549435794353485)\n",
      "     | > loss_disc_real_1: 0.2555844187736511  (0.2555844187736511)\n",
      "     | > loss_disc_real_2: 0.2419404536485672  (0.2419404536485672)\n",
      "     | > loss_disc_real_3: 0.22621938586235046  (0.22621938586235046)\n",
      "     | > loss_disc_real_4: 0.23511600494384766  (0.23511600494384766)\n",
      "     | > loss_disc_real_5: 0.2277601659297943  (0.2277601659297943)\n",
      "     | > loss_0: 2.970571279525757  (2.970571279525757)\n",
      "     | > loss_gen: 1.4759202003479004  (1.4759202003479004)\n",
      "     | > loss_kl: 3.8477632999420166  (3.8477632999420166)\n",
      "     | > loss_feat: 0.6326943635940552  (0.6326943635940552)\n",
      "     | > loss_mel: 23.067520141601562  (23.067520141601562)\n",
      "     | > loss_duration: 1.455918550491333  (1.455918550491333)\n",
      "     | > loss_1: 30.479816436767578  (30.479816436767578)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.985045909881592  (2.985045909881592)\n",
      "     | > loss_disc_real_0: 0.2491150200366974  (0.2491150200366974)\n",
      "     | > loss_disc_real_1: 0.26249122619628906  (0.26249122619628906)\n",
      "     | > loss_disc_real_2: 0.2541888356208801  (0.2541888356208801)\n",
      "     | > loss_disc_real_3: 0.24117247760295868  (0.24117247760295868)\n",
      "     | > loss_disc_real_4: 0.24600006639957428  (0.24600006639957428)\n",
      "     | > loss_disc_real_5: 0.24564915895462036  (0.24564915895462036)\n",
      "     | > loss_0: 2.985045909881592  (2.985045909881592)\n",
      "     | > loss_gen: 1.515628695487976  (1.515628695487976)\n",
      "     | > loss_kl: 4.044865608215332  (4.044865608215332)\n",
      "     | > loss_feat: 0.27346718311309814  (0.27346718311309814)\n",
      "     | > loss_mel: 29.0877742767334  (29.0877742767334)\n",
      "     | > loss_duration: 1.3502963781356812  (1.3502963781356812)\n",
      "     | > loss_1: 36.272029876708984  (36.272029876708984)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 2.9739131927490234  (2.9794795513153076)\n",
      "     | > loss_disc_real_0: 0.23174020648002625  (0.24042761325836182)\n",
      "     | > loss_disc_real_1: 0.2670179605484009  (0.26475459337234497)\n",
      "     | > loss_disc_real_2: 0.24992303550243378  (0.25205593556165695)\n",
      "     | > loss_disc_real_3: 0.23504985868930817  (0.23811116814613342)\n",
      "     | > loss_disc_real_4: 0.24222737550735474  (0.2441137209534645)\n",
      "     | > loss_disc_real_5: 0.23991656303405762  (0.242782860994339)\n",
      "     | > loss_0: 2.9739131927490234  (2.9794795513153076)\n",
      "     | > loss_gen: 1.4963260889053345  (1.5059773921966553)\n",
      "     | > loss_kl: 3.250075340270996  (3.647470474243164)\n",
      "     | > loss_feat: 0.4081686735153198  (0.340817928314209)\n",
      "     | > loss_mel: 22.543739318847656  (25.815756797790527)\n",
      "     | > loss_duration: 1.7069780826568604  (1.5286372303962708)\n",
      "     | > loss_1: 29.405288696289062  (32.83865928649902)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 3.016954183578491  (2.9919710954030356)\n",
      "     | > loss_disc_real_0: 0.24468424916267395  (0.24184649189313254)\n",
      "     | > loss_disc_real_1: 0.2771986424922943  (0.26890260974566144)\n",
      "     | > loss_disc_real_2: 0.25550445914268494  (0.25320544342199963)\n",
      "     | > loss_disc_real_3: 0.2437969148159027  (0.24000641703605652)\n",
      "     | > loss_disc_real_4: 0.24695593118667603  (0.245061124364535)\n",
      "     | > loss_disc_real_5: 0.2481681853532791  (0.2445779691139857)\n",
      "     | > loss_0: 3.016954183578491  (2.9919710954030356)\n",
      "     | > loss_gen: 1.5032559633255005  (1.5050702492396038)\n",
      "     | > loss_kl: 3.728872537612915  (3.6746044953664145)\n",
      "     | > loss_feat: 0.1788560450077057  (0.2868306338787079)\n",
      "     | > loss_mel: 21.44454002380371  (24.358684539794922)\n",
      "     | > loss_duration: 0.8816057443618774  (1.3129600683848064)\n",
      "     | > loss_1: 27.73712921142578  (31.13814926147461)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 3.0012083053588867  (2.9942803978919983)\n",
      "     | > loss_disc_real_0: 0.24861928820610046  (0.2435396909713745)\n",
      "     | > loss_disc_real_1: 0.2748585045337677  (0.270391583442688)\n",
      "     | > loss_disc_real_2: 0.2572331726551056  (0.2542123757302761)\n",
      "     | > loss_disc_real_3: 0.24439075589179993  (0.24110250174999237)\n",
      "     | > loss_disc_real_4: 0.2478959709405899  (0.24576983600854874)\n",
      "     | > loss_disc_real_5: 0.2498205304145813  (0.2458886094391346)\n",
      "     | > loss_0: 3.0012083053588867  (2.9942803978919983)\n",
      "     | > loss_gen: 1.523666501045227  (1.5097193121910095)\n",
      "     | > loss_kl: 3.2780580520629883  (3.575467884540558)\n",
      "     | > loss_feat: 0.06380364298820496  (0.23107388615608215)\n",
      "     | > loss_mel: 21.97193145751953  (23.761996269226074)\n",
      "     | > loss_duration: 1.138744592666626  (1.2694061994552612)\n",
      "     | > loss_1: 27.97620391845703  (30.347662925720215)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 3.0234642028808594  (3.0001171588897706)\n",
      "     | > loss_disc_real_0: 0.16764459013938904  (0.2283606708049774)\n",
      "     | > loss_disc_real_1: 0.22419679164886475  (0.26115262508392334)\n",
      "     | > loss_disc_real_2: 0.22112536430358887  (0.24759497344493867)\n",
      "     | > loss_disc_real_3: 0.1824600100517273  (0.22937400341033937)\n",
      "     | > loss_disc_real_4: 0.19181908667087555  (0.2349796861410141)\n",
      "     | > loss_disc_real_5: 0.18017379939556122  (0.23274564743041992)\n",
      "     | > loss_0: 3.0234642028808594  (3.0001171588897706)\n",
      "     | > loss_gen: 1.2350589036941528  (1.4547872304916383)\n",
      "     | > loss_kl: 3.1789538860321045  (3.496165084838867)\n",
      "     | > loss_feat: 1.2514533996582031  (0.43514978885650635)\n",
      "     | > loss_mel: 22.29174041748047  (23.467945098876953)\n",
      "     | > loss_duration: 1.4047882556915283  (1.2964826107025147)\n",
      "     | > loss_1: 29.361997604370117  (30.150529861450195)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 2.8989737033843994  (2.983259916305542)\n",
      "     | > loss_disc_real_0: 0.2124951183795929  (0.22571641206741333)\n",
      "     | > loss_disc_real_1: 0.25332310795783997  (0.2598477055629094)\n",
      "     | > loss_disc_real_2: 0.24038633704185486  (0.24639353404442468)\n",
      "     | > loss_disc_real_3: 0.22837387025356293  (0.22920731455087662)\n",
      "     | > loss_disc_real_4: 0.23017680644989014  (0.23417920619249344)\n",
      "     | > loss_disc_real_5: 0.2330894023180008  (0.2328029399116834)\n",
      "     | > loss_0: 2.8989737033843994  (2.983259916305542)\n",
      "     | > loss_gen: 1.5154372453689575  (1.4648955663045247)\n",
      "     | > loss_kl: 3.0539700984954834  (3.4224659204483032)\n",
      "     | > loss_feat: 0.8127486109733582  (0.49808292587598163)\n",
      "     | > loss_mel: 22.745832443237305  (23.34759298960368)\n",
      "     | > loss_duration: 1.144749641418457  (1.2711937824885051)\n",
      "     | > loss_1: 29.27273941040039  (30.004231452941895)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0023746887842814126 \u001b[0m(-9.016195933024117e-05)\n",
      "     | > avg_loss_disc:\u001b[91m 2.983259916305542 \u001b[0m(+0.051049192746480454)\n",
      "     | > avg_loss_disc_real_0:\u001b[91m 0.22571641206741333 \u001b[0m(+0.05508660276730856)\n",
      "     | > avg_loss_disc_real_1:\u001b[91m 0.2598477055629094 \u001b[0m(+0.06209565450747806)\n",
      "     | > avg_loss_disc_real_2:\u001b[91m 0.24639353404442468 \u001b[0m(+0.017426222562789917)\n",
      "     | > avg_loss_disc_real_3:\u001b[91m 0.22920731455087662 \u001b[0m(+0.024144080777963012)\n",
      "     | > avg_loss_disc_real_4:\u001b[91m 0.23417920619249344 \u001b[0m(+0.014769742886225373)\n",
      "     | > avg_loss_disc_real_5:\u001b[91m 0.2328029399116834 \u001b[0m(+0.01607659210761389)\n",
      "     | > avg_loss_0:\u001b[91m 2.983259916305542 \u001b[0m(+0.051049192746480454)\n",
      "     | > avg_loss_gen:\u001b[91m 1.4648955663045247 \u001b[0m(+0.13524069388707471)\n",
      "     | > avg_loss_kl:\u001b[92m 3.4224659204483032 \u001b[0m(-0.10066350301106786)\n",
      "     | > avg_loss_feat:\u001b[92m 0.49808292587598163 \u001b[0m(-0.19750194251537329)\n",
      "     | > avg_loss_mel:\u001b[91m 23.34759298960368 \u001b[0m(+1.4382069905598982)\n",
      "     | > avg_loss_duration:\u001b[91m 1.2711937824885051 \u001b[0m(+0.0023392240206401294)\n",
      "     | > avg_loss_1:\u001b[91m 30.004231452941895 \u001b[0m(+1.2776215871175118)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 10/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:42:00) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:42:03 -- STEP: 4/32 -- GLOBAL_STEP: 1000325\u001b[0m\n",
      "     | > loss_disc: 2.935298442840576  (2.8930066227912903)\n",
      "     | > loss_disc_real_0: 0.3087009787559509  (0.22911525890231133)\n",
      "     | > loss_disc_real_1: 0.2789049744606018  (0.2517285421490669)\n",
      "     | > loss_disc_real_2: 0.27336087822914124  (0.24931176006793976)\n",
      "     | > loss_disc_real_3: 0.28265827894210815  (0.24453239142894745)\n",
      "     | > loss_disc_real_4: 0.28257277607917786  (0.23999875783920288)\n",
      "     | > loss_disc_real_5: 0.2719707489013672  (0.2370583526790142)\n",
      "     | > loss_0: 2.935298442840576  (2.8930066227912903)\n",
      "     | > grad_norm_0: tensor(2.2086, device='cuda:0')  (tensor(2.0457, device='cuda:0'))\n",
      "     | > loss_gen: 1.7238073348999023  (1.648240566253662)\n",
      "     | > loss_kl: 2.930959463119507  (3.558816909790039)\n",
      "     | > loss_feat: 0.6891348361968994  (1.087882250547409)\n",
      "     | > loss_mel: 19.905649185180664  (23.512739658355713)\n",
      "     | > loss_duration: 1.397395133972168  (5.674444884061813)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 26.64694595336914  (35.482123374938965)\n",
      "     | > grad_norm_1: tensor(183.5764, device='cuda:0')  (tensor(193.4859, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019975014057813518 \n",
      "     | > current_lr_1: 0.00019975014057813518 \n",
      "     | > step_time: 0.3925  (0.40182989835739136)\n",
      "     | > loader_time: 0.0049  (0.003524482250213623)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:42:13 -- STEP: 29/32 -- GLOBAL_STEP: 1000350\u001b[0m\n",
      "     | > loss_disc: 2.934488296508789  (2.9340925792167925)\n",
      "     | > loss_disc_real_0: 0.3014257550239563  (0.23742967972467685)\n",
      "     | > loss_disc_real_1: 0.2762833833694458  (0.249920790565425)\n",
      "     | > loss_disc_real_2: 0.27870434522628784  (0.24832806299472676)\n",
      "     | > loss_disc_real_3: 0.2651722729206085  (0.25052505423282756)\n",
      "     | > loss_disc_real_4: 0.2597517967224121  (0.2512099583601129)\n",
      "     | > loss_disc_real_5: 0.28539416193962097  (0.24496055522869375)\n",
      "     | > loss_0: 2.934488296508789  (2.9340925792167925)\n",
      "     | > grad_norm_0: tensor(2.8257, device='cuda:0')  (tensor(2.7050, device='cuda:0'))\n",
      "     | > loss_gen: 1.7201383113861084  (1.603301767645211)\n",
      "     | > loss_kl: 3.345304250717163  (3.424360957638971)\n",
      "     | > loss_feat: 0.717498779296875  (0.9283051583273655)\n",
      "     | > loss_mel: 22.53323745727539  (23.74979012587975)\n",
      "     | > loss_duration: 13.095464706420898  (3.487576525786827)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 41.411643981933594  (33.193334316385204)\n",
      "     | > grad_norm_1: tensor(94.5492, device='cuda:0')  (tensor(170.4929, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019975014057813518 \n",
      "     | > current_lr_1: 0.00019975014057813518 \n",
      "     | > step_time: 0.4395  (0.4028469118578681)\n",
      "     | > loader_time: 0.0033  (0.003383060981487406)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.9594881534576416  (2.9594881534576416)\n",
      "     | > loss_disc_real_0: 0.21555767953395844  (0.21555767953395844)\n",
      "     | > loss_disc_real_1: 0.2412979006767273  (0.2412979006767273)\n",
      "     | > loss_disc_real_2: 0.22965668141841888  (0.22965668141841888)\n",
      "     | > loss_disc_real_3: 0.23978734016418457  (0.23978734016418457)\n",
      "     | > loss_disc_real_4: 0.24386091530323029  (0.24386091530323029)\n",
      "     | > loss_disc_real_5: 0.21565519273281097  (0.21565519273281097)\n",
      "     | > loss_0: 2.9594881534576416  (2.9594881534576416)\n",
      "     | > loss_gen: 1.4312524795532227  (1.4312524795532227)\n",
      "     | > loss_kl: 3.4509012699127197  (3.4509012699127197)\n",
      "     | > loss_feat: 0.30938684940338135  (0.30938684940338135)\n",
      "     | > loss_mel: 21.27519416809082  (21.27519416809082)\n",
      "     | > loss_duration: 1.4824193716049194  (1.4824193716049194)\n",
      "     | > loss_1: 27.949155807495117  (27.949155807495117)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.9822394847869873  (2.9822394847869873)\n",
      "     | > loss_disc_real_0: 0.2308882772922516  (0.2308882772922516)\n",
      "     | > loss_disc_real_1: 0.24782831966876984  (0.24782831966876984)\n",
      "     | > loss_disc_real_2: 0.23301208019256592  (0.23301208019256592)\n",
      "     | > loss_disc_real_3: 0.2469947189092636  (0.2469947189092636)\n",
      "     | > loss_disc_real_4: 0.2500137686729431  (0.2500137686729431)\n",
      "     | > loss_disc_real_5: 0.24013222754001617  (0.24013222754001617)\n",
      "     | > loss_0: 2.9822394847869873  (2.9822394847869873)\n",
      "     | > loss_gen: 1.4695910215377808  (1.4695910215377808)\n",
      "     | > loss_kl: 4.0028181076049805  (4.0028181076049805)\n",
      "     | > loss_feat: 0.15965735912322998  (0.15965735912322998)\n",
      "     | > loss_mel: 20.34931755065918  (20.34931755065918)\n",
      "     | > loss_duration: 1.3870656490325928  (1.3870656490325928)\n",
      "     | > loss_1: 27.368450164794922  (27.368450164794922)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 3.1700382232666016  (3.0761388540267944)\n",
      "     | > loss_disc_real_0: 0.06969191133975983  (0.1502900943160057)\n",
      "     | > loss_disc_real_1: 0.153030663728714  (0.2004294916987419)\n",
      "     | > loss_disc_real_2: 0.17363430559635162  (0.20332319289445877)\n",
      "     | > loss_disc_real_3: 0.16596367955207825  (0.20647919923067093)\n",
      "     | > loss_disc_real_4: 0.16671134531497955  (0.20836255699396133)\n",
      "     | > loss_disc_real_5: 0.08580479770898819  (0.16296851262450218)\n",
      "     | > loss_0: 3.1700382232666016  (3.0761388540267944)\n",
      "     | > loss_gen: 0.9286288022994995  (1.1991099119186401)\n",
      "     | > loss_kl: 3.0675454139709473  (3.535181760787964)\n",
      "     | > loss_feat: 2.0440118312835693  (1.1018345952033997)\n",
      "     | > loss_mel: 25.486974716186523  (22.91814613342285)\n",
      "     | > loss_duration: 1.7073355913162231  (1.547200620174408)\n",
      "     | > loss_1: 33.2344970703125  (30.30147361755371)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 3.075307607650757  (3.0758617719014487)\n",
      "     | > loss_disc_real_0: 0.1338645964860916  (0.14481492837270102)\n",
      "     | > loss_disc_real_1: 0.17336659133434296  (0.19140852491060892)\n",
      "     | > loss_disc_real_2: 0.17634031176567078  (0.19432889918486276)\n",
      "     | > loss_disc_real_3: 0.1810089498758316  (0.19798911611239114)\n",
      "     | > loss_disc_real_4: 0.18774093687534332  (0.20148868362108865)\n",
      "     | > loss_disc_real_5: 0.12395904213190079  (0.14996535579363504)\n",
      "     | > loss_0: 3.075307607650757  (3.0758617719014487)\n",
      "     | > loss_gen: 1.1563966274261475  (1.1848721504211426)\n",
      "     | > loss_kl: 4.392751216888428  (3.821038246154785)\n",
      "     | > loss_feat: 1.8718618154525757  (1.3585103352864583)\n",
      "     | > loss_mel: 28.06205940246582  (24.632783889770508)\n",
      "     | > loss_duration: 0.8945119380950928  (1.3296377261479695)\n",
      "     | > loss_1: 36.37757873535156  (32.32684199015299)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 2.945920467376709  (3.0433764457702637)\n",
      "     | > loss_disc_real_0: 0.1877736747264862  (0.1555546149611473)\n",
      "     | > loss_disc_real_1: 0.2183607965707779  (0.19814659282565117)\n",
      "     | > loss_disc_real_2: 0.21525800228118896  (0.19956117495894432)\n",
      "     | > loss_disc_real_3: 0.22904086112976074  (0.20575205236673355)\n",
      "     | > loss_disc_real_4: 0.23747600615024567  (0.21048551425337791)\n",
      "     | > loss_disc_real_5: 0.20185311138629913  (0.16293729469180107)\n",
      "     | > loss_0: 2.945920467376709  (3.0433764457702637)\n",
      "     | > loss_gen: 1.3587071895599365  (1.228330910205841)\n",
      "     | > loss_kl: 3.7393202781677246  (3.80060875415802)\n",
      "     | > loss_feat: 0.7503697872161865  (1.2064751982688904)\n",
      "     | > loss_mel: 21.305397033691406  (23.800937175750732)\n",
      "     | > loss_duration: 1.146626591682434  (1.2838849425315857)\n",
      "     | > loss_1: 28.3004207611084  (31.320236682891846)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 3.079366683959961  (3.0505744934082033)\n",
      "     | > loss_disc_real_0: 0.0998687893152237  (0.14441744983196259)\n",
      "     | > loss_disc_real_1: 0.1383390724658966  (0.18618508875370027)\n",
      "     | > loss_disc_real_2: 0.1573377549648285  (0.19111649096012115)\n",
      "     | > loss_disc_real_3: 0.15394417941570282  (0.1953904777765274)\n",
      "     | > loss_disc_real_4: 0.16288110613822937  (0.2009646326303482)\n",
      "     | > loss_disc_real_5: 0.09113854169845581  (0.148577544093132)\n",
      "     | > loss_0: 3.079366683959961  (3.0505744934082033)\n",
      "     | > loss_gen: 0.9829839468002319  (1.1792615175247192)\n",
      "     | > loss_kl: 3.269277572631836  (3.694342517852783)\n",
      "     | > loss_feat: 2.0866031646728516  (1.3825007915496825)\n",
      "     | > loss_mel: 24.416412353515625  (23.92403221130371)\n",
      "     | > loss_duration: 1.4109454154968262  (1.3092970371246337)\n",
      "     | > loss_1: 32.166221618652344  (31.489433670043944)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 3.2728559970855713  (3.0876214106877646)\n",
      "     | > loss_disc_real_0: 0.1594831496477127  (0.14692839980125427)\n",
      "     | > loss_disc_real_1: 0.21212221682071686  (0.19050794343153635)\n",
      "     | > loss_disc_real_2: 0.19742700457572937  (0.1921682432293892)\n",
      "     | > loss_disc_real_3: 0.2006964236497879  (0.1962748020887375)\n",
      "     | > loss_disc_real_4: 0.19908763468265533  (0.20065179963906607)\n",
      "     | > loss_disc_real_5: 0.1565212607383728  (0.1499014968673388)\n",
      "     | > loss_0: 3.2728559970855713  (3.0876214106877646)\n",
      "     | > loss_gen: 1.1271244287490845  (1.17057200272878)\n",
      "     | > loss_kl: 3.298293113708496  (3.6283342838287354)\n",
      "     | > loss_feat: 0.8610067963600159  (1.2955851256847382)\n",
      "     | > loss_mel: 20.661880493164062  (23.380340258280437)\n",
      "     | > loss_duration: 1.1571733951568604  (1.2839430967966716)\n",
      "     | > loss_1: 27.105478286743164  (30.758774439493816)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.002461592356363932 \u001b[0m(+8.690357208251953e-05)\n",
      "     | > avg_loss_disc:\u001b[91m 3.0876214106877646 \u001b[0m(+0.10436149438222264)\n",
      "     | > avg_loss_disc_real_0:\u001b[92m 0.14692839980125427 \u001b[0m(-0.07878801226615906)\n",
      "     | > avg_loss_disc_real_1:\u001b[92m 0.19050794343153635 \u001b[0m(-0.06933976213137308)\n",
      "     | > avg_loss_disc_real_2:\u001b[92m 0.1921682432293892 \u001b[0m(-0.05422529081503549)\n",
      "     | > avg_loss_disc_real_3:\u001b[92m 0.1962748020887375 \u001b[0m(-0.03293251246213913)\n",
      "     | > avg_loss_disc_real_4:\u001b[92m 0.20065179963906607 \u001b[0m(-0.03352740655342737)\n",
      "     | > avg_loss_disc_real_5:\u001b[92m 0.1499014968673388 \u001b[0m(-0.0829014430443446)\n",
      "     | > avg_loss_0:\u001b[91m 3.0876214106877646 \u001b[0m(+0.10436149438222264)\n",
      "     | > avg_loss_gen:\u001b[92m 1.17057200272878 \u001b[0m(-0.29432356357574463)\n",
      "     | > avg_loss_kl:\u001b[91m 3.6283342838287354 \u001b[0m(+0.20586836338043213)\n",
      "     | > avg_loss_feat:\u001b[91m 1.2955851256847382 \u001b[0m(+0.7975021998087566)\n",
      "     | > avg_loss_mel:\u001b[91m 23.380340258280437 \u001b[0m(+0.03274726867675781)\n",
      "     | > avg_loss_duration:\u001b[91m 1.2839430967966716 \u001b[0m(+0.012749314308166504)\n",
      "     | > avg_loss_1:\u001b[91m 30.758774439493816 \u001b[0m(+0.7545429865519218)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 11/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:42:18) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:42:28 -- STEP: 22/32 -- GLOBAL_STEP: 1000375\u001b[0m\n",
      "     | > loss_disc: 2.9713661670684814  (2.9431525577198374)\n",
      "     | > loss_disc_real_0: 0.214852973818779  (0.24692487648942255)\n",
      "     | > loss_disc_real_1: 0.2179538607597351  (0.2528863224116239)\n",
      "     | > loss_disc_real_2: 0.2121286243200302  (0.2527976686304266)\n",
      "     | > loss_disc_real_3: 0.22949106991291046  (0.25021587312221527)\n",
      "     | > loss_disc_real_4: 0.22334495186805725  (0.2480075095187534)\n",
      "     | > loss_disc_real_5: 0.22450384497642517  (0.2526989592747255)\n",
      "     | > loss_0: 2.9713661670684814  (2.9431525577198374)\n",
      "     | > grad_norm_0: tensor(1.9744, device='cuda:0')  (tensor(1.9589, device='cuda:0'))\n",
      "     | > loss_gen: 1.3869041204452515  (1.5778545412150295)\n",
      "     | > loss_kl: 3.4606661796569824  (3.3794514482671563)\n",
      "     | > loss_feat: 0.4794180393218994  (0.6855712891979651)\n",
      "     | > loss_mel: 20.903913497924805  (22.65971348502419)\n",
      "     | > loss_duration: 13.020298957824707  (3.1475011110305786)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 39.25120162963867  (31.450092055580832)\n",
      "     | > grad_norm_1: tensor(146.5676, device='cuda:0')  (tensor(185.2234, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019972517181056292 \n",
      "     | > current_lr_1: 0.00019972517181056292 \n",
      "     | > step_time: 0.4009  (0.4095141129060225)\n",
      "     | > loader_time: 0.003  (0.0035671645944768734)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.8778882026672363  (2.8778882026672363)\n",
      "     | > loss_disc_real_0: 0.13962437212467194  (0.13962437212467194)\n",
      "     | > loss_disc_real_1: 0.24349458515644073  (0.24349458515644073)\n",
      "     | > loss_disc_real_2: 0.23799675703048706  (0.23799675703048706)\n",
      "     | > loss_disc_real_3: 0.2227843552827835  (0.2227843552827835)\n",
      "     | > loss_disc_real_4: 0.21809718012809753  (0.21809718012809753)\n",
      "     | > loss_disc_real_5: 0.1812628209590912  (0.1812628209590912)\n",
      "     | > loss_0: 2.8778882026672363  (2.8778882026672363)\n",
      "     | > loss_gen: 1.383963942527771  (1.383963942527771)\n",
      "     | > loss_kl: 3.132535457611084  (3.132535457611084)\n",
      "     | > loss_feat: 1.0094704627990723  (1.0094704627990723)\n",
      "     | > loss_mel: 23.8929443359375  (23.8929443359375)\n",
      "     | > loss_duration: 1.4755712747573853  (1.4755712747573853)\n",
      "     | > loss_1: 30.894485473632812  (30.894485473632812)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.916403293609619  (2.916403293609619)\n",
      "     | > loss_disc_real_0: 0.18820598721504211  (0.18820598721504211)\n",
      "     | > loss_disc_real_1: 0.26091963052749634  (0.26091963052749634)\n",
      "     | > loss_disc_real_2: 0.2407587170600891  (0.2407587170600891)\n",
      "     | > loss_disc_real_3: 0.221157044172287  (0.221157044172287)\n",
      "     | > loss_disc_real_4: 0.22653287649154663  (0.22653287649154663)\n",
      "     | > loss_disc_real_5: 0.18541057407855988  (0.18541057407855988)\n",
      "     | > loss_0: 2.916403293609619  (2.916403293609619)\n",
      "     | > loss_gen: 1.4281853437423706  (1.4281853437423706)\n",
      "     | > loss_kl: 3.798478364944458  (3.798478364944458)\n",
      "     | > loss_feat: 0.896425724029541  (0.896425724029541)\n",
      "     | > loss_mel: 31.02159881591797  (31.02159881591797)\n",
      "     | > loss_duration: 1.3916869163513184  (1.3916869163513184)\n",
      "     | > loss_1: 38.536373138427734  (38.536373138427734)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 3.0185539722442627  (2.967478632926941)\n",
      "     | > loss_disc_real_0: 0.11594772338867188  (0.152076855301857)\n",
      "     | > loss_disc_real_1: 0.2374994158744812  (0.24920952320098877)\n",
      "     | > loss_disc_real_2: 0.23078763484954834  (0.23577317595481873)\n",
      "     | > loss_disc_real_3: 0.20680761337280273  (0.21398232877254486)\n",
      "     | > loss_disc_real_4: 0.196585550904274  (0.2115592136979103)\n",
      "     | > loss_disc_real_5: 0.15145929157733917  (0.16843493282794952)\n",
      "     | > loss_0: 3.0185539722442627  (2.967478632926941)\n",
      "     | > loss_gen: 1.2296321392059326  (1.3289087414741516)\n",
      "     | > loss_kl: 2.7871572971343994  (3.2928178310394287)\n",
      "     | > loss_feat: 1.1329015493392944  (1.0146636366844177)\n",
      "     | > loss_mel: 23.14596939086914  (27.083784103393555)\n",
      "     | > loss_duration: 1.7387847900390625  (1.5652358531951904)\n",
      "     | > loss_1: 30.03444480895996  (34.28540897369385)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 2.934072971343994  (2.956343412399292)\n",
      "     | > loss_disc_real_0: 0.1240537017583847  (0.14273580412069956)\n",
      "     | > loss_disc_real_1: 0.23391836881637573  (0.24411247173945108)\n",
      "     | > loss_disc_real_2: 0.21065203845500946  (0.2273994634548823)\n",
      "     | > loss_disc_real_3: 0.17407408356666565  (0.20067958037058511)\n",
      "     | > loss_disc_real_4: 0.16744214296340942  (0.1968535234530767)\n",
      "     | > loss_disc_real_5: 0.12211908400058746  (0.15299631655216217)\n",
      "     | > loss_0: 2.934072971343994  (2.956343412399292)\n",
      "     | > loss_gen: 1.1908820867538452  (1.2828998565673828)\n",
      "     | > loss_kl: 4.055114269256592  (3.546916643778483)\n",
      "     | > loss_feat: 1.5259162187576294  (1.185081164042155)\n",
      "     | > loss_mel: 23.529630661010742  (25.89906628926595)\n",
      "     | > loss_duration: 0.8932651281356812  (1.3412456115086873)\n",
      "     | > loss_1: 31.194807052612305  (33.255208333333336)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 2.895507335662842  (2.9411343932151794)\n",
      "     | > loss_disc_real_0: 0.14081674814224243  (0.14225604012608528)\n",
      "     | > loss_disc_real_1: 0.24512498080730438  (0.2443655990064144)\n",
      "     | > loss_disc_real_2: 0.23599518835544586  (0.2295483946800232)\n",
      "     | > loss_disc_real_3: 0.22760172188282013  (0.20741011574864388)\n",
      "     | > loss_disc_real_4: 0.22876328229904175  (0.20483096316456795)\n",
      "     | > loss_disc_real_5: 0.17266114056110382  (0.15791252255439758)\n",
      "     | > loss_0: 2.895507335662842  (2.9411343932151794)\n",
      "     | > loss_gen: 1.3814914226531982  (1.3075477480888367)\n",
      "     | > loss_kl: 3.5784363746643066  (3.554796576499939)\n",
      "     | > loss_feat: 1.1023162603378296  (1.1643899381160736)\n",
      "     | > loss_mel: 22.175966262817383  (24.96829128265381)\n",
      "     | > loss_duration: 1.155089020729065  (1.2947064638137817)\n",
      "     | > loss_1: 29.393299102783203  (32.2897310256958)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 3.000659942626953  (2.9530395030975343)\n",
      "     | > loss_disc_real_0: 0.15049868822097778  (0.14390456974506377)\n",
      "     | > loss_disc_real_1: 0.2460688203573227  (0.24470624327659607)\n",
      "     | > loss_disc_real_2: 0.23832179605960846  (0.23130307495594024)\n",
      "     | > loss_disc_real_3: 0.2121160328388214  (0.20835129916667938)\n",
      "     | > loss_disc_real_4: 0.20636512339115143  (0.20513779520988465)\n",
      "     | > loss_disc_real_5: 0.18753278255462646  (0.16383657455444336)\n",
      "     | > loss_0: 3.000659942626953  (2.9530395030975343)\n",
      "     | > loss_gen: 1.3268399238586426  (1.311406183242798)\n",
      "     | > loss_kl: 2.75254225730896  (3.3943457126617433)\n",
      "     | > loss_feat: 0.9775183796882629  (1.1270156264305116)\n",
      "     | > loss_mel: 23.23778533935547  (24.622190093994142)\n",
      "     | > loss_duration: 1.4375386238098145  (1.3232728958129882)\n",
      "     | > loss_1: 29.732223510742188  (31.77822952270508)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 3.0008227825164795  (2.961003383000692)\n",
      "     | > loss_disc_real_0: 0.21792450547218323  (0.15624122569958368)\n",
      "     | > loss_disc_real_1: 0.2830825746059418  (0.2511022984981537)\n",
      "     | > loss_disc_real_2: 0.27512824535369873  (0.23860727002223334)\n",
      "     | > loss_disc_real_3: 0.2670897841453552  (0.21814104666312537)\n",
      "     | > loss_disc_real_4: 0.26450109481811523  (0.21503167847792307)\n",
      "     | > loss_disc_real_5: 0.2376682013273239  (0.17614184568325678)\n",
      "     | > loss_0: 3.0008227825164795  (2.961003383000692)\n",
      "     | > loss_gen: 1.5514953136444092  (1.3514210383097331)\n",
      "     | > loss_kl: 3.7565431594848633  (3.4547119537989297)\n",
      "     | > loss_feat: 0.059569116681814194  (0.9491078748057286)\n",
      "     | > loss_mel: 21.814720153808594  (24.15427843729655)\n",
      "     | > loss_duration: 1.162979006767273  (1.2965572476387024)\n",
      "     | > loss_1: 28.345306396484375  (31.20607566833496)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.002467473347981771 \u001b[0m(+5.880991617838831e-06)\n",
      "     | > avg_loss_disc:\u001b[92m 2.961003383000692 \u001b[0m(-0.12661802768707275)\n",
      "     | > avg_loss_disc_real_0:\u001b[91m 0.15624122569958368 \u001b[0m(+0.009312825898329408)\n",
      "     | > avg_loss_disc_real_1:\u001b[91m 0.2511022984981537 \u001b[0m(+0.06059435506661734)\n",
      "     | > avg_loss_disc_real_2:\u001b[91m 0.23860727002223334 \u001b[0m(+0.046439026792844146)\n",
      "     | > avg_loss_disc_real_3:\u001b[91m 0.21814104666312537 \u001b[0m(+0.021866244574387877)\n",
      "     | > avg_loss_disc_real_4:\u001b[91m 0.21503167847792307 \u001b[0m(+0.014379878838856996)\n",
      "     | > avg_loss_disc_real_5:\u001b[91m 0.17614184568325678 \u001b[0m(+0.02624034881591797)\n",
      "     | > avg_loss_0:\u001b[92m 2.961003383000692 \u001b[0m(-0.12661802768707275)\n",
      "     | > avg_loss_gen:\u001b[91m 1.3514210383097331 \u001b[0m(+0.1808490355809531)\n",
      "     | > avg_loss_kl:\u001b[92m 3.4547119537989297 \u001b[0m(-0.17362233002980565)\n",
      "     | > avg_loss_feat:\u001b[92m 0.9491078748057286 \u001b[0m(-0.3464772508790096)\n",
      "     | > avg_loss_mel:\u001b[91m 24.15427843729655 \u001b[0m(+0.7739381790161133)\n",
      "     | > avg_loss_duration:\u001b[91m 1.2965572476387024 \u001b[0m(+0.012614150842030769)\n",
      "     | > avg_loss_1:\u001b[91m 31.20607566833496 \u001b[0m(+0.44730122884114465)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 12/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:42:36) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:42:44 -- STEP: 15/32 -- GLOBAL_STEP: 1000400\u001b[0m\n",
      "     | > loss_disc: 2.967383623123169  (2.9279075622558595)\n",
      "     | > loss_disc_real_0: 0.23592665791511536  (0.2470593919356664)\n",
      "     | > loss_disc_real_1: 0.22440700232982635  (0.25732646783192953)\n",
      "     | > loss_disc_real_2: 0.23154160380363464  (0.25966643691062924)\n",
      "     | > loss_disc_real_3: 0.28072381019592285  (0.2626300762097041)\n",
      "     | > loss_disc_real_4: 0.27567002177238464  (0.264117216070493)\n",
      "     | > loss_disc_real_5: 0.310916930437088  (0.2676515688498815)\n",
      "     | > loss_0: 2.967383623123169  (2.9279075622558595)\n",
      "     | > grad_norm_0: tensor(1.2236, device='cuda:0')  (tensor(2.5447, device='cuda:0'))\n",
      "     | > loss_gen: 1.3633183240890503  (1.6653982718785605)\n",
      "     | > loss_kl: 3.1111483573913574  (3.419169616699219)\n",
      "     | > loss_feat: 0.6716402173042297  (0.9823302606741587)\n",
      "     | > loss_mel: 21.920936584472656  (24.427758026123048)\n",
      "     | > loss_duration: 1.3385093212127686  (3.1971007585525513)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 28.40555191040039  (33.69175707499187)\n",
      "     | > grad_norm_1: tensor(110.4549, device='cuda:0')  (tensor(135.1009, device='cuda:0'))\n",
      "     | > current_lr_0: 0.0001997002061640866 \n",
      "     | > current_lr_1: 0.0001997002061640866 \n",
      "     | > step_time: 0.4337  (0.44945468902587893)\n",
      "     | > loader_time: 0.0042  (0.003650220235188802)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.9360387325286865  (2.9360387325286865)\n",
      "     | > loss_disc_real_0: 0.26913970708847046  (0.26913970708847046)\n",
      "     | > loss_disc_real_1: 0.25710296630859375  (0.25710296630859375)\n",
      "     | > loss_disc_real_2: 0.26769405603408813  (0.26769405603408813)\n",
      "     | > loss_disc_real_3: 0.2295631617307663  (0.2295631617307663)\n",
      "     | > loss_disc_real_4: 0.2226274162530899  (0.2226274162530899)\n",
      "     | > loss_disc_real_5: 0.18994279205799103  (0.18994279205799103)\n",
      "     | > loss_0: 2.9360387325286865  (2.9360387325286865)\n",
      "     | > loss_gen: 1.5138155221939087  (1.5138155221939087)\n",
      "     | > loss_kl: 3.2684719562530518  (3.2684719562530518)\n",
      "     | > loss_feat: 0.924938440322876  (0.924938440322876)\n",
      "     | > loss_mel: 23.49406623840332  (23.49406623840332)\n",
      "     | > loss_duration: 1.4771416187286377  (1.4771416187286377)\n",
      "     | > loss_1: 30.678434371948242  (30.678434371948242)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.894996166229248  (2.894996166229248)\n",
      "     | > loss_disc_real_0: 0.22618739306926727  (0.22618739306926727)\n",
      "     | > loss_disc_real_1: 0.2544235587120056  (0.2544235587120056)\n",
      "     | > loss_disc_real_2: 0.26977404952049255  (0.26977404952049255)\n",
      "     | > loss_disc_real_3: 0.22429272532463074  (0.22429272532463074)\n",
      "     | > loss_disc_real_4: 0.225126713514328  (0.225126713514328)\n",
      "     | > loss_disc_real_5: 0.19850169122219086  (0.19850169122219086)\n",
      "     | > loss_0: 2.894996166229248  (2.894996166229248)\n",
      "     | > loss_gen: 1.515844702720642  (1.515844702720642)\n",
      "     | > loss_kl: 3.797612428665161  (3.797612428665161)\n",
      "     | > loss_feat: 0.9113935232162476  (0.9113935232162476)\n",
      "     | > loss_mel: 25.083450317382812  (25.083450317382812)\n",
      "     | > loss_duration: 1.352948784828186  (1.352948784828186)\n",
      "     | > loss_1: 32.66124725341797  (32.66124725341797)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 2.9402661323547363  (2.917631149291992)\n",
      "     | > loss_disc_real_0: 0.24623583257198334  (0.2362116128206253)\n",
      "     | > loss_disc_real_1: 0.27338308095932007  (0.26390331983566284)\n",
      "     | > loss_disc_real_2: 0.28322580456733704  (0.2764999270439148)\n",
      "     | > loss_disc_real_3: 0.24969711899757385  (0.2369949221611023)\n",
      "     | > loss_disc_real_4: 0.2481933981180191  (0.23666005581617355)\n",
      "     | > loss_disc_real_5: 0.2070005238056183  (0.20275110751390457)\n",
      "     | > loss_0: 2.9402661323547363  (2.917631149291992)\n",
      "     | > loss_gen: 1.5851044654846191  (1.5504745841026306)\n",
      "     | > loss_kl: 3.35962176322937  (3.5786170959472656)\n",
      "     | > loss_feat: 0.6476466059684753  (0.7795200645923615)\n",
      "     | > loss_mel: 23.904541015625  (24.493995666503906)\n",
      "     | > loss_duration: 1.6811091899871826  (1.5170289874076843)\n",
      "     | > loss_1: 31.178022384643555  (31.91963481903076)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 3.1522536277770996  (2.9958386421203613)\n",
      "     | > loss_disc_real_0: 0.2257174700498581  (0.23271356523036957)\n",
      "     | > loss_disc_real_1: 0.2507476210594177  (0.2595180869102478)\n",
      "     | > loss_disc_real_2: 0.25009405612945557  (0.2676979700724284)\n",
      "     | > loss_disc_real_3: 0.20975999534130096  (0.22791661322116852)\n",
      "     | > loss_disc_real_4: 0.19456006586551666  (0.22262672583262125)\n",
      "     | > loss_disc_real_5: 0.1829194724559784  (0.19614056249459585)\n",
      "     | > loss_0: 3.1522536277770996  (2.9958386421203613)\n",
      "     | > loss_gen: 1.3246862888336182  (1.4752118190129597)\n",
      "     | > loss_kl: 3.847930669784546  (3.668388287226359)\n",
      "     | > loss_feat: 1.0022321939468384  (0.8537574410438538)\n",
      "     | > loss_mel: 23.219974517822266  (24.06932195027669)\n",
      "     | > loss_duration: 0.8692184090614319  (1.3010921279589336)\n",
      "     | > loss_1: 30.264041900634766  (31.367770512898762)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 2.99107027053833  (2.9946465492248535)\n",
      "     | > loss_disc_real_0: 0.28149932622909546  (0.24491000548005104)\n",
      "     | > loss_disc_real_1: 0.2909404933452606  (0.267373688519001)\n",
      "     | > loss_disc_real_2: 0.29025721549987793  (0.27333778142929077)\n",
      "     | > loss_disc_real_3: 0.255219429731369  (0.23474231734871864)\n",
      "     | > loss_disc_real_4: 0.24991144239902496  (0.22944790497422218)\n",
      "     | > loss_disc_real_5: 0.2120881825685501  (0.2001274675130844)\n",
      "     | > loss_0: 2.99107027053833  (2.9946465492248535)\n",
      "     | > loss_gen: 1.6036090850830078  (1.5073111355304718)\n",
      "     | > loss_kl: 3.5109078884124756  (3.629018187522888)\n",
      "     | > loss_feat: 0.17838643491268158  (0.6849146895110607)\n",
      "     | > loss_mel: 19.099597930908203  (22.82689094543457)\n",
      "     | > loss_duration: 1.1378759145736694  (1.2602880746126175)\n",
      "     | > loss_1: 25.530378341674805  (29.908422470092773)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 2.9239609241485596  (2.9805094242095946)\n",
      "     | > loss_disc_real_0: 0.24093306064605713  (0.24411461651325225)\n",
      "     | > loss_disc_real_1: 0.26618024706840515  (0.2671350002288818)\n",
      "     | > loss_disc_real_2: 0.26319438219070435  (0.2713091015815735)\n",
      "     | > loss_disc_real_3: 0.22514216601848602  (0.2328222870826721)\n",
      "     | > loss_disc_real_4: 0.20767706632614136  (0.22509373724460602)\n",
      "     | > loss_disc_real_5: 0.19230683147907257  (0.19856334030628203)\n",
      "     | > loss_0: 2.9239609241485596  (2.9805094242095946)\n",
      "     | > loss_gen: 1.5021405220031738  (1.5062770128250123)\n",
      "     | > loss_kl: 3.348956346511841  (3.5730058193206786)\n",
      "     | > loss_feat: 0.7984457612037659  (0.7076209038496017)\n",
      "     | > loss_mel: 19.34601402282715  (22.130715560913085)\n",
      "     | > loss_duration: 1.4183542728424072  (1.2919013142585754)\n",
      "     | > loss_1: 26.413909912109375  (29.209519958496095)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 2.972698211669922  (2.9792075554529824)\n",
      "     | > loss_disc_real_0: 0.2631244957447052  (0.24728292971849442)\n",
      "     | > loss_disc_real_1: 0.26679959893226624  (0.26707910001277924)\n",
      "     | > loss_disc_real_2: 0.2746449410915375  (0.27186507483323413)\n",
      "     | > loss_disc_real_3: 0.23756647109985352  (0.23361298441886902)\n",
      "     | > loss_disc_real_4: 0.22987079620361328  (0.2258899137377739)\n",
      "     | > loss_disc_real_5: 0.1960676610469818  (0.19814739376306534)\n",
      "     | > loss_0: 2.972698211669922  (2.9792075554529824)\n",
      "     | > loss_gen: 1.513458490371704  (1.507473925749461)\n",
      "     | > loss_kl: 3.3523483276367188  (3.5362295707066855)\n",
      "     | > loss_feat: 0.6593706011772156  (0.6995791867375374)\n",
      "     | > loss_mel: 23.09226417541504  (22.290973663330078)\n",
      "     | > loss_duration: 1.1596312522888184  (1.2698563039302826)\n",
      "     | > loss_1: 29.77707290649414  (29.30411211649577)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.002460956573486328 \u001b[0m(-6.516774495442853e-06)\n",
      "     | > avg_loss_disc:\u001b[91m 2.9792075554529824 \u001b[0m(+0.018204172452290557)\n",
      "     | > avg_loss_disc_real_0:\u001b[91m 0.24728292971849442 \u001b[0m(+0.09104170401891074)\n",
      "     | > avg_loss_disc_real_1:\u001b[91m 0.26707910001277924 \u001b[0m(+0.01597680151462555)\n",
      "     | > avg_loss_disc_real_2:\u001b[91m 0.27186507483323413 \u001b[0m(+0.033257804811000796)\n",
      "     | > avg_loss_disc_real_3:\u001b[91m 0.23361298441886902 \u001b[0m(+0.015471937755743653)\n",
      "     | > avg_loss_disc_real_4:\u001b[91m 0.2258899137377739 \u001b[0m(+0.01085823525985083)\n",
      "     | > avg_loss_disc_real_5:\u001b[91m 0.19814739376306534 \u001b[0m(+0.022005548079808562)\n",
      "     | > avg_loss_0:\u001b[91m 2.9792075554529824 \u001b[0m(+0.018204172452290557)\n",
      "     | > avg_loss_gen:\u001b[91m 1.507473925749461 \u001b[0m(+0.15605288743972778)\n",
      "     | > avg_loss_kl:\u001b[91m 3.5362295707066855 \u001b[0m(+0.08151761690775583)\n",
      "     | > avg_loss_feat:\u001b[92m 0.6995791867375374 \u001b[0m(-0.24952868806819117)\n",
      "     | > avg_loss_mel:\u001b[92m 22.290973663330078 \u001b[0m(-1.8633047739664725)\n",
      "     | > avg_loss_duration:\u001b[92m 1.2698563039302826 \u001b[0m(-0.0267009437084198)\n",
      "     | > avg_loss_1:\u001b[92m 29.30411211649577 \u001b[0m(-1.9019635518391915)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 13/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:42:55) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:42:59 -- STEP: 8/32 -- GLOBAL_STEP: 1000425\u001b[0m\n",
      "     | > loss_disc: 2.9304699897766113  (2.9442722499370575)\n",
      "     | > loss_disc_real_0: 0.163129985332489  (0.24129522778093818)\n",
      "     | > loss_disc_real_1: 0.27867937088012695  (0.2585197649896145)\n",
      "     | > loss_disc_real_2: 0.28915420174598694  (0.25785895995795727)\n",
      "     | > loss_disc_real_3: 0.2915884256362915  (0.2648894414305687)\n",
      "     | > loss_disc_real_4: 0.29907816648483276  (0.26207722909748554)\n",
      "     | > loss_disc_real_5: 0.22154486179351807  (0.24817545339465139)\n",
      "     | > loss_0: 2.9304699897766113  (2.9442722499370575)\n",
      "     | > grad_norm_0: tensor(2.6239, device='cuda:0')  (tensor(2.1953, device='cuda:0'))\n",
      "     | > loss_gen: 1.6841001510620117  (1.633663296699524)\n",
      "     | > loss_kl: 3.477492094039917  (3.518806368112564)\n",
      "     | > loss_feat: 0.9253401160240173  (0.9460066556930542)\n",
      "     | > loss_mel: 25.595888137817383  (22.70574116706848)\n",
      "     | > loss_duration: 1.7452071905136108  (3.598430335521698)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 33.42802810668945  (32.402647495269775)\n",
      "     | > grad_norm_1: tensor(98.3312, device='cuda:0')  (tensor(134.1837, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019967524363831608 \n",
      "     | > current_lr_1: 0.00019967524363831608 \n",
      "     | > step_time: 0.462  (0.41923171281814575)\n",
      "     | > loader_time: 0.0046  (0.003546595573425293)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.997973918914795  (2.997973918914795)\n",
      "     | > loss_disc_real_0: 0.296810120344162  (0.296810120344162)\n",
      "     | > loss_disc_real_1: 0.22450734674930573  (0.22450734674930573)\n",
      "     | > loss_disc_real_2: 0.26638832688331604  (0.26638832688331604)\n",
      "     | > loss_disc_real_3: 0.27325737476348877  (0.27325737476348877)\n",
      "     | > loss_disc_real_4: 0.27791863679885864  (0.27791863679885864)\n",
      "     | > loss_disc_real_5: 0.2992372214794159  (0.2992372214794159)\n",
      "     | > loss_0: 2.997973918914795  (2.997973918914795)\n",
      "     | > loss_gen: 1.6612581014633179  (1.6612581014633179)\n",
      "     | > loss_kl: 3.085458278656006  (3.085458278656006)\n",
      "     | > loss_feat: 0.16434288024902344  (0.16434288024902344)\n",
      "     | > loss_mel: 22.046234130859375  (22.046234130859375)\n",
      "     | > loss_duration: 1.4559197425842285  (1.4559197425842285)\n",
      "     | > loss_1: 28.4132137298584  (28.4132137298584)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 3.019620418548584  (3.019620418548584)\n",
      "     | > loss_disc_real_0: 0.29604923725128174  (0.29604923725128174)\n",
      "     | > loss_disc_real_1: 0.22010622918605804  (0.22010622918605804)\n",
      "     | > loss_disc_real_2: 0.2602440118789673  (0.2602440118789673)\n",
      "     | > loss_disc_real_3: 0.26871809363365173  (0.26871809363365173)\n",
      "     | > loss_disc_real_4: 0.271497905254364  (0.271497905254364)\n",
      "     | > loss_disc_real_5: 0.3059164583683014  (0.3059164583683014)\n",
      "     | > loss_0: 3.019620418548584  (3.019620418548584)\n",
      "     | > loss_gen: 1.6189210414886475  (1.6189210414886475)\n",
      "     | > loss_kl: 3.7475414276123047  (3.7475414276123047)\n",
      "     | > loss_feat: 0.44765305519104004  (0.44765305519104004)\n",
      "     | > loss_mel: 28.930320739746094  (28.930320739746094)\n",
      "     | > loss_duration: 1.3520424365997314  (1.3520424365997314)\n",
      "     | > loss_1: 36.09647750854492  (36.09647750854492)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 2.995051145553589  (3.0073357820510864)\n",
      "     | > loss_disc_real_0: 0.2876149117946625  (0.2918320745229721)\n",
      "     | > loss_disc_real_1: 0.22257928550243378  (0.2213427573442459)\n",
      "     | > loss_disc_real_2: 0.2594121992588043  (0.2598281055688858)\n",
      "     | > loss_disc_real_3: 0.262812077999115  (0.26576508581638336)\n",
      "     | > loss_disc_real_4: 0.26682162284851074  (0.2691597640514374)\n",
      "     | > loss_disc_real_5: 0.2931026816368103  (0.29950957000255585)\n",
      "     | > loss_0: 2.995051145553589  (3.0073357820510864)\n",
      "     | > loss_gen: 1.6136537790298462  (1.6162874102592468)\n",
      "     | > loss_kl: 3.1228740215301514  (3.435207724571228)\n",
      "     | > loss_feat: 0.3332598805427551  (0.3904564678668976)\n",
      "     | > loss_mel: 21.636003494262695  (25.283162117004395)\n",
      "     | > loss_duration: 1.719710111618042  (1.5358762741088867)\n",
      "     | > loss_1: 28.425498962402344  (32.26098823547363)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 2.968665599822998  (2.99444572130839)\n",
      "     | > loss_disc_real_0: 0.2687070369720459  (0.2841237286726634)\n",
      "     | > loss_disc_real_1: 0.2077282965183258  (0.21680460373560587)\n",
      "     | > loss_disc_real_2: 0.24060776829719543  (0.25342132647832233)\n",
      "     | > loss_disc_real_3: 0.2427181452512741  (0.2580827722946803)\n",
      "     | > loss_disc_real_4: 0.24540548026561737  (0.26124166945616406)\n",
      "     | > loss_disc_real_5: 0.26320528984069824  (0.28740814328193665)\n",
      "     | > loss_0: 2.968665599822998  (2.99444572130839)\n",
      "     | > loss_gen: 1.527557373046875  (1.5867107311884563)\n",
      "     | > loss_kl: 3.6059834957122803  (3.4921329816182456)\n",
      "     | > loss_feat: 0.9385595321655273  (0.5731574892997742)\n",
      "     | > loss_mel: 25.374839782714844  (25.31372133890788)\n",
      "     | > loss_duration: 0.8734457492828369  (1.3150660991668701)\n",
      "     | > loss_1: 32.32038879394531  (32.28078842163086)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 3.0202672481536865  (3.0009011030197144)\n",
      "     | > loss_disc_real_0: 0.23955421149730682  (0.27298134937882423)\n",
      "     | > loss_disc_real_1: 0.19861797988414764  (0.21225794777274132)\n",
      "     | > loss_disc_real_2: 0.2338825762271881  (0.2485366389155388)\n",
      "     | > loss_disc_real_3: 0.23943471908569336  (0.25342075899243355)\n",
      "     | > loss_disc_real_4: 0.23844140768051147  (0.2555416040122509)\n",
      "     | > loss_disc_real_5: 0.2577842175960541  (0.280002161860466)\n",
      "     | > loss_0: 3.0202672481536865  (3.0009011030197144)\n",
      "     | > loss_gen: 1.4254298210144043  (1.5463905036449432)\n",
      "     | > loss_kl: 3.5600359439849854  (3.5091087222099304)\n",
      "     | > loss_feat: 1.0092365741729736  (0.682177260518074)\n",
      "     | > loss_mel: 24.56861114501953  (25.12744379043579)\n",
      "     | > loss_duration: 1.140622854232788  (1.2714552879333496)\n",
      "     | > loss_1: 31.703937530517578  (32.13657569885254)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 3.092440605163574  (3.0192090034484864)\n",
      "     | > loss_disc_real_0: 0.2119014412164688  (0.26076536774635317)\n",
      "     | > loss_disc_real_1: 0.17103047668933868  (0.2040124535560608)\n",
      "     | > loss_disc_real_2: 0.19923309981822968  (0.23867593109607696)\n",
      "     | > loss_disc_real_3: 0.18757636845111847  (0.24025188088417054)\n",
      "     | > loss_disc_real_4: 0.18081814050674438  (0.2405969113111496)\n",
      "     | > loss_disc_real_5: 0.2159416526556015  (0.2671900600194931)\n",
      "     | > loss_0: 3.092440605163574  (3.0192090034484864)\n",
      "     | > loss_gen: 1.2443829774856567  (1.4859889984130858)\n",
      "     | > loss_kl: 3.005841016769409  (3.408455181121826)\n",
      "     | > loss_feat: 1.3799712657928467  (0.8217360615730286)\n",
      "     | > loss_mel: 21.942537307739258  (24.490462493896484)\n",
      "     | > loss_duration: 1.4085321426391602  (1.2988706588745118)\n",
      "     | > loss_1: 28.981266021728516  (31.505513763427736)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 2.995964527130127  (3.0153349240620932)\n",
      "     | > loss_disc_real_0: 0.2414042353630066  (0.2575385123491287)\n",
      "     | > loss_disc_real_1: 0.19839102029800415  (0.20307554801305136)\n",
      "     | > loss_disc_real_2: 0.22120361030101776  (0.23576387763023376)\n",
      "     | > loss_disc_real_3: 0.22742165625095367  (0.2381135101119677)\n",
      "     | > loss_disc_real_4: 0.2306346744298935  (0.2389365384976069)\n",
      "     | > loss_disc_real_5: 0.23766735196113586  (0.26226960867643356)\n",
      "     | > loss_0: 2.995964527130127  (3.0153349240620932)\n",
      "     | > loss_gen: 1.4107130765914917  (1.4734430114428203)\n",
      "     | > loss_kl: 2.853968381881714  (3.3160407145818076)\n",
      "     | > loss_feat: 1.0747942924499512  (0.863912433385849)\n",
      "     | > loss_mel: 23.928176879882812  (24.396748224894207)\n",
      "     | > loss_duration: 1.1407802104949951  (1.272522250811259)\n",
      "     | > loss_1: 30.408432006835938  (31.32266680399577)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0024423996607462564 \u001b[0m(-1.855691274007176e-05)\n",
      "     | > avg_loss_disc:\u001b[91m 3.0153349240620932 \u001b[0m(+0.03612736860911081)\n",
      "     | > avg_loss_disc_real_0:\u001b[91m 0.2575385123491287 \u001b[0m(+0.010255582630634308)\n",
      "     | > avg_loss_disc_real_1:\u001b[92m 0.20307554801305136 \u001b[0m(-0.06400355199972788)\n",
      "     | > avg_loss_disc_real_2:\u001b[92m 0.23576387763023376 \u001b[0m(-0.03610119720300037)\n",
      "     | > avg_loss_disc_real_3:\u001b[91m 0.2381135101119677 \u001b[0m(+0.004500525693098695)\n",
      "     | > avg_loss_disc_real_4:\u001b[91m 0.2389365384976069 \u001b[0m(+0.013046624759833009)\n",
      "     | > avg_loss_disc_real_5:\u001b[91m 0.26226960867643356 \u001b[0m(+0.06412221491336823)\n",
      "     | > avg_loss_0:\u001b[91m 3.0153349240620932 \u001b[0m(+0.03612736860911081)\n",
      "     | > avg_loss_gen:\u001b[92m 1.4734430114428203 \u001b[0m(-0.034030914306640625)\n",
      "     | > avg_loss_kl:\u001b[92m 3.3160407145818076 \u001b[0m(-0.22018885612487793)\n",
      "     | > avg_loss_feat:\u001b[91m 0.863912433385849 \u001b[0m(+0.16433324664831161)\n",
      "     | > avg_loss_mel:\u001b[91m 24.396748224894207 \u001b[0m(+2.105774561564129)\n",
      "     | > avg_loss_duration:\u001b[91m 1.272522250811259 \u001b[0m(+0.002665946880976433)\n",
      "     | > avg_loss_1:\u001b[91m 31.32266680399577 \u001b[0m(+2.0185546875)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 14/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:43:13) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:43:14 -- STEP: 1/32 -- GLOBAL_STEP: 1000450\u001b[0m\n",
      "     | > loss_disc: 2.991879463195801  (2.991879463195801)\n",
      "     | > loss_disc_real_0: 0.25866761803627014  (0.25866761803627014)\n",
      "     | > loss_disc_real_1: 0.2811332643032074  (0.2811332643032074)\n",
      "     | > loss_disc_real_2: 0.24196726083755493  (0.24196726083755493)\n",
      "     | > loss_disc_real_3: 0.215794637799263  (0.215794637799263)\n",
      "     | > loss_disc_real_4: 0.24737854301929474  (0.24737854301929474)\n",
      "     | > loss_disc_real_5: 0.24609224498271942  (0.24609224498271942)\n",
      "     | > loss_0: 2.991879463195801  (2.991879463195801)\n",
      "     | > grad_norm_0: tensor(2.7324, device='cuda:0')  (tensor(2.7324, device='cuda:0'))\n",
      "     | > loss_gen: 1.4395909309387207  (1.4395909309387207)\n",
      "     | > loss_kl: 3.524757146835327  (3.524757146835327)\n",
      "     | > loss_feat: 0.7062395811080933  (0.7062395811080933)\n",
      "     | > loss_mel: 23.392162322998047  (23.392162322998047)\n",
      "     | > loss_duration: 1.3900766372680664  (1.3900766372680664)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 30.45282745361328  (30.45282745361328)\n",
      "     | > grad_norm_1: tensor(158.8653, device='cuda:0')  (tensor(158.8653, device='cuda:0'))\n",
      "     | > current_lr_0: 0.0001996502842328613 \n",
      "     | > current_lr_1: 0.0001996502842328613 \n",
      "     | > step_time: 0.4159  (0.4158644676208496)\n",
      "     | > loader_time: 0.0038  (0.0038497447967529297)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:43:25 -- STEP: 26/32 -- GLOBAL_STEP: 1000475\u001b[0m\n",
      "     | > loss_disc: 3.139615774154663  (2.9585226682516246)\n",
      "     | > loss_disc_real_0: 0.2031179964542389  (0.24239331827713892)\n",
      "     | > loss_disc_real_1: 0.19636757671833038  (0.24922533505238015)\n",
      "     | > loss_disc_real_2: 0.18515776097774506  (0.24871676128644213)\n",
      "     | > loss_disc_real_3: 0.20975227653980255  (0.2475858021240968)\n",
      "     | > loss_disc_real_4: 0.2284715324640274  (0.24759428546978884)\n",
      "     | > loss_disc_real_5: 0.21464554965496063  (0.2405845929796879)\n",
      "     | > loss_0: 3.139615774154663  (2.9585226682516246)\n",
      "     | > grad_norm_0: tensor(5.4310, device='cuda:0')  (tensor(3.1935, device='cuda:0'))\n",
      "     | > loss_gen: 1.7568140029907227  (1.58144604242765)\n",
      "     | > loss_kl: 3.846388816833496  (3.3326969605225782)\n",
      "     | > loss_feat: 1.3239190578460693  (0.830104205184258)\n",
      "     | > loss_mel: 24.23993492126465  (23.29283171433669)\n",
      "     | > loss_duration: 1.6300740242004395  (2.8549331105672398)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 32.7971305847168  (31.892012082613427)\n",
      "     | > grad_norm_1: tensor(188.5036, device='cuda:0')  (tensor(177.3233, device='cuda:0'))\n",
      "     | > current_lr_0: 0.0001996502842328613 \n",
      "     | > current_lr_1: 0.0001996502842328613 \n",
      "     | > step_time: 0.3977  (0.4119472320263202)\n",
      "     | > loader_time: 0.0028  (0.003440077488238995)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.899077892303467  (2.899077892303467)\n",
      "     | > loss_disc_real_0: 0.20739395916461945  (0.20739395916461945)\n",
      "     | > loss_disc_real_1: 0.2013736516237259  (0.2013736516237259)\n",
      "     | > loss_disc_real_2: 0.20145614445209503  (0.20145614445209503)\n",
      "     | > loss_disc_real_3: 0.21248741447925568  (0.21248741447925568)\n",
      "     | > loss_disc_real_4: 0.20871001482009888  (0.20871001482009888)\n",
      "     | > loss_disc_real_5: 0.20574265718460083  (0.20574265718460083)\n",
      "     | > loss_0: 2.899077892303467  (2.899077892303467)\n",
      "     | > loss_gen: 1.3541221618652344  (1.3541221618652344)\n",
      "     | > loss_kl: 3.4640824794769287  (3.4640824794769287)\n",
      "     | > loss_feat: 0.7054261565208435  (0.7054261565208435)\n",
      "     | > loss_mel: 22.767059326171875  (22.767059326171875)\n",
      "     | > loss_duration: 1.475252628326416  (1.475252628326416)\n",
      "     | > loss_1: 29.765941619873047  (29.765941619873047)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.929184913635254  (2.929184913635254)\n",
      "     | > loss_disc_real_0: 0.19749385118484497  (0.19749385118484497)\n",
      "     | > loss_disc_real_1: 0.19974038004875183  (0.19974038004875183)\n",
      "     | > loss_disc_real_2: 0.1901724487543106  (0.1901724487543106)\n",
      "     | > loss_disc_real_3: 0.20070067048072815  (0.20070067048072815)\n",
      "     | > loss_disc_real_4: 0.2022736370563507  (0.2022736370563507)\n",
      "     | > loss_disc_real_5: 0.20349165797233582  (0.20349165797233582)\n",
      "     | > loss_0: 2.929184913635254  (2.929184913635254)\n",
      "     | > loss_gen: 1.3079580068588257  (1.3079580068588257)\n",
      "     | > loss_kl: 3.664959192276001  (3.664959192276001)\n",
      "     | > loss_feat: 1.0870920419692993  (1.0870920419692993)\n",
      "     | > loss_mel: 30.799768447875977  (30.799768447875977)\n",
      "     | > loss_duration: 1.3801491260528564  (1.3801491260528564)\n",
      "     | > loss_1: 38.239925384521484  (38.239925384521484)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 2.9204394817352295  (2.9248121976852417)\n",
      "     | > loss_disc_real_0: 0.22622808814048767  (0.21186096966266632)\n",
      "     | > loss_disc_real_1: 0.2012132853269577  (0.20047683268785477)\n",
      "     | > loss_disc_real_2: 0.1928696185350418  (0.1915210336446762)\n",
      "     | > loss_disc_real_3: 0.20027980208396912  (0.20049023628234863)\n",
      "     | > loss_disc_real_4: 0.18807421624660492  (0.1951739266514778)\n",
      "     | > loss_disc_real_5: 0.17225049436092377  (0.1878710761666298)\n",
      "     | > loss_0: 2.9204394817352295  (2.9248121976852417)\n",
      "     | > loss_gen: 1.299906849861145  (1.3039324283599854)\n",
      "     | > loss_kl: 2.538041114807129  (3.101500153541565)\n",
      "     | > loss_feat: 0.964422345161438  (1.0257571935653687)\n",
      "     | > loss_mel: 22.850069046020508  (26.824918746948242)\n",
      "     | > loss_duration: 1.7225638628005981  (1.5513564944267273)\n",
      "     | > loss_1: 29.375003814697266  (33.807464599609375)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 2.9370129108428955  (2.9288791020711265)\n",
      "     | > loss_disc_real_0: 0.2672325670719147  (0.23031816879908243)\n",
      "     | > loss_disc_real_1: 0.2160109430551529  (0.20565486947695413)\n",
      "     | > loss_disc_real_2: 0.21506018936634064  (0.19936741888523102)\n",
      "     | > loss_disc_real_3: 0.21713443100452423  (0.2060383011897405)\n",
      "     | > loss_disc_real_4: 0.21863892674446106  (0.2029955933491389)\n",
      "     | > loss_disc_real_5: 0.21409887075424194  (0.19661367436250052)\n",
      "     | > loss_0: 2.9370129108428955  (2.9288791020711265)\n",
      "     | > loss_gen: 1.4203217029571533  (1.342728853225708)\n",
      "     | > loss_kl: 3.7642478942871094  (3.322416067123413)\n",
      "     | > loss_feat: 0.28711187839508057  (0.779542088508606)\n",
      "     | > loss_mel: 23.181781768798828  (25.61053975423177)\n",
      "     | > loss_duration: 0.8660595417022705  (1.3229241768519084)\n",
      "     | > loss_1: 29.51952362060547  (32.378150939941406)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 2.9029455184936523  (2.922395706176758)\n",
      "     | > loss_disc_real