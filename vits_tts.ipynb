{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef9f4479-ac3a-4afe-b68a-10f825ca0529",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig, CharactersConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "\n",
    "from TTS.tts.models.vits import Vits, VitsArgs, VitsAudioConfig\n",
    "from TTS.tts.configs.vits_config import VitsConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e45337-335e-46bf-b792-7b6c87974844",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.dirname(os.path.abspath('__file__'))\n",
    "\n",
    "\n",
    "dataset_config = BaseDatasetConfig(\n",
    "    formatter=\"ljspeech\", meta_file_train=\"Mixed_formatted.txt\", path=os.path.join(output_path, \"data/\"), language = \"en\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62b0b0ae-90f6-494c-94f7-fa5a7be77369",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_config = VitsAudioConfig(\n",
    "    sample_rate=22050, win_length=1024, hop_length=256, num_mels=80, mel_fmin=0, mel_fmax=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d030092-2845-4892-ae38-8636b6c9c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_config = CharactersConfig(\n",
    "    characters_class= \"TTS.tts.models.vits.VitsCharacters\",\n",
    "    characters= \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz1234567890\",\n",
    "    punctuations=\"\"\" !,.?-\"'\"\"\",\n",
    "    pad= \"<PAD>\",\n",
    "    eos= \"<EOS>\",\n",
    "    bos= \"<BOS>\",\n",
    "    blank= \"<BLNK>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b929e53f-7050-42f8-b298-e9b2a9388564",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = VitsConfig(\n",
    "    audio=audio_config,\n",
    "    # characters=character_config, # Comment out if with phonemes\n",
    "    run_name=\"vits_tyler1_phonemes\",\n",
    "    batch_size=4,\n",
    "    eval_batch_size=2,\n",
    "    # batch_group_size=4,\n",
    "    num_loader_workers=8,\n",
    "    num_eval_loader_workers=2,\n",
    "    run_eval=True,\n",
    "    test_delay_epochs=-1,\n",
    "    epochs=5000,\n",
    "    text_cleaner=\"english_cleaners\",\n",
    "    use_phonemes=True, # Replace with False if no phonemes\n",
    "    phoneme_language=\"en-us\",\n",
    "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
    "    compute_input_seq_cache=True,\n",
    "    print_step=25,\n",
    "    print_eval=True,\n",
    "    mixed_precision=True,\n",
    "    output_path=output_path + \"/vitstts_checkpoint\",\n",
    "    datasets=[dataset_config],\n",
    "    cudnn_benchmark=False,\n",
    "    test_sentences = [\"Mic test one two three\", \"I am Tyler1\", \"Welcome chat!\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59fc8653-77f6-4043-8bda-469a3a3f90ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatter(root_path, manifest_file, **kwargs):  # pylint: disable=unused-argument\n",
    "    \"\"\"Assumes each line as ```<filename>|<transcription>```\n",
    "    \"\"\"\n",
    "    txt_file = os.path.join(root_path, manifest_file)\n",
    "    items = []\n",
    "    speaker_name = \"Tyler1\"\n",
    "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
    "        for line in ttf:\n",
    "            cols = line.split(\"|\")\n",
    "            wav_file = os.path.dirname(os.path.abspath('__file__')) + f\"/data/wavs/{cols[0]}.wav\"\n",
    "            text = cols[1]\n",
    "            # print(text)\n",
    "            items.append({\"text\":text, \"audio_file\":wav_file, \"speaker_name\":speaker_name, \"root_path\": root_path})\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2956d0f9-645b-4e93-b2ba-adf2902ddb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n"
     ]
    }
   ],
   "source": [
    "ap = AudioProcessor.init_from_config(config)\n",
    "\n",
    "tokenizer, config = TTSTokenizer.init_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d2648df-3c07-4c19-8ec0-9a9a74dcbea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Found 60 files in /home/ubuntu/tyler1/data\n"
     ]
    }
   ],
   "source": [
    "train_samples, eval_samples = load_tts_samples(\n",
    "    dataset_config,\n",
    "    eval_split=True,\n",
    "    # eval_split_max_size=config.eval_split_max_size,\n",
    "    eval_split_size=0.05,\n",
    "    formatter = formatter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb8348c7-ae87-4aa2-b3f1-2b29722273c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "model = Vits(config, ap, tokenizer, speaker_manager=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22481fdc-0156-4946-a56c-a786f1f2978f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: True\n",
      " | > Precision: fp16\n",
      " | > Current device: 0\n",
      " | > Num. of GPUs: 1\n",
      " | > Num. of CPUs: 30\n",
      " | > Num. of Torch Threads: 30\n",
      " | > Torch seed: 54321\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      "2024-01-23 09:21:01.016354: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-23 09:21:01.059846: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F AVX512_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      " > Start Tensorboard: tensorboard --logdir=/home/ubuntu/tyler1/vitstts_checkpoint/vits_tyler1_phonemes-January-23-2024_09+21AM-1edd3ad\n",
      "\n",
      " > Model has 83059180 parameters\n"
     ]
    }
   ],
   "source": [
    "# Make sure to change phoneme in config cell when training a phoneme model\n",
    "\n",
    "model_path = \"vitstts_checkpoint/vits_tyler1-January-16-2024_01+41PM-d5007e2/\" # no phonemes\n",
    "model_path = \"vitstts_checkpoint/vits_tyler1-January-17-2024_09+38AM-d5007e2/\" # with phonemes\n",
    "\n",
    "trainer = Trainer(\n",
    "    # TrainerArgs(restore_path = model_path + \"/best_model.pth\"), # Load from checkpoint\n",
    "    TrainerArgs(),\n",
    "    config,\n",
    "    output_path,\n",
    "    model=model,\n",
    "    train_samples=train_samples,\n",
    "    eval_samples=eval_samples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ae7363-4092-4b7f-9094-c4455294d539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/5000\u001b[0m\n",
      " --> /home/ubuntu/tyler1/vitstts_checkpoint/vits_tyler1_phonemes-January-23-2024_09+21AM-1edd3ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Pre-computing phonemes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 2/57 [00:00<00:03, 16.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ɡˈaɪz oʊkˈeɪ lˈɪsən lˈɛts tˈɔːk ɐbˌaʊt sˈʌmθɪŋ ɹˈiːəl kwˈɪk. ˈaɪ swˈɛɹ tə ɡˈɑːd lˈaɪk jˈɛh maɪ kˈɑːɹdɪˌoʊ wˈʌzn̩t ðə bˈɛst bˌʌt bɹˈoʊ aɪm nˌɑːt lˈaɪk aɪm nˌɑːt kˈoʊp lˈaɪk aɪm nˌɑːt kɹˈeɪzi. ˈaɪ hæv ðɪs ʃˈɑːɹp pˈeɪn ɪn maɪ hˈɑːɹt fɹʌm tˈaɪm tə tˈaɪm. lˈaɪk ˈæktʃuːəl ʃˈɑːɹp, lˈaɪk ɹˈaɪt wɛn ˈaɪ lˈaɪk dˈuː ɐ θˈɜːɾi sˈɛkənd dʒˈɑːɡ ɔːɹ wʌtˈɛvɚɹ ɔːɹ wɛn ˈaɪ snˈiːz ɔːɹ wɛn ˈaɪ dˈuː bˈɛntʃ. ˈaɪ fˈiːl ɪɾ ɐ lˈɑːt. aɪm nˌɑːt kɹˈeɪzi lˈaɪk aɪm nˌɑːt ˈaɪ swˈɛɹ tə ɡˈɑːd ˈæktʃuːəli.\n",
      " [!] Character '̩' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [00:08<00:00,  6.94it/s]\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-23 09:21:11) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: espeak\n",
      "\t| > 1 not found characters:\n",
      "\t| > ̩\n",
      "| > Number of instances : 57\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 1462\n",
      " | > Min text length: 131\n",
      " | > Avg text length: 685.6140350877193\n",
      " | \n",
      " | > Max audio length: 7408822.0\n",
      " | > Min audio length: 578318.0\n",
      " | > Avg audio length: 3487299.50877193\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/functional.py:650: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:863.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-23 09:21:14 -- STEP: 0/15 -- GLOBAL_STEP: 0\u001b[0m\n",
      "     | > loss_disc: 5.958283424377441  (5.958283424377441)\n",
      "     | > loss_disc_real_0: 1.0065133571624756  (1.0065133571624756)\n",
      "     | > loss_disc_real_1: 1.022413730621338  (1.022413730621338)\n",
      "     | > loss_disc_real_2: 0.9817718863487244  (0.9817718863487244)\n",
      "     | > loss_disc_real_3: 0.9567512273788452  (0.9567512273788452)\n",
      "     | > loss_disc_real_4: 1.0066996812820435  (1.0066996812820435)\n",
      "     | > loss_disc_real_5: 0.9833380579948425  (0.9833380579948425)\n",
      "     | > loss_0: 5.958283424377441  (5.958283424377441)\n",
      "     | > grad_norm_0: 0  (0)\n",
      "     | > loss_gen: 5.957746982574463  (5.957746982574463)\n",
      "     | > loss_kl: 160.70339965820312  (160.70339965820312)\n",
      "     | > loss_feat: 0.27372416853904724  (0.27372416853904724)\n",
      "     | > loss_mel: 106.33445739746094  (106.33445739746094)\n",
      "     | > loss_duration: 1.3796894550323486  (1.3796894550323486)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > loss_1: 274.6490173339844  (274.6490173339844)\n",
      "     | > grad_norm_1: 0  (0)\n",
      "     | > current_lr_0: 0.0002 \n",
      "     | > current_lr_1: 0.0002 \n",
      "     | > step_time: 2.2984  (2.2984020709991455)\n",
      "     | > loader_time: 0.7703  (0.7703180313110352)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: espeak\n",
      "\t| > 1 not found characters:\n",
      "\t| > ̩\n",
      "| > Number of instances : 3\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 1148\n",
      " | > Min text length: 261\n",
      " | > Avg text length: 681.3333333333334\n",
      " | \n",
      " | > Max audio length: 6162562.0\n",
      " | > Min audio length: 1429014.0\n",
      " | > Avg audio length: 3654345.3333333335\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 3.053609848022461  (3.053609848022461)\n",
      "     | > loss_disc_real_0: 0.29904425144195557  (0.29904425144195557)\n",
      "     | > loss_disc_real_1: 0.2782394289970398  (0.2782394289970398)\n",
      "     | > loss_disc_real_2: 0.28470495343208313  (0.28470495343208313)\n",
      "     | > loss_disc_real_3: 0.26765817403793335  (0.26765817403793335)\n",
      "     | > loss_disc_real_4: 0.2995864152908325  (0.2995864152908325)\n",
      "     | > loss_disc_real_5: 0.2713654339313507  (0.2713654339313507)\n",
      "     | > loss_0: 3.053609848022461  (3.053609848022461)\n",
      "     | > loss_gen: 1.7278966903686523  (1.7278966903686523)\n",
      "     | > loss_kl: 17.80422592163086  (17.80422592163086)\n",
      "     | > loss_feat: 0.20188529789447784  (0.20188529789447784)\n",
      "     | > loss_mel: 114.70222473144531  (114.70222473144531)\n",
      "     | > loss_duration: 2.957717180252075  (2.957717180252075)\n",
      "     | > loss_1: 137.39395141601562  (137.39395141601562)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 3.0608999729156494  (3.0608999729156494)\n",
      "     | > loss_disc_real_0: 0.29910117387771606  (0.29910117387771606)\n",
      "     | > loss_disc_real_1: 0.2792060077190399  (0.2792060077190399)\n",
      "     | > loss_disc_real_2: 0.2866024374961853  (0.2866024374961853)\n",
      "     | > loss_disc_real_3: 0.26852667331695557  (0.26852667331695557)\n",
      "     | > loss_disc_real_4: 0.3008735775947571  (0.3008735775947571)\n",
      "     | > loss_disc_real_5: 0.27346551418304443  (0.27346551418304443)\n",
      "     | > loss_0: 3.0608999729156494  (3.0608999729156494)\n",
      "     | > loss_gen: 1.7277858257293701  (1.7277858257293701)\n",
      "     | > loss_kl: 15.162726402282715  (15.162726402282715)\n",
      "     | > loss_feat: 0.17718160152435303  (0.17718160152435303)\n",
      "     | > loss_mel: 64.30608367919922  (64.30608367919922)\n",
      "     | > loss_duration: 2.9432733058929443  (2.9432733058929443)\n",
      "     | > loss_1: 84.31704711914062  (84.31704711914062)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/TTS/tts/models/vits.py:1455: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3614.)\n",
      "  test_figures[\"{}-alignment\".format(idx)] = plot_alignment(alignment.T, output_fig=False)\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time: 0.006366252899169922 \u001b[0m(+0)\n",
      "     | > avg_loss_disc: 3.0608999729156494 \u001b[0m(+0)\n",
      "     | > avg_loss_disc_real_0: 0.29910117387771606 \u001b[0m(+0)\n",
      "     | > avg_loss_disc_real_1: 0.2792060077190399 \u001b[0m(+0)\n",
      "     | > avg_loss_disc_real_2: 0.2866024374961853 \u001b[0m(+0)\n",
      "     | > avg_loss_disc_real_3: 0.26852667331695557 \u001b[0m(+0)\n",
      "     | > avg_loss_disc_real_4: 0.3008735775947571 \u001b[0m(+0)\n",
      "     | > avg_loss_disc_real_5: 0.27346551418304443 \u001b[0m(+0)\n",
      "     | > avg_loss_0: 3.0608999729156494 \u001b[0m(+0)\n",
      "     | > avg_loss_gen: 1.7277858257293701 \u001b[0m(+0)\n",
      "     | > avg_loss_kl: 15.162726402282715 \u001b[0m(+0)\n",
      "     | > avg_loss_feat: 0.17718160152435303 \u001b[0m(+0)\n",
      "     | > avg_loss_mel: 64.30608367919922 \u001b[0m(+0)\n",
      "     | > avg_loss_duration: 2.9432733058929443 \u001b[0m(+0)\n",
      "     | > avg_loss_1: 84.31704711914062 \u001b[0m(+0)\n",
      "\n",
      " > BEST MODEL : /home/ubuntu/tyler1/vitstts_checkpoint/vits_tyler1_phonemes-January-23-2024_09+21AM-1edd3ad/best_model_15.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 1/5000\u001b[0m\n",
      " --> /home/ubuntu/tyler1/vitstts_checkpoint/vits_tyler1_phonemes-January-23-2024_09+21AM-1edd3ad\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-23 09:22:18) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-23 09:22:48 -- STEP: 10/15 -- GLOBAL_STEP: 25\u001b[0m\n",
      "     | > loss_disc: 2.801196813583374  (2.8900539875030518)\n",
      "     | > loss_disc_real_0: 0.2800379693508148  (0.25221690237522126)\n",
      "     | > loss_disc_real_1: 0.24173857271671295  (0.24150739908218383)\n",
      "     | > loss_disc_real_2: 0.23730847239494324  (0.24375846087932587)\n",
      "     | > loss_disc_real_3: 0.23550114035606384  (0.2623416319489479)\n",
      "     | > loss_disc_real_4: 0.2510402500629425  (0.2495233580470085)\n",
      "     | > loss_disc_real_5: 0.22822105884552002  (0.2540858328342438)\n",
      "     | > loss_0: 2.801196813583374  (2.8900539875030518)\n",
      "     | > grad_norm_0: tensor(1.6060, device='cuda:0')  (tensor(1.5467, device='cuda:0'))\n",
      "     | > loss_gen: 1.739232063293457  (1.6723671317100526)\n",
      "     | > loss_kl: 11.958043098449707  (12.811641693115234)\n",
      "     | > loss_feat: 1.1823022365570068  (0.8269291430711746)\n",
      "     | > loss_mel: 71.92053985595703  (81.15151481628418)\n",
      "     | > loss_duration: 1.9263763427734375  (2.050798714160919)\n",
      "     | > amp_scaler: 512.0  (512.0)\n",
      "     | > loss_1: 88.72649383544922  (98.51325225830078)\n",
      "     | > grad_norm_1: tensor(155.8179, device='cuda:0')  (tensor(194.4888, device='cuda:0'))\n",
      "     | > current_lr_0: 0.000199975 \n",
      "     | > current_lr_1: 0.000199975 \n",
      "     | > step_time: 5.632  (2.837778425216675)\n",
      "     | > loader_time: 0.0173  (0.010993576049804688)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 3.093824863433838  (3.093824863433838)\n",
      "     | > loss_disc_real_0: 0.2479248046875  (0.2479248046875)\n",
      "     | > loss_disc_real_1: 0.3524229824542999  (0.3524229824542999)\n",
      "     | > loss_disc_real_2: 0.34964829683303833  (0.34964829683303833)\n",
      "     | > loss_disc_real_3: 0.30652567744255066  (0.30652567744255066)\n",
      "     | > loss_disc_real_4: 0.3079974353313446  (0.3079974353313446)\n",
      "     | > loss_disc_real_5: 0.31348156929016113  (0.31348156929016113)\n",
      "     | > loss_0: 3.093824863433838  (3.093824863433838)\n",
      "     | > loss_gen: 1.8913967609405518  (1.8913967609405518)\n",
      "     | > loss_kl: 5.867955207824707  (5.867955207824707)\n",
      "     | > loss_feat: 0.27155303955078125  (0.27155303955078125)\n",
      "     | > loss_mel: 78.0065689086914  (78.0065689086914)\n",
      "     | > loss_duration: 2.6350040435791016  (2.6350040435791016)\n",
      "     | > loss_1: 88.67247772216797  (88.67247772216797)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 3.1309821605682373  (3.1309821605682373)\n",
      "     | > loss_disc_real_0: 0.24920599162578583  (0.24920599162578583)\n",
      "     | > loss_disc_real_1: 0.40514233708381653  (0.40514233708381653)\n",
      "     | > loss_disc_real_2: 0.3895493447780609  (0.3895493447780609)\n",
      "     | > loss_disc_real_3: 0.33496612310409546  (0.33496612310409546)\n",
      "     | > loss_disc_real_4: 0.3695238530635834  (0.3695238530635834)\n",
      "     | > loss_disc_real_5: 0.35567277669906616  (0.35567277669906616)\n",
      "     | > loss_0: 3.1309821605682373  (3.1309821605682373)\n",
      "     | > loss_gen: 2.1165528297424316  (2.1165528297424316)\n",
      "     | > loss_kl: 4.365316390991211  (4.365316390991211)\n",
      "     | > loss_feat: 0.0339265875518322  (0.0339265875518322)\n",
      "     | > loss_mel: 74.19326782226562  (74.19326782226562)\n",
      "     | > loss_duration: 2.605498790740967  (2.605498790740967)\n",
      "     | > loss_1: 83.31456756591797  (83.31456756591797)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.005904436111450195 \u001b[0m(-0.00046181678771972656)\n",
      "     | > avg_loss_disc:\u001b[91m 3.1309821605682373 \u001b[0m(+0.07008218765258789)\n",
      "     | > avg_loss_disc_real_0:\u001b[92m 0.24920599162578583 \u001b[0m(-0.04989518225193024)\n",
      "     | > avg_loss_disc_real_1:\u001b[91m 0.40514233708381653 \u001b[0m(+0.1259363293647766)\n",
      "     | > avg_loss_disc_real_2:\u001b[91m 0.3895493447780609 \u001b[0m(+0.10294690728187561)\n",
      "     | > avg_loss_disc_real_3:\u001b[91m 0.33496612310409546 \u001b[0m(+0.06643944978713989)\n",
      "     | > avg_loss_disc_real_4:\u001b[91m 0.3695238530635834 \u001b[0m(+0.0686502754688263)\n",
      "     | > avg_loss_disc_real_5:\u001b[91m 0.35567277669906616 \u001b[0m(+0.08220726251602173)\n",
      "     | > avg_loss_0:\u001b[91m 3.1309821605682373 \u001b[0m(+0.07008218765258789)\n",
      "     | > avg_loss_gen:\u001b[91m 2.1165528297424316 \u001b[0m(+0.3887670040130615)\n",
      "     | > avg_loss_kl:\u001b[92m 4.365316390991211 \u001b[0m(-10.797410011291504)\n",
      "     | > avg_loss_feat:\u001b[92m 0.0339265875518322 \u001b[0m(-0.14325501397252083)\n",
      "     | > avg_loss_mel:\u001b[91m 74.19326782226562 \u001b[0m(+9.887184143066406)\n",
      "     | > avg_loss_duration:\u001b[92m 2.605498790740967 \u001b[0m(-0.33777451515197754)\n",
      "     | > avg_loss_1:\u001b[92m 83.31456756591797 \u001b[0m(-1.0024795532226562)\n",
      "\n",
      " > BEST MODEL : /home/ubuntu/tyler1/vitstts_checkpoint/vits_tyler1_phonemes-January-23-2024_09+21AM-1edd3ad/best_model_30.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 2/5000\u001b[0m\n",
      " --> /home/ubuntu/tyler1/vitstts_checkpoint/vits_tyler1_phonemes-January-23-2024_09+21AM-1edd3ad\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-23 09:23:20) \u001b[0m\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.9747252464294434  (2.9747252464294434)\n",
      "     | > loss_disc_real_0: 0.19458505511283875  (0.19458505511283875)\n",
      "     | > loss_disc_real_1: 0.22326385974884033  (0.22326385974884033)\n",
      "     | > loss_disc_real_2: 0.24161218106746674  (0.24161218106746674)\n",
      "     | > loss_disc_real_3: 0.2977736294269562  (0.2977736294269562)\n",
      "     | > loss_disc_real_4: 0.38594353199005127  (0.38594353199005127)\n",
      "     | > loss_disc_real_5: 0.12637844681739807  (0.12637844681739807)\n",
      "     | > loss_0: 2.9747252464294434  (2.9747252464294434)\n",
      "     | > loss_gen: 1.6041991710662842  (1.6041991710662842)\n",
      "     | > loss_kl: 2.7847018241882324  (2.7847018241882324)\n",
      "     | > loss_feat: 0.6217526197433472  (0.6217526197433472)\n",
      "     | > loss_mel: 62.29728317260742  (62.29728317260742)\n",
      "     | > loss_duration: 2.619922399520874  (2.619922399520874)\n",
      "     | > loss_1: 69.9278564453125  (69.9278564453125)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 3.0899081230163574  (3.0899081230163574)\n",
      "     | > loss_disc_real_0: 0.2353300005197525  (0.2353300005197525)\n",
      "     | > loss_disc_real_1: 0.23704499006271362  (0.23704499006271362)\n",
      "     | > loss_disc_real_2: 0.2671225666999817  (0.2671225666999817)\n",
      "     | > loss_disc_real_3: 0.32696661353111267  (0.32696661353111267)\n",
      "     | > loss_disc_real_4: 0.3918340504169464  (0.3918340504169464)\n",
      "     | > loss_disc_real_5: 0.14259199798107147  (0.14259199798107147)\n",
      "     | > loss_0: 3.0899081230163574  (3.0899081230163574)\n",
      "     | > loss_gen: 1.619883418083191  (1.619883418083191)\n",
      "     | > loss_kl: 2.281982898712158  (2.281982898712158)\n",
      "     | > loss_feat: 0.09966837614774704  (0.09966837614774704)\n",
      "     | > loss_mel: 44.18148422241211  (44.18148422241211)\n",
      "     | > loss_duration: 2.58008074760437  (2.58008074760437)\n",
      "     | > loss_1: 50.76310348510742  (50.76310348510742)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.0062410831451416016 \u001b[0m(+0.00033664703369140625)\n",
      "     | > avg_loss_disc:\u001b[92m 3.0899081230163574 \u001b[0m(-0.04107403755187988)\n",
      "     | > avg_loss_disc_real_0:\u001b[92m 0.2353300005197525 \u001b[0m(-0.013875991106033325)\n",
      "     | > avg_loss_disc_real_1:\u001b[92m 0.23704499006271362 \u001b[0m(-0.1680973470211029)\n",
      "     | > avg_loss_disc_real_2:\u001b[92m 0.2671225666999817 \u001b[0m(-0.12242677807807922)\n",
      "     | > avg_loss_disc_real_3:\u001b[92m 0.32696661353111267 \u001b[0m(-0.007999509572982788)\n",
      "     | > avg_loss_disc_real_4:\u001b[91m 0.3918340504169464 \u001b[0m(+0.022310197353363037)\n",
      "     | > avg_loss_disc_real_5:\u001b[92m 0.14259199798107147 \u001b[0m(-0.2130807787179947)\n",
      "     | > avg_loss_0:\u001b[92m 3.0899081230163574 \u001b[0m(-0.04107403755187988)\n",
      "     | > avg_loss_gen:\u001b[92m 1.619883418083191 \u001b[0m(-0.4966694116592407)\n",
      "     | > avg_loss_kl:\u001b[92m 2.281982898712158 \u001b[0m(-2.0833334922790527)\n",
      "     | > avg_loss_feat:\u001b[91m 0.09966837614774704 \u001b[0m(+0.06574178859591484)\n",
      "     | > avg_loss_mel:\u001b[92m 44.18148422241211 \u001b[0m(-30.011783599853516)\n",
      "     | > avg_loss_duration:\u001b[92m 2.58008074760437 \u001b[0m(-0.02541804313659668)\n",
      "     | > avg_loss_1:\u001b[92m 50.76310348510742 \u001b[0m(-32.55146408081055)\n",
      "\n",
      " > BEST MODEL : /home/ubuntu/tyler1/vitstts_checkpoint/vits_tyler1_phonemes-January-23-2024_09+21AM-1edd3ad/best_model_45.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 3/5000\u001b[0m\n",
      " --> /home/ubuntu/tyler1/vitstts_checkpoint/vits_tyler1_phonemes-January-23-2024_09+21AM-1edd3ad\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-23 09:24:25) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-23 09:24:31 -- STEP: 5/15 -- GLOBAL_STEP: 50\u001b[0m\n",
      "     | > loss_disc: 2.7556090354919434  (2.9253257751464843)\n",
      "     | > loss_disc_real_0: 0.22334444522857666  (0.2274113893508911)\n",
      "     | > loss_disc_real_1: 0.25070837140083313  (0.313273549079895)\n",
      "     | > loss_disc_real_2: 0.2203742116689682  (0.2986582487821579)\n",
      "     | > loss_disc_real_3: 0.1738847941160202  (0.2662394791841507)\n",
      "     | > loss_disc_real_4: 0.1882675588130951  (0.17741011679172516)\n",
      "     | > loss_disc_real_5: 0.29293814301490784  (0.29286031424999237)\n",
      "     | > loss_0: 2.7556090354919434  (2.9253257751464843)\n",
      "     | > grad_norm_0: tensor(2.5783, device='cuda:0')  (tensor(3.1745, device='cuda:0'))\n",
      "     | > loss_gen: 1.7455880641937256  (1.750856304168701)\n",
      "     | > loss_kl: 6.7382917404174805  (4.331829690933228)\n",
      "     | > loss_feat: 1.6592497825622559  (0.836414384841919)\n",
      "     | > loss_mel: 58.71286392211914  (62.141282653808595)\n",
      "     | > loss_duration: 2.1625137329101562  (1.9895848751068115)\n",
      "     | > amp_scaler: 256.0  (460.8)\n",
      "     | > loss_1: 71.01850891113281  (71.04996871948242)\n",
      "     | > grad_norm_1: 0  (tensor(195.7720, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019992500937460937 \n",
      "     | > current_lr_1: 0.00019992500937460937 \n",
      "     | > step_time: 1.4922  (1.0380194187164307)\n",
      "     | > loader_time: 0.0092  (0.006906032562255859)\n",
      "\n",
      " > Keyboard interrupt detected.\n",
      " > Saving model before exiting...\n",
      "\n",
      " > CHECKPOINT : /home/ubuntu/tyler1/vitstts_checkpoint/vits_tyler1_phonemes-January-23-2024_09+21AM-1edd3ad/checkpoint_56.pth\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
