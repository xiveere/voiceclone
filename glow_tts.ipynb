{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef9f4479-ac3a-4afe-b68a-10f825ca0529",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig, CharactersConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.utils.speakers import SpeakerManager\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "\n",
    "from TTS.tts.models.vits import Vits, VitsArgs, VitsAudioConfig\n",
    "from TTS.tts.configs.vits_config import VitsConfig\n",
    "\n",
    "from TTS.tts.models.glow_tts import GlowTTS\n",
    "from TTS.tts.configs.glow_tts_config import GlowTTSConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e45337-335e-46bf-b792-7b6c87974844",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.dirname(os.path.abspath('__file__'))\n",
    "\n",
    "dataset_config = BaseDatasetConfig(\n",
    "    formatter=\"ljspeech\", meta_file_train=\"Mixed_formatted.txt\", path=os.path.join(output_path, \"data/\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c2faf7-ee3d-4811-9a41-091bbaa3bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GlowTTSConfig(\n",
    "    batch_size=8,\n",
    "    eval_batch_size=2,\n",
    "    num_loader_workers=16,\n",
    "    num_eval_loader_workers=2,\n",
    "    run_eval=True,\n",
    "    test_delay_epochs=-1,\n",
    "    epochs=5000,\n",
    "    text_cleaner=\"phoneme_cleaners\",\n",
    "    use_phonemes=True,\n",
    "    phoneme_language=\"en-us\",\n",
    "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
    "    print_step=50,\n",
    "    print_eval=False,\n",
    "    mixed_precision=True,\n",
    "    output_path=output_path + '/glowtts_checkpoint',\n",
    "    datasets=[dataset_config],\n",
    "    lr = 1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23500c41-c52e-4a95-8006-18c7bdd151ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:45\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n"
     ]
    }
   ],
   "source": [
    "ap = AudioProcessor.init_from_config(config)\n",
    "\n",
    "tokenizer, config = TTSTokenizer.init_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59fc8653-77f6-4043-8bda-469a3a3f90ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatter(root_path, manifest_file, **kwargs):  # pylint: disable=unused-argument\n",
    "    \"\"\"Assumes each line as ```<filename>|<transcription>```\n",
    "    \"\"\"\n",
    "    txt_file = os.path.join(root_path, manifest_file)\n",
    "    items = []\n",
    "    speaker_name = \"Tyler1\"\n",
    "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
    "        for line in ttf:\n",
    "            cols = line.split(\"|\")\n",
    "            wav_file = os.path.dirname(os.path.abspath('__file__')) + f\"/data/wavs/{cols[0]}.wav\"\n",
    "            text = cols[1]\n",
    "            # print(text)\n",
    "            items.append({\"text\":text, \"audio_file\":wav_file, \"speaker_name\":speaker_name, \"root_path\": root_path})\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "401b79c5-a8b6-43df-8f12-d9af73bca21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Found 60 files in /home/ubuntu/tyler1/data\n"
     ]
    }
   ],
   "source": [
    "train_samples, eval_samples = load_tts_samples(\n",
    "    dataset_config,\n",
    "    eval_split=True,\n",
    "    eval_split_max_size=config.eval_split_max_size,\n",
    "    eval_split_size=0.05,\n",
    "    formatter=formatter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "305727f8-ec49-4f68-b674-2f930e6d9666",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: True\n",
      " | > Precision: fp16\n",
      " | > Current device: 0\n",
      " | > Num. of GPUs: 1\n",
      " | > Num. of CPUs: 30\n",
      " | > Num. of Torch Threads: 30\n",
      " | > Torch seed: 54321\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      "2024-01-13 10:24:18.264151: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-13 10:24:18.307533: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F AVX512_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      " > Start Tensorboard: tensorboard --logdir=/home/ubuntu/tyler1/glowtts_checkpoint/run-January-13-2024_10+24AM-f3397c1\n",
      "\n",
      " > Model has 28610257 parameters\n"
     ]
    }
   ],
   "source": [
    "# init model\n",
    "\n",
    "model = GlowTTS(config, ap, tokenizer, speaker_manager=None)\n",
    "\n",
    "# init trainer\n",
    "trainer = Trainer(\n",
    "    TrainerArgs(),\n",
    "    config,\n",
    "    output_path,\n",
    "    model=model,\n",
    "    train_samples=train_samples,\n",
    "    eval_samples=eval_samples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea35a466-ec20-4c9a-8533-a9d30aa2a98a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/5000\u001b[0m\n",
      " --> /home/ubuntu/tyler1/glowtts_checkpoint/run-January-13-2024_10+24AM-f3397c1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-13 10:24:20) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: gruut\n",
      "| > Number of instances : 57\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 1462\n",
      " | > Min text length: 131\n",
      " | > Avg text length: 685.6491228070175\n",
      " | \n",
      " | > Max audio length: 7408822.0\n",
      " | > Min audio length: 578318.0\n",
      " | > Avg audio length: 3487299.50877193\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2024-01-13 10:24:24 -- STEP: 0/8 -- GLOBAL_STEP: 0\u001b[0m\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.7199  (1.719942569732666)\n",
      "     | > loader_time: 2.0312  (2.031230926513672)\n",
      "\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: gruut\n",
      "| > Number of instances : 3\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 1148\n",
      " | > Min text length: 261\n",
      " | > Avg text length: 681.3333333333334\n",
      " | \n",
      " | > Max audio length: 6162562.0\n",
      " | > Min audio length: 1429014.0\n",
      " | > Avg audio length: 3654345.3333333335\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time: 0.0023560523986816406 \u001b[0m(+0)\n",
      "     | > avg_loss: 3.2444334030151367 \u001b[0m(+0)\n",
      "     | > avg_log_mle: 1.7664422988891602 \u001b[0m(+0)\n",
      "     | > avg_loss_dur: 1.4779911041259766 \u001b[0m(+0)\n",
      "\n",
      " > BEST MODEL : /home/ubuntu/tyler1/glowtts_checkpoint/run-January-13-2024_10+24AM-f3397c1/best_model_8.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 1/5000\u001b[0m\n",
      " --> /home/ubuntu/tyler1/glowtts_checkpoint/run-January-13-2024_10+24AM-f3397c1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-13 10:24:56) \u001b[0m\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      " > Keyboard interrupt detected.\n",
      " > Saving model before exiting...\n",
      "\n",
      " > CHECKPOINT : /home/ubuntu/tyler1/glowtts_checkpoint/run-January-13-2024_10+24AM-f3397c1/checkpoint_16.pth\n",
      " ! Run is kept in /home/ubuntu/tyler1/glowtts_checkpoint/run-January-13-2024_10+24AM-f3397c1\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256897a7-6fd6-4a23-ba06-af949cb96040",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
