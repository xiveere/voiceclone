{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f28fb199-18c3-40b6-a0e6-40085920b023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flush CUDA cache\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82b468c8-f92e-411b-83cd-35c9f20e05f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change continue_path in vits_tts.py to match --continue_path arg if needed\n",
    "# !CUDA_VISIBLE_DEVICES=\"0,1,2,3\"  python -m trainer.distribute --script vits_tts.py --continue_path \"vitstts_checkpoint/vits_tyler1_phonemes-February-29-2024_09+00AM-e526ca1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4587b9-c0bd-4ae6-a504-59f9ba1137fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vits_tts.py', '--continue_path=', '--restore_path=vitstts_checkpoint/tts_models--en--ljspeech--vits/model_file.pth', '--group_id=group_2024_03_01-073840', '--use_ddp=true', '--rank=0']\n",
      "['vits_tts.py', '--continue_path=', '--restore_path=vitstts_checkpoint/tts_models--en--ljspeech--vits/model_file.pth', '--group_id=group_2024_03_01-073840', '--use_ddp=true', '--rank=1']\n",
      "['vits_tts.py', '--continue_path=', '--restore_path=vitstts_checkpoint/tts_models--en--ljspeech--vits/model_file.pth', '--group_id=group_2024_03_01-073840', '--use_ddp=true', '--rank=2']\n",
      "['vits_tts.py', '--continue_path=', '--restore_path=vitstts_checkpoint/tts_models--en--ljspeech--vits/model_file.pth', '--group_id=group_2024_03_01-073840', '--use_ddp=true', '--rank=3']\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " | > Found 558 files in /home/sagemaker-user/dist/main/data\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " | > Found 558 files in /home/sagemaker-user/dist/main/data\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " | > Found 558 files in /home/sagemaker-user/dist/main/data\n",
      " | > Found 558 files in /home/sagemaker-user/dist/main/data\n",
      "[W socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:54321 (errno: 99 - Cannot assign requested address).\n",
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: True\n",
      " | > Precision: fp16\n",
      " | > Current device: 0\n",
      " | > Num. of GPUs: 4\n",
      " | > Num. of CPUs: 48\n",
      " | > Num. of Torch Threads: 24\n",
      " | > Torch seed: 54321\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      "[W socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:54321 (errno: 99 - Cannot assign requested address).\n",
      "[W socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:54321 (errno: 99 - Cannot assign requested address).\n",
      "2024-03-01 07:38:48.058838: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[W socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:54321 (errno: 99 - Cannot assign requested address).\n",
      "[W socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:54321 (errno: 99 - Cannot assign requested address).\n",
      "[W socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:54321 (errno: 99 - Cannot assign requested address).\n",
      "[W socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:54321 (errno: 99 - Cannot assign requested address).\n",
      " > Start Tensorboard: tensorboard --logdir=/home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      " > Using PyTorch DDP\n",
      " > Restoring from model_file.pth ...\n",
      " > Restoring Model...\n",
      " > Partial model initialization...\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.0.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.0.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.1.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.1.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.2.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.2.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.3.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.3.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.4.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.4.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.5.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.5.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.6.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.6.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.7.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.7.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.8.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.8.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.9.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.9.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.10.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.10.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.11.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.11.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.12.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.12.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.13.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.13.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.14.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.14.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.15.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.in_layers.15.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.0.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.0.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.1.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.1.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.2.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.2.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.3.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.3.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.4.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.4.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.5.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.5.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.6.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.6.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.7.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.7.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.8.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.8.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.9.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.9.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.10.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.10.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.11.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.11.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.12.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.12.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.13.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.13.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.14.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.14.weight_v\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.15.weight_g\n",
      " | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.15.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.in_layers.0.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.in_layers.0.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.in_layers.1.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.in_layers.1.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.in_layers.2.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.in_layers.2.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.in_layers.3.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.in_layers.3.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.0.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.0.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.1.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.1.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.2.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.2.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.3.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.3.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.in_layers.0.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.in_layers.0.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.in_layers.1.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.in_layers.1.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.in_layers.2.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.in_layers.2.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.in_layers.3.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.in_layers.3.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.0.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.0.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.1.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.1.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.2.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.2.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.3.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.3.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.in_layers.0.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.in_layers.0.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.in_layers.1.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.in_layers.1.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.in_layers.2.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.in_layers.2.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.in_layers.3.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.in_layers.3.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.0.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.0.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.1.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.1.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.2.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.2.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.3.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.3.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.in_layers.0.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.in_layers.0.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.in_layers.1.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.in_layers.1.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.in_layers.2.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.in_layers.2.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.in_layers.3.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.in_layers.3.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.0.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.0.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.1.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.1.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.2.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.2.weight_v\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.3.weight_g\n",
      " | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.3.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.ups.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.ups.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.ups.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.ups.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.ups.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.ups.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.ups.3.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.ups.3.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs2.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs1.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs1.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs1.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs1.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs1.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs1.2.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs2.0.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs2.0.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs2.1.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs2.1.weight_v\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs2.2.weight_g\n",
      " | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs2.2.weight_v\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.4.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.4.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.5.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.5.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.6.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.6.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.7.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.7.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.8.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.8.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.9.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.9.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.10.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.10.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.11.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.11.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.12.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.12.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.13.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.13.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.14.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.14.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.15.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.15.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.4.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.4.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.5.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.5.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.6.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.6.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.7.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.7.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.8.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.8.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.9.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.9.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.10.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.10.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.11.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.11.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.12.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.12.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.13.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.13.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.14.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.14.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.15.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.15.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.ups.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.ups.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.ups.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.ups.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.ups.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.ups.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.ups.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.ups.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs1.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs1.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs1.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs1.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs1.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs1.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs2.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs2.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs2.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs2.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs2.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs2.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.0.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.1.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.2.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.3.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.4.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.4.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.4.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.5.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.5.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.5.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.0.conv_post.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.0.conv_post.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.0.conv_post.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.0.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.1.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.2.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.3.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.4.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.4.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.4.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.1.conv_post.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.1.conv_post.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.1.conv_post.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.0.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.1.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.2.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.3.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.4.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.4.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.4.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.2.conv_post.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.2.conv_post.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.2.conv_post.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.0.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.1.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.2.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.3.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.4.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.4.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.4.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.3.conv_post.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.3.conv_post.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.3.conv_post.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.0.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.1.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.2.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.3.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.4.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.4.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.4.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.4.conv_post.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.4.conv_post.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.4.conv_post.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.0.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.0.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.0.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.1.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.1.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.1.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.2.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.2.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.2.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.3.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.3.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.3.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.4.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.4.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.4.parametrizations.weight.original1\n",
      " | > Layer missing in the checkpoint: disc.nets.5.conv_post.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.5.conv_post.parametrizations.weight.original0\n",
      " | > Layer missing in the checkpoint: disc.nets.5.conv_post.parametrizations.weight.original1\n",
      " | > Layer dimention missmatch between model definition and checkpoint: text_encoder.emb.weight\n",
      " | > 557 / 949 layers are restored.\n",
      " > Model restored from step 1000000\n",
      "\n",
      " > Model has 83059180 parameters\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\n",
      "\n",
      "\t| > use_phonemes: True\n",
      "\n",
      "\n",
      "> DataLoader initialization> DataLoader initialization\t| > phonemizer:\n",
      "\n",
      "\n",
      "| > Tokenizer:| > Tokenizer:\n",
      "\n",
      "\t\t| > phoneme language: en-us\t| > add_blank: True\n",
      "\n",
      "\t| > add_blank: True\t| > use_eos_bos: False\t\t| > phoneme backend: espeak\n",
      "\n",
      "\n",
      "\t| > use_phonemes: True\t| > use_eos_bos: False\n",
      "| > Number of instances : 503\n",
      "\t| > phonemizer:\n",
      "\t| > use_phonemes: True\n",
      "\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\t\t| > phoneme language: en-us\n",
      "\n",
      "\t\t| > phoneme backend: espeak\t\t| > phoneme backend: espeak\n",
      "\n",
      "| > Number of instances : 503| > Number of instances : 503\n",
      "\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: espeak\n",
      "| > Number of instances : 503\n",
      " | > Preprocessing samples | > Preprocessing samples\n",
      "\n",
      " | > Max text length: 400 | > Max text length: 400\n",
      "\n",
      " | > Min text length: 26 | > Min text length: 26\n",
      "\n",
      " | > Preprocessing samples\n",
      " | > Avg text length: 178.0854870775348 | > Avg text length: 178.0854870775348\n",
      "\n",
      " |  | \n",
      "\n",
      " | > Max text length: 400\n",
      " | > Max audio length: 606879 | > Max audio length: 606879\n",
      "\n",
      " | > Min audio length: 72765 | > Min audio length: 72765 | > Min text length: 26\n",
      "\n",
      "\n",
      " | > Avg audio length: 206187.1829025845 | > Avg audio length: 206187.1829025845\n",
      "\n",
      " | > Num. instances discarded samples: 0 | > Num. instances discarded samples: 0\n",
      "\n",
      " | > Batch group size: 0. | > Batch group size: 0.\n",
      "\n",
      " | > Avg text length: 178.0854870775348\n",
      " | \n",
      " | > Max audio length: 606879\n",
      " | > Min audio length: 72765\n",
      " | > Avg audio length: 206187.1829025845\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 400\n",
      " | > Min text length: 26\n",
      " | > Avg text length: 178.0854870775348\n",
      " | \n",
      " | > Max audio length: 606879\n",
      " | > Min audio length: 72765\n",
      " | > Avg audio length: 206187.1829025845\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:38:52) \u001b[0m\n",
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:660: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:874.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:660: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:874.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:660: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:874.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:660: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:874.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:39:06 -- STEP: 24/32 -- GLOBAL_STEP: 1000025\u001b[0m\n",
      "     | > loss_disc: 3.0187196731567383  (3.4308770298957825)\n",
      "     | > loss_disc_real_0: 0.27963292598724365  (0.33689315896481276)\n",
      "     | > loss_disc_real_1: 0.22012177109718323  (0.3454773100093007)\n",
      "     | > loss_disc_real_2: 0.24871718883514404  (0.34778113042314845)\n",
      "     | > loss_disc_real_3: 0.21944139897823334  (0.35164113777379197)\n",
      "     | > loss_disc_real_4: 0.23728272318840027  (0.3746634215737383)\n",
      "     | > loss_disc_real_5: 0.21140600740909576  (0.3661355885366599)\n",
      "     | > loss_0: 3.0187196731567383  (3.4308770298957825)\n",
      "     | > grad_norm_0: tensor(1.4548, device='cuda:0')  (tensor(2.4630, device='cuda:0'))\n",
      "     | > loss_gen: 1.656968593597412  (1.9772588908672333)\n",
      "     | > loss_kl: 5.8259100914001465  (12.981624027093254)\n",
      "     | > loss_feat: 1.1817665100097656  (0.6226706200589737)\n",
      "     | > loss_mel: 23.974361419677734  (24.815733273824055)\n",
      "     | > loss_duration: 0.836958646774292  (3.4617550149559975)\n",
      "     | > amp_scaler: 512.0  (1728.0)\n",
      "     | > loss_1: 33.47596740722656  (43.859041929244995)\n",
      "     | > grad_norm_1: tensor(213.7095, device='cuda:0')  (tensor(199.4677, device='cuda:0'))\n",
      "     | > current_lr_0: 0.0002 \n",
      "     | > current_lr_1: 0.0002 \n",
      "     | > step_time: 0.3881  (0.46228774388631183)\n",
      "     | > loader_time: 0.0028  (0.0037464300791422525)\n",
      "\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: espeak\n",
      "| > Number of instances : 55\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: espeak\n",
      "| > Number of instances : 55\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: espeak\n",
      "| > Number of instances : 55\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: espeak\n",
      "| > Number of instances : 55\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 397\n",
      " | > Min text length: 72\n",
      " | > Avg text length: 170.8909090909091\n",
      " |  | > Preprocessing samples\n",
      "\n",
      " | > Max audio length: 447245\n",
      " | > Min audio length: 115395\n",
      " | > Preprocessing samples | > Max text length: 397\n",
      "\n",
      " | > Preprocessing samples | > Avg audio length: 190971.58181818182 | > Min text length: 72\n",
      "\n",
      "\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      " | > Max text length: 397\n",
      " | > Max text length: 397 | > Min text length: 72\n",
      "\n",
      " | > Avg text length: 170.8909090909091\n",
      " | \n",
      " | > Min text length: 72 | > Max audio length: 447245\n",
      "\n",
      " | > Min audio length: 115395\n",
      " | > Avg text length: 170.8909090909091\n",
      " | \n",
      " | > Max audio length: 447245 | > Avg audio length: 190971.58181818182 | > Avg text length: 170.8909090909091\n",
      "\n",
      "\n",
      " | > Num. instances discarded samples: 0 | \n",
      "\n",
      " | > Batch group size: 0. | > Min audio length: 115395\n",
      "\n",
      " | > Max audio length: 447245 | > Avg audio length: 190971.58181818182\n",
      "\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      " | > Min audio length: 115395\n",
      " | > Avg audio length: 190971.58181818182\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "sˌoʊ ˈaɪ wʌz ˈæktʃuːəli, sˌoʊ hiː ɡɑːt ðæt ɡˈoʊld, sˌoʊ hiː wʌz ˈæktʃuːəli dˈɪd ðæt lˈɪɾəl dˈæmɪdʒ. ðə kɹˈeɪzi pˈɑːɹt ɪz hiː fˈɑːɹmd ɐbˌaʊt tˈuː θˈaʊzənd ʌv ðæt æɾ æt ðə vˈɛɹi ˈɛnd ʌvðə ɡˈeɪm. jˈɛh. hiː lˈɪɾɚɹəli wˈʌzn̩t plˈeɪɪŋ. ˈaɪ hæv nˈoʊ aɪdˈiə wˈaɪ. maɪ bˈɑːtleɪn ˈæktʃuːəli tˈuːvθɹiːd ænd hiː hæd ɐ wˈɪnɪŋ tˈɑːp lˈeɪn. ðə jˈɛs, mˈɪdleɪn wʌz dˈɑːɡʃɪt, bˌʌt wiː hæd wˈɪn kəndˈɪʃənz.\n",
      " [!] Character '̩' not found in the vocabulary. Discarding it.\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 3.044276714324951  (3.044276714324951)\n",
      "     | > loss_disc_real_0: 0.25449055433273315  (0.25449055433273315)\n",
      "     | > loss_disc_real_1: 0.21323829889297485  (0.21323829889297485)\n",
      "     | > loss_disc_real_2: 0.2276454120874405  (0.2276454120874405)\n",
      "     | > loss_disc_real_3: 0.21287348866462708  (0.21287348866462708)\n",
      "     | > loss_disc_real_4: 0.21392902731895447  (0.21392902731895447)\n",
      "     | > loss_disc_real_5: 0.16915225982666016  (0.16915225982666016)\n",
      "     | > loss_0: 3.044276714324951  (3.044276714324951)\n",
      "     | > loss_gen: 1.3143295049667358  (1.3143295049667358)\n",
      "     | > loss_kl: 5.614052772521973  (5.614052772521973)\n",
      "     | > loss_feat: 0.6975724101066589  (0.6975724101066589)\n",
      "     | > loss_mel: 23.010780334472656  (23.010780334472656)\n",
      "     | > loss_duration: 1.2800872325897217  (1.2800872325897217)\n",
      "     | > loss_1: 31.916820526123047  (31.916820526123047)\n",
      "\n",
      "hiː kˈɪld hˌɪm. hiː wʌz dˈɛd ˈɛnɪwˌeɪ, bɪkˈʌz ɪf ˈaɪ, ɪf ˈaɪ wˈʌzn̩t ðˈɛɹ, hiː wʌz dˈaɪɪŋ ɹᵻɡˈɑːɹdləs.\n",
      " [!] Character '̩' not found in the vocabulary. Discarding it.\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 3.02241849899292  (3.02241849899292)\n",
      "     | > loss_disc_real_0: 0.255789190530777  (0.255789190530777)\n",
      "     | > loss_disc_real_1: 0.21919775009155273  (0.21919775009155273)\n",
      "     | > loss_disc_real_2: 0.23037667572498322  (0.23037667572498322)\n",
      "     | > loss_disc_real_3: 0.21502481400966644  (0.21502481400966644)\n",
      "     | > loss_disc_real_4: 0.21585866808891296  (0.21585866808891296)\n",
      "     | > loss_disc_real_5: 0.18040530383586884  (0.18040530383586884)\n",
      "     | > loss_0: 3.02241849899292  (3.02241849899292)\n",
      "     | > loss_gen: 1.3486888408660889  (1.3486888408660889)\n",
      "     | > loss_kl: 7.1741533279418945  (7.1741533279418945)\n",
      "     | > loss_feat: 0.5357404351234436  (0.5357404351234436)\n",
      "     | > loss_mel: 30.643774032592773  (30.643774032592773)\n",
      "     | > loss_duration: 1.1663860082626343  (1.1663860082626343)\n",
      "     | > loss_1: 40.868743896484375  (40.868743896484375)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 3.0503735542297363  (3.036396026611328)\n",
      "     | > loss_disc_real_0: 0.25530123710632324  (0.2555452138185501)\n",
      "     | > loss_disc_real_1: 0.21688628196716309  (0.2180420160293579)\n",
      "     | > loss_disc_real_2: 0.22985535860061646  (0.23011601716279984)\n",
      "     | > loss_disc_real_3: 0.21516084671020508  (0.21509283035993576)\n",
      "     | > loss_disc_real_4: 0.21683600544929504  (0.216347336769104)\n",
      "     | > loss_disc_real_5: 0.17795133590698242  (0.17917831987142563)\n",
      "     | > loss_0: 3.0503735542297363  (3.036396026611328)\n",
      "     | > loss_gen: 1.3292125463485718  (1.3389506936073303)\n",
      "     | > loss_kl: 5.084502696990967  (6.129328012466431)\n",
      "     | > loss_feat: 0.4043891727924347  (0.47006480395793915)\n",
      "     | > loss_mel: 21.995895385742188  (26.31983470916748)\n",
      "     | > loss_duration: 1.4402456283569336  (1.303315818309784)\n",
      "     | > loss_1: 30.25424575805664  (35.56149482727051)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 3.032165050506592  (3.0349857012430825)\n",
      "     | > loss_disc_real_0: 0.24833132326602936  (0.2531405836343765)\n",
      "     | > loss_disc_real_1: 0.1837085336446762  (0.20659752190113068)\n",
      "     | > loss_disc_real_2: 0.1993688941001892  (0.21986697614192963)\n",
      "     | > loss_disc_real_3: 0.1789192259311676  (0.20303496221701303)\n",
      "     | > loss_disc_real_4: 0.17056381702423096  (0.201086163520813)\n",
      "     | > loss_disc_real_5: 0.1324714720249176  (0.1636093705892563)\n",
      "     | > loss_0: 3.032165050506592  (3.0349857012430825)\n",
      "     | > loss_gen: 1.196753740310669  (1.2915517091751099)\n",
      "     | > loss_kl: 5.825119972229004  (6.027925332387288)\n",
      "     | > loss_feat: 1.2556519508361816  (0.7319271862506866)\n",
      "     | > loss_mel: 24.108379364013672  (25.582682927449543)\n",
      "     | > loss_duration: 0.8117091059684753  (1.1394469141960144)\n",
      "     | > loss_1: 33.19761657714844  (34.77353541056315)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 3.0210022926330566  (3.031489849090576)\n",
      "     | > loss_disc_real_0: 0.2537226378917694  (0.25328609719872475)\n",
      "     | > loss_disc_real_1: 0.20601814985275269  (0.20645267888903618)\n",
      "     | > loss_disc_real_2: 0.2216888815164566  (0.22032245248556137)\n",
      "     | > loss_disc_real_3: 0.20429928600788116  (0.20335104316473007)\n",
      "     | > loss_disc_real_4: 0.20430795848369598  (0.20189161226153374)\n",
      "     | > loss_disc_real_5: 0.16414965689182281  (0.16374444216489792)\n",
      "     | > loss_0: 3.0210022926330566  (3.031489849090576)\n",
      "     | > loss_gen: 1.3039346933364868  (1.294647455215454)\n",
      "     | > loss_kl: 6.140231132507324  (6.056001782417297)\n",
      "     | > loss_feat: 0.7352138757705688  (0.7327488586306572)\n",
      "     | > loss_mel: 22.391494750976562  (24.7848858833313)\n",
      "     | > loss_duration: 1.0056824684143066  (1.1060058027505875)\n",
      "     | > loss_1: 31.576555252075195  (33.97429037094116)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 3.059900999069214  (3.0371720790863037)\n",
      "     | > loss_disc_real_0: 0.2487555891275406  (0.2523799955844879)\n",
      "     | > loss_disc_real_1: 0.18621285259723663  (0.20240471363067628)\n",
      "     | > loss_disc_real_2: 0.20206955075263977  (0.21667187213897704)\n",
      "     | > loss_disc_real_3: 0.1825876086950302  (0.1991983562707901)\n",
      "     | > loss_disc_real_4: 0.17738379538059235  (0.19699004888534546)\n",
      "     | > loss_disc_real_5: 0.1331881582736969  (0.15763318538665771)\n",
      "     | > loss_0: 3.059900999069214  (3.0371720790863037)\n",
      "     | > loss_gen: 1.1879125833511353  (1.2733004808425903)\n",
      "     | > loss_kl: 4.909700393676758  (5.826741504669189)\n",
      "     | > loss_feat: 1.136431097984314  (0.8134853065013885)\n",
      "     | > loss_mel: 23.22458839416504  (24.472826385498045)\n",
      "     | > loss_duration: 1.228395700454712  (1.1304837822914124)\n",
      "     | > loss_1: 31.687026977539062  (33.516837692260744)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 2.985161304473877  (3.0285036166508994)\n",
      "     | > loss_disc_real_0: 0.24468401074409485  (0.2510973314444224)\n",
      "     | > loss_disc_real_1: 0.16530129313468933  (0.19622081021467844)\n",
      "     | > loss_disc_real_2: 0.1808946579694748  (0.21070900311072668)\n",
      "     | > loss_disc_real_3: 0.16109919548034668  (0.19284849613904953)\n",
      "     | > loss_disc_real_4: 0.1490204930305481  (0.1889951229095459)\n",
      "     | > loss_disc_real_5: 0.10382258892059326  (0.14866475264231363)\n",
      "     | > loss_0: 2.985161304473877  (3.0285036166508994)\n",
      "     | > loss_gen: 1.1527189016342163  (1.253203550974528)\n",
      "     | > loss_kl: 5.509315490722656  (5.773837169011434)\n",
      "     | > loss_feat: 1.7788665294647217  (0.9743821769952774)\n",
      "     | > loss_mel: 26.444908142089844  (24.801506678263348)\n",
      "     | > loss_duration: 1.036780834197998  (1.1148666242758434)\n",
      "     | > loss_1: 35.92258834838867  (33.91779613494873)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "/home/sagemaker-user/TTS/TTS/tts/models/vits.py:1455: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  test_figures[\"{}-alignment\".format(idx)] = plot_alignment(alignment.T, output_fig=False)\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time: 0.0026081005732218423 \u001b[0m(+0)\n",
      "     | > avg_loss_disc: 3.0285036166508994 \u001b[0m(+0)\n",
      "     | > avg_loss_disc_real_0: 0.2510973314444224 \u001b[0m(+0)\n",
      "     | > avg_loss_disc_real_1: 0.19622081021467844 \u001b[0m(+0)\n",
      "     | > avg_loss_disc_real_2: 0.21070900311072668 \u001b[0m(+0)\n",
      "     | > avg_loss_disc_real_3: 0.19284849613904953 \u001b[0m(+0)\n",
      "     | > avg_loss_disc_real_4: 0.1889951229095459 \u001b[0m(+0)\n",
      "     | > avg_loss_disc_real_5: 0.14866475264231363 \u001b[0m(+0)\n",
      "     | > avg_loss_0: 3.0285036166508994 \u001b[0m(+0)\n",
      "     | > avg_loss_gen: 1.253203550974528 \u001b[0m(+0)\n",
      "     | > avg_loss_kl: 5.773837169011434 \u001b[0m(+0)\n",
      "     | > avg_loss_feat: 0.9743821769952774 \u001b[0m(+0)\n",
      "     | > avg_loss_mel: 24.801506678263348 \u001b[0m(+0)\n",
      "     | > avg_loss_duration: 1.1148666242758434 \u001b[0m(+0)\n",
      "     | > avg_loss_1: 33.91779613494873 \u001b[0m(+0)\n",
      "\n",
      " > BEST MODEL : /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1/best_model_1000033.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 1/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:39:16) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:39:24 -- STEP: 17/32 -- GLOBAL_STEP: 1000050\u001b[0m\n",
      "     | > loss_disc: 2.8677048683166504  (2.979074015336878)\n",
      "     | > loss_disc_real_0: 0.23235924541950226  (0.2506859022028306)\n",
      "     | > loss_disc_real_1: 0.19216720759868622  (0.25798408599460826)\n",
      "     | > loss_disc_real_2: 0.20806927978992462  (0.2588070438188665)\n",
      "     | > loss_disc_real_3: 0.18293210864067078  (0.2601036061258877)\n",
      "     | > loss_disc_real_4: 0.19206108152866364  (0.2596072317922817)\n",
      "     | > loss_disc_real_5: 0.1835060566663742  (0.259416161214604)\n",
      "     | > loss_0: 2.8677048683166504  (2.979074015336878)\n",
      "     | > grad_norm_0: tensor(1.7556, device='cuda:0')  (tensor(1.3138, device='cuda:0'))\n",
      "     | > loss_gen: 1.3815150260925293  (1.6030570829615873)\n",
      "     | > loss_kl: 4.933537006378174  (5.363025973824894)\n",
      "     | > loss_feat: 1.2717946767807007  (0.8265933482085958)\n",
      "     | > loss_mel: 23.520647048950195  (24.306531008552103)\n",
      "     | > loss_duration: 1.45330011844635  (3.3060932019177605)\n",
      "     | > amp_scaler: 256.0  (316.2352941176471)\n",
      "     | > loss_1: 32.560794830322266  (35.40530115015367)\n",
      "     | > grad_norm_1: tensor(202.1695, device='cuda:0')  (tensor(253.1747, device='cuda:0'))\n",
      "     | > current_lr_0: 0.000199975 \n",
      "     | > current_lr_1: 0.000199975 \n",
      "     | > step_time: 0.367  (0.371138053781846)\n",
      "     | > loader_time: 0.0033  (0.003455975476433249)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.9944801330566406  (2.9944801330566406)\n",
      "     | > loss_disc_real_0: 0.202688068151474  (0.202688068151474)\n",
      "     | > loss_disc_real_1: 0.2745203971862793  (0.2745203971862793)\n",
      "     | > loss_disc_real_2: 0.2848358154296875  (0.2848358154296875)\n",
      "     | > loss_disc_real_3: 0.28583621978759766  (0.28583621978759766)\n",
      "     | > loss_disc_real_4: 0.2535483241081238  (0.2535483241081238)\n",
      "     | > loss_disc_real_5: 0.24026411771774292  (0.24026411771774292)\n",
      "     | > loss_0: 2.9944801330566406  (2.9944801330566406)\n",
      "     | > loss_gen: 1.5699691772460938  (1.5699691772460938)\n",
      "     | > loss_kl: 4.786034107208252  (4.786034107208252)\n",
      "     | > loss_feat: 0.7218202352523804  (0.7218202352523804)\n",
      "     | > loss_mel: 23.845983505249023  (23.845983505249023)\n",
      "     | > loss_duration: 1.4161252975463867  (1.4161252975463867)\n",
      "     | > loss_1: 32.33993148803711  (32.33993148803711)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.9449563026428223  (2.9449563026428223)\n",
      "     | > loss_disc_real_0: 0.18340782821178436  (0.18340782821178436)\n",
      "     | > loss_disc_real_1: 0.2759050130844116  (0.2759050130844116)\n",
      "     | > loss_disc_real_2: 0.2821822762489319  (0.2821822762489319)\n",
      "     | > loss_disc_real_3: 0.2850534915924072  (0.2850534915924072)\n",
      "     | > loss_disc_real_4: 0.2529771029949188  (0.2529771029949188)\n",
      "     | > loss_disc_real_5: 0.2355494201183319  (0.2355494201183319)\n",
      "     | > loss_0: 2.9449563026428223  (2.9449563026428223)\n",
      "     | > loss_gen: 1.5918747186660767  (1.5918747186660767)\n",
      "     | > loss_kl: 5.86736536026001  (5.86736536026001)\n",
      "     | > loss_feat: 0.8801179528236389  (0.8801179528236389)\n",
      "     | > loss_mel: 41.03133773803711  (41.03133773803711)\n",
      "     | > loss_duration: 1.2973079681396484  (1.2973079681396484)\n",
      "     | > loss_1: 50.667999267578125  (50.667999267578125)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 3.0149383544921875  (2.979947328567505)\n",
      "     | > loss_disc_real_0: 0.21727845072746277  (0.20034313946962357)\n",
      "     | > loss_disc_real_1: 0.28090739250183105  (0.27840620279312134)\n",
      "     | > loss_disc_real_2: 0.2979668974876404  (0.29007458686828613)\n",
      "     | > loss_disc_real_3: 0.295072466135025  (0.2900629788637161)\n",
      "     | > loss_disc_real_4: 0.26485586166381836  (0.2589164823293686)\n",
      "     | > loss_disc_real_5: 0.2497950941324234  (0.24267225712537766)\n",
      "     | > loss_0: 3.0149383544921875  (2.979947328567505)\n",
      "     | > loss_gen: 1.611722707748413  (1.6017987132072449)\n",
      "     | > loss_kl: 3.9857394695281982  (4.926552414894104)\n",
      "     | > loss_feat: 0.3039797246456146  (0.5920488387346268)\n",
      "     | > loss_mel: 20.581701278686523  (30.806519508361816)\n",
      "     | > loss_duration: 1.5827730894088745  (1.4400405287742615)\n",
      "     | > loss_1: 28.065916061401367  (39.366957664489746)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 2.9929237365722656  (2.9842727979024253)\n",
      "     | > loss_disc_real_0: 0.2151174247264862  (0.2052679012219111)\n",
      "     | > loss_disc_real_1: 0.273794025182724  (0.2768688102563222)\n",
      "     | > loss_disc_real_2: 0.2935962677001953  (0.29124848047892254)\n",
      "     | > loss_disc_real_3: 0.2917022109031677  (0.2906093895435333)\n",
      "     | > loss_disc_real_4: 0.26150742173194885  (0.2597801287968953)\n",
      "     | > loss_disc_real_5: 0.23868833482265472  (0.24134428302447)\n",
      "     | > loss_0: 2.9929237365722656  (2.9842727979024253)\n",
      "     | > loss_gen: 1.6004197597503662  (1.601339062054952)\n",
      "     | > loss_kl: 5.599498271942139  (5.150867700576782)\n",
      "     | > loss_feat: 0.37697434425354004  (0.5203573405742645)\n",
      "     | > loss_mel: 23.196041107177734  (28.26969337463379)\n",
      "     | > loss_duration: 0.9549682140350342  (1.278349757194519)\n",
      "     | > loss_1: 31.727901458740234  (36.82060559590658)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 3.0247256755828857  (2.9943860173225403)\n",
      "     | > loss_disc_real_0: 0.21271982789039612  (0.20713088288903236)\n",
      "     | > loss_disc_real_1: 0.28189799189567566  (0.2781261056661606)\n",
      "     | > loss_disc_real_2: 0.295494943857193  (0.29231009632349014)\n",
      "     | > loss_disc_real_3: 0.2934161424636841  (0.291311077773571)\n",
      "     | > loss_disc_real_4: 0.2641741931438446  (0.26087864488363266)\n",
      "     | > loss_disc_real_5: 0.24281497299671173  (0.24171195551753044)\n",
      "     | > loss_0: 3.0247256755828857  (2.9943860173225403)\n",
      "     | > loss_gen: 1.5889818668365479  (1.598249763250351)\n",
      "     | > loss_kl: 4.656607151031494  (5.02730256319046)\n",
      "     | > loss_feat: 0.5507495999336243  (0.5279554054141045)\n",
      "     | > loss_mel: 21.142446517944336  (26.487881660461426)\n",
      "     | > loss_duration: 1.137006163597107  (1.243013858795166)\n",
      "     | > loss_1: 29.07579231262207  (34.88440227508545)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 2.985424041748047  (2.9925936222076417)\n",
      "     | > loss_disc_real_0: 0.2143874168395996  (0.20858218967914582)\n",
      "     | > loss_disc_real_1: 0.2776387929916382  (0.2780286431312561)\n",
      "     | > loss_disc_real_2: 0.29485100507736206  (0.2928182780742645)\n",
      "     | > loss_disc_real_3: 0.29332324862480164  (0.2917135119438171)\n",
      "     | > loss_disc_real_4: 0.26186999678611755  (0.2610769152641296)\n",
      "     | > loss_disc_real_5: 0.24593348801136017  (0.24255626201629638)\n",
      "     | > loss_0: 2.985424041748047  (2.9925936222076417)\n",
      "     | > loss_gen: 1.6219761371612549  (1.6029950380325317)\n",
      "     | > loss_kl: 4.798611164093018  (4.981564283370972)\n",
      "     | > loss_feat: 0.35238897800445557  (0.4928421199321747)\n",
      "     | > loss_mel: 23.358009338378906  (25.86190719604492)\n",
      "     | > loss_duration: 1.4110468626022339  (1.2766204595565795)\n",
      "     | > loss_1: 31.542034149169922  (34.215928649902345)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 3.0120527744293213  (2.9958368142445884)\n",
      "     | > loss_disc_real_0: 0.22474469244480133  (0.2112759401400884)\n",
      "     | > loss_disc_real_1: 0.2821527123451233  (0.27871598800023395)\n",
      "     | > loss_disc_real_2: 0.30070582032203674  (0.29413286844889325)\n",
      "     | > loss_disc_real_3: 0.2988668978214264  (0.2929057429234187)\n",
      "     | > loss_disc_real_4: 0.2684995234012604  (0.2623140166203181)\n",
      "     | > loss_disc_real_5: 0.2530919909477234  (0.2443122168382009)\n",
      "     | > loss_0: 3.0120527744293213  (2.9958368142445884)\n",
      "     | > loss_gen: 1.6348810195922852  (1.6083093682924907)\n",
      "     | > loss_kl: 4.346102714538574  (4.875654021898906)\n",
      "     | > loss_feat: 0.17048099637031555  (0.4391152660051982)\n",
      "     | > loss_mel: 23.410675048828125  (25.45336850484212)\n",
      "     | > loss_duration: 1.175898790359497  (1.2598335146903992)\n",
      "     | > loss_1: 30.738040924072266  (33.63628069559733)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0025005340576171875 \u001b[0m(-0.0001075665156046548)\n",
      "     | > avg_loss_disc:\u001b[92m 2.9958368142445884 \u001b[0m(-0.032666802406311035)\n",
      "     | > avg_loss_disc_real_0:\u001b[92m 0.2112759401400884 \u001b[0m(-0.039821391304334014)\n",
      "     | > avg_loss_disc_real_1:\u001b[91m 0.27871598800023395 \u001b[0m(+0.08249517778555551)\n",
      "     | > avg_loss_disc_real_2:\u001b[91m 0.29413286844889325 \u001b[0m(+0.08342386533816656)\n",
      "     | > avg_loss_disc_real_3:\u001b[91m 0.2929057429234187 \u001b[0m(+0.10005724678436917)\n",
      "     | > avg_loss_disc_real_4:\u001b[91m 0.2623140166203181 \u001b[0m(+0.07331889371077221)\n",
      "     | > avg_loss_disc_real_5:\u001b[91m 0.2443122168382009 \u001b[0m(+0.09564746419588727)\n",
      "     | > avg_loss_0:\u001b[92m 2.9958368142445884 \u001b[0m(-0.032666802406311035)\n",
      "     | > avg_loss_gen:\u001b[91m 1.6083093682924907 \u001b[0m(+0.35510581731796265)\n",
      "     | > avg_loss_kl:\u001b[92m 4.875654021898906 \u001b[0m(-0.8981831471125279)\n",
      "     | > avg_loss_feat:\u001b[92m 0.4391152660051982 \u001b[0m(-0.5352669109900792)\n",
      "     | > avg_loss_mel:\u001b[91m 25.45336850484212 \u001b[0m(+0.6518618265787737)\n",
      "     | > avg_loss_duration:\u001b[91m 1.2598335146903992 \u001b[0m(+0.1449668904145558)\n",
      "     | > avg_loss_1:\u001b[92m 33.63628069559733 \u001b[0m(-0.2815154393514021)\n",
      "\n",
      " > BEST MODEL : /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1/best_model_1000065.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 2/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:39:35) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:39:39 -- STEP: 10/32 -- GLOBAL_STEP: 1000075\u001b[0m\n",
      "     | > loss_disc: 3.031365394592285  (2.9496742486953735)\n",
      "     | > loss_disc_real_0: 0.31021255254745483  (0.25385855585336686)\n",
      "     | > loss_disc_real_1: 0.26809635758399963  (0.25569315552711486)\n",
      "     | > loss_disc_real_2: 0.26779916882514954  (0.2513489663600922)\n",
      "     | > loss_disc_real_3: 0.26816093921661377  (0.24888477325439454)\n",
      "     | > loss_disc_real_4: 0.2872309982776642  (0.26182751506567004)\n",
      "     | > loss_disc_real_5: 0.2963058352470398  (0.26319791823625566)\n",
      "     | > loss_0: 3.031365394592285  (2.9496742486953735)\n",
      "     | > grad_norm_0: tensor(1.1379, device='cuda:0')  (tensor(1.4302, device='cuda:0'))\n",
      "     | > loss_gen: 1.4787211418151855  (1.5960845589637755)\n",
      "     | > loss_kl: 4.069777965545654  (4.761947441101074)\n",
      "     | > loss_feat: 0.41939249634742737  (0.8120949149131775)\n",
      "     | > loss_mel: 22.018117904663086  (23.188201713562012)\n",
      "     | > loss_duration: 1.3890557289123535  (4.452674698829651)\n",
      "     | > amp_scaler: 256.0  (256.0)\n",
      "     | > loss_1: 29.375064849853516  (34.81100292205811)\n",
      "     | > grad_norm_1: tensor(115.7579, device='cuda:0')  (tensor(164.0002, device='cuda:0'))\n",
      "     | > current_lr_0: 0.000199950003125 \n",
      "     | > current_lr_1: 0.000199950003125 \n",
      "     | > step_time: 0.3666  (0.3745719432830811)\n",
      "     | > loader_time: 0.003  (0.003545188903808594)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.95879864692688  (2.95879864692688)\n",
      "     | > loss_disc_real_0: 0.28076672554016113  (0.28076672554016113)\n",
      "     | > loss_disc_real_1: 0.23914861679077148  (0.23914861679077148)\n",
      "     | > loss_disc_real_2: 0.21677470207214355  (0.21677470207214355)\n",
      "     | > loss_disc_real_3: 0.24079017341136932  (0.24079017341136932)\n",
      "     | > loss_disc_real_4: 0.23634931445121765  (0.23634931445121765)\n",
      "     | > loss_disc_real_5: 0.267622709274292  (0.267622709274292)\n",
      "     | > loss_0: 2.95879864692688  (2.95879864692688)\n",
      "     | > loss_gen: 1.53231680393219  (1.53231680393219)\n",
      "     | > loss_kl: 4.323696136474609  (4.323696136474609)\n",
      "     | > loss_feat: 0.4463096857070923  (0.4463096857070923)\n",
      "     | > loss_mel: 24.03934669494629  (24.03934669494629)\n",
      "     | > loss_duration: 1.4337419271469116  (1.4337419271469116)\n",
      "     | > loss_1: 31.77541160583496  (31.77541160583496)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.891322135925293  (2.891322135925293)\n",
      "     | > loss_disc_real_0: 0.24754703044891357  (0.24754703044891357)\n",
      "     | > loss_disc_real_1: 0.23200786113739014  (0.23200786113739014)\n",
      "     | > loss_disc_real_2: 0.19149616360664368  (0.19149616360664368)\n",
      "     | > loss_disc_real_3: 0.21214637160301208  (0.21214637160301208)\n",
      "     | > loss_disc_real_4: 0.20938259363174438  (0.20938259363174438)\n",
      "     | > loss_disc_real_5: 0.22119130194187164  (0.22119130194187164)\n",
      "     | > loss_0: 2.891322135925293  (2.891322135925293)\n",
      "     | > loss_gen: 1.4364540576934814  (1.4364540576934814)\n",
      "     | > loss_kl: 5.418540954589844  (5.418540954589844)\n",
      "     | > loss_feat: 1.0922260284423828  (1.0922260284423828)\n",
      "     | > loss_mel: 29.160480499267578  (29.160480499267578)\n",
      "     | > loss_duration: 1.3412694931030273  (1.3412694931030273)\n",
      "     | > loss_1: 38.448974609375  (38.448974609375)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 2.9223647117614746  (2.906843423843384)\n",
      "     | > loss_disc_real_0: 0.22149120271205902  (0.2345191165804863)\n",
      "     | > loss_disc_real_1: 0.21304304897785187  (0.222525455057621)\n",
      "     | > loss_disc_real_2: 0.18058714270591736  (0.18604165315628052)\n",
      "     | > loss_disc_real_3: 0.19715918600559235  (0.20465277880430222)\n",
      "     | > loss_disc_real_4: 0.1863640695810318  (0.1978733316063881)\n",
      "     | > loss_disc_real_5: 0.20191292464733124  (0.21155211329460144)\n",
      "     | > loss_0: 2.9223647117614746  (2.906843423843384)\n",
      "     | > loss_gen: 1.3428800106048584  (1.38966703414917)\n",
      "     | > loss_kl: 3.858241081237793  (4.638391017913818)\n",
      "     | > loss_feat: 1.3088324069976807  (1.2005292177200317)\n",
      "     | > loss_mel: 25.746854782104492  (27.453667640686035)\n",
      "     | > loss_duration: 1.7000089883804321  (1.5206392407417297)\n",
      "     | > loss_1: 33.956817626953125  (36.20289611816406)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 2.907383918762207  (2.9070235888163247)\n",
      "     | > loss_disc_real_0: 0.21654021739959717  (0.2285261501868566)\n",
      "     | > loss_disc_real_1: 0.19207565486431122  (0.21237552165985107)\n",
      "     | > loss_disc_real_2: 0.17353005707263947  (0.18187112112840018)\n",
      "     | > loss_disc_real_3: 0.19641201198101044  (0.2019058565298716)\n",
      "     | > loss_disc_real_4: 0.1772458851337433  (0.1909975161155065)\n",
      "     | > loss_disc_real_5: 0.17477957904338837  (0.19929460187753043)\n",
      "     | > loss_0: 2.907383918762207  (2.9070235888163247)\n",
      "     | > loss_gen: 1.2898907661437988  (1.3564082781473796)\n",
      "     | > loss_kl: 4.519428730010986  (4.598736921946208)\n",
      "     | > loss_feat: 1.5469170808792114  (1.3159918387730916)\n",
      "     | > loss_mel: 26.37386131286621  (27.093732198079426)\n",
      "     | > loss_duration: 0.9482707381248474  (1.3298497398694356)\n",
      "     | > loss_1: 34.678367614746094  (35.69471995035807)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 2.8924288749694824  (2.9033749103546143)\n",
      "     | > loss_disc_real_0: 0.23815524578094482  (0.23093342408537865)\n",
      "     | > loss_disc_real_1: 0.21646444499492645  (0.21339775249361992)\n",
      "     | > loss_disc_real_2: 0.18967033922672272  (0.1838209256529808)\n",
      "     | > loss_disc_real_3: 0.20544171333312988  (0.2027898207306862)\n",
      "     | > loss_disc_real_4: 0.19062462449073792  (0.19090429320931435)\n",
      "     | > loss_disc_real_5: 0.21785996854305267  (0.20393594354391098)\n",
      "     | > loss_0: 2.8924288749694824  (2.9033749103546143)\n",
      "     | > loss_gen: 1.39545476436615  (1.3661698997020721)\n",
      "     | > loss_kl: 4.467488765716553  (4.565924882888794)\n",
      "     | > loss_feat: 1.147383451461792  (1.2738397419452667)\n",
      "     | > loss_mel: 26.9592227935791  (27.060104846954346)\n",
      "     | > loss_duration: 1.150639533996582  (1.2850471884012222)\n",
      "     | > loss_1: 35.12018966674805  (35.551087379455566)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 2.8868722915649414  (2.9000743865966796)\n",
      "     | > loss_disc_real_0: 0.24227650463581085  (0.2332020401954651)\n",
      "     | > loss_disc_real_1: 0.22231270372867584  (0.2151807427406311)\n",
      "     | > loss_disc_real_2: 0.1971382349729538  (0.1864843875169754)\n",
      "     | > loss_disc_real_3: 0.22196510434150696  (0.20662487745285035)\n",
      "     | > loss_disc_real_4: 0.2037700116634369  (0.19347743690013885)\n",
      "     | > loss_disc_real_5: 0.21922695636749268  (0.20699414610862732)\n",
      "     | > loss_0: 2.8868722915649414  (2.9000743865966796)\n",
      "     | > loss_gen: 1.4336835145950317  (1.3796726226806642)\n",
      "     | > loss_kl: 3.917745590209961  (4.4362890243530275)\n",
      "     | > loss_feat: 0.9914090037345886  (1.217353594303131)\n",
      "     | > loss_mel: 23.108686447143555  (26.269821166992188)\n",
      "     | > loss_duration: 1.4418535232543945  (1.3164084553718567)\n",
      "     | > loss_1: 30.89337921142578  (34.61954574584961)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 2.9519898891448975  (2.908726970354716)\n",
      "     | > loss_disc_real_0: 0.26957398653030396  (0.23926403125127158)\n",
      "     | > loss_disc_real_1: 0.24415850639343262  (0.22001037001609802)\n",
      "     | > loss_disc_real_2: 0.2115764319896698  (0.19066639492909113)\n",
      "     | > loss_disc_real_3: 0.23395724594593048  (0.21118027220169702)\n",
      "     | > loss_disc_real_4: 0.2298867404460907  (0.1995456541577975)\n",
      "     | > loss_disc_real_5: 0.2445600926876068  (0.2132551372051239)\n",
      "     | > loss_0: 2.9519898891448975  (2.908726970354716)\n",
      "     | > loss_gen: 1.4935485124588013  (1.398651937643687)\n",
      "     | > loss_kl: 4.156071186065674  (4.389586051305135)\n",
      "     | > loss_feat: 0.6093010306358337  (1.1160115003585815)\n",
      "     | > loss_mel: 23.3363094329834  (25.78090254465739)\n",
      "     | > loss_duration: 1.17374587059021  (1.292631357908249)\n",
      "     | > loss_1: 30.76897621154785  (33.977784156799316)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.002406438191731771 \u001b[0m(-9.409586588541652e-05)\n",
      "     | > avg_loss_disc:\u001b[92m 2.908726970354716 \u001b[0m(-0.08710984388987253)\n",
      "     | > avg_loss_disc_real_0:\u001b[91m 0.23926403125127158 \u001b[0m(+0.027988091111183167)\n",
      "     | > avg_loss_disc_real_1:\u001b[92m 0.22001037001609802 \u001b[0m(-0.05870561798413593)\n",
      "     | > avg_loss_disc_real_2:\u001b[92m 0.19066639492909113 \u001b[0m(-0.10346647351980212)\n",
      "     | > avg_loss_disc_real_3:\u001b[92m 0.21118027220169702 \u001b[0m(-0.08172547072172168)\n",
      "     | > avg_loss_disc_real_4:\u001b[92m 0.1995456541577975 \u001b[0m(-0.06276836246252063)\n",
      "     | > avg_loss_disc_real_5:\u001b[92m 0.2132551372051239 \u001b[0m(-0.031057079633076995)\n",
      "     | > avg_loss_0:\u001b[92m 2.908726970354716 \u001b[0m(-0.08710984388987253)\n",
      "     | > avg_loss_gen:\u001b[92m 1.398651937643687 \u001b[0m(-0.2096574306488037)\n",
      "     | > avg_loss_kl:\u001b[92m 4.389586051305135 \u001b[0m(-0.48606797059377094)\n",
      "     | > avg_loss_feat:\u001b[91m 1.1160115003585815 \u001b[0m(+0.6768962343533833)\n",
      "     | > avg_loss_mel:\u001b[91m 25.78090254465739 \u001b[0m(+0.3275340398152693)\n",
      "     | > avg_loss_duration:\u001b[91m 1.292631357908249 \u001b[0m(+0.03279784321784973)\n",
      "     | > avg_loss_1:\u001b[91m 33.977784156799316 \u001b[0m(+0.34150346120198805)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 3/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:39:51) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:39:53 -- STEP: 3/32 -- GLOBAL_STEP: 1000100\u001b[0m\n",
      "     | > loss_disc: 3.124021053314209  (3.029479742050171)\n",
      "     | > loss_disc_real_0: 0.17262041568756104  (0.23371572295824686)\n",
      "     | > loss_disc_real_1: 0.1162162646651268  (0.2844756717483203)\n",
      "     | > loss_disc_real_2: 0.22606457769870758  (0.27239451309045154)\n",
      "     | > loss_disc_real_3: 0.21104395389556885  (0.2594993809858958)\n",
      "     | > loss_disc_real_4: 0.21446795761585236  (0.27156733969847363)\n",
      "     | > loss_disc_real_5: 0.17569641768932343  (0.23557595908641815)\n",
      "     | > loss_0: 3.124021053314209  (3.029479742050171)\n",
      "     | > grad_norm_0: tensor(5.4391, device='cuda:0')  (tensor(3.5127, device='cuda:0'))\n",
      "     | > loss_gen: 1.5528134107589722  (1.6232942740122478)\n",
      "     | > loss_kl: 5.052215576171875  (4.7732768058776855)\n",
      "     | > loss_feat: 1.531136155128479  (0.962914228439331)\n",
      "     | > loss_mel: 26.21868133544922  (24.60630734761556)\n",
      "     | > loss_duration: 10.70669937133789  (8.062211275100708)\n",
      "     | > amp_scaler: 256.0  (256.0)\n",
      "     | > loss_1: 45.061546325683594  (40.02800432840983)\n",
      "     | > grad_norm_1: tensor(279.8502, device='cuda:0')  (tensor(211.7299, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019992500937460937 \n",
      "     | > current_lr_1: 0.00019992500937460937 \n",
      "     | > step_time: 0.3733  (0.3734448750813802)\n",
      "     | > loader_time: 0.0031  (0.0032672882080078125)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:40:03 -- STEP: 28/32 -- GLOBAL_STEP: 1000125\u001b[0m\n",
      "     | > loss_disc: 2.964106321334839  (2.951759764126369)\n",
      "     | > loss_disc_real_0: 0.2696360647678375  (0.24762347447020666)\n",
      "     | > loss_disc_real_1: 0.30647146701812744  (0.25634948510144423)\n",
      "     | > loss_disc_real_2: 0.23429785668849945  (0.2546628415584565)\n",
      "     | > loss_disc_real_3: 0.2415585219860077  (0.251648552183594)\n",
      "     | > loss_disc_real_4: 0.2605613172054291  (0.2519646845757962)\n",
      "     | > loss_disc_real_5: 0.28280287981033325  (0.251491721187319)\n",
      "     | > loss_0: 2.964106321334839  (2.951759764126369)\n",
      "     | > grad_norm_0: tensor(1.3522, device='cuda:0')  (tensor(1.9201, device='cuda:0'))\n",
      "     | > loss_gen: 1.652567982673645  (1.6021306940487452)\n",
      "     | > loss_kl: 4.0427350997924805  (4.187199618135181)\n",
      "     | > loss_feat: 0.6769453287124634  (0.8625883300389562)\n",
      "     | > loss_mel: 22.935009002685547  (23.532341684613908)\n",
      "     | > loss_duration: 1.5062774419784546  (3.338189418826784)\n",
      "     | > amp_scaler: 256.0  (256.0)\n",
      "     | > loss_1: 30.813535690307617  (33.52244935716901)\n",
      "     | > grad_norm_1: tensor(130.8898, device='cuda:0')  (tensor(180.4328, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019992500937460937 \n",
      "     | > current_lr_1: 0.00019992500937460937 \n",
      "     | > step_time: 0.3545  (0.3917512893676758)\n",
      "     | > loader_time: 0.0028  (0.0034258365631103516)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 3.0196361541748047  (3.0196361541748047)\n",
      "     | > loss_disc_real_0: 0.26668062806129456  (0.26668062806129456)\n",
      "     | > loss_disc_real_1: 0.3273454010486603  (0.3273454010486603)\n",
      "     | > loss_disc_real_2: 0.25242069363594055  (0.25242069363594055)\n",
      "     | > loss_disc_real_3: 0.2749352753162384  (0.2749352753162384)\n",
      "     | > loss_disc_real_4: 0.2952856123447418  (0.2952856123447418)\n",
      "     | > loss_disc_real_5: 0.28177228569984436  (0.28177228569984436)\n",
      "     | > loss_0: 3.0196361541748047  (3.0196361541748047)\n",
      "     | > loss_gen: 1.6970124244689941  (1.6970124244689941)\n",
      "     | > loss_kl: 4.329864501953125  (4.329864501953125)\n",
      "     | > loss_feat: 0.04825405031442642  (0.04825405031442642)\n",
      "     | > loss_mel: 21.09493064880371  (21.09493064880371)\n",
      "     | > loss_duration: 1.4495491981506348  (1.4495491981506348)\n",
      "     | > loss_1: 28.619609832763672  (28.619609832763672)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.9048261642456055  (2.9048261642456055)\n",
      "     | > loss_disc_real_0: 0.21959154307842255  (0.21959154307842255)\n",
      "     | > loss_disc_real_1: 0.3348305821418762  (0.3348305821418762)\n",
      "     | > loss_disc_real_2: 0.23018380999565125  (0.23018380999565125)\n",
      "     | > loss_disc_real_3: 0.24671399593353271  (0.24671399593353271)\n",
      "     | > loss_disc_real_4: 0.26950106024742126  (0.26950106024742126)\n",
      "     | > loss_disc_real_5: 0.24079617857933044  (0.24079617857933044)\n",
      "     | > loss_0: 2.9048261642456055  (2.9048261642456055)\n",
      "     | > loss_gen: 1.6641895771026611  (1.6641895771026611)\n",
      "     | > loss_kl: 5.180713653564453  (5.180713653564453)\n",
      "     | > loss_feat: 0.9158511757850647  (0.9158511757850647)\n",
      "     | > loss_mel: 29.490880966186523  (29.490880966186523)\n",
      "     | > loss_duration: 1.362220048904419  (1.362220048904419)\n",
      "     | > loss_1: 38.613853454589844  (38.613853454589844)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 3.023757219314575  (2.9642916917800903)\n",
      "     | > loss_disc_real_0: 0.23317241668701172  (0.22638197988271713)\n",
      "     | > loss_disc_real_1: 0.3156276047229767  (0.32522909343242645)\n",
      "     | > loss_disc_real_2: 0.23647882044315338  (0.2333313152194023)\n",
      "     | > loss_disc_real_3: 0.2528393864631653  (0.249776691198349)\n",
      "     | > loss_disc_real_4: 0.27095770835876465  (0.27022938430309296)\n",
      "     | > loss_disc_real_5: 0.24463212490081787  (0.24271415174007416)\n",
      "     | > loss_0: 3.023757219314575  (2.9642916917800903)\n",
      "     | > loss_gen: 1.5701788663864136  (1.6171842217445374)\n",
      "     | > loss_kl: 3.7904908657073975  (4.485602259635925)\n",
      "     | > loss_feat: 0.572493314743042  (0.7441722452640533)\n",
      "     | > loss_mel: 20.624372482299805  (25.057626724243164)\n",
      "     | > loss_duration: 1.6607847213745117  (1.5115023851394653)\n",
      "     | > loss_1: 28.218318939208984  (33.416086196899414)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 3.019890308380127  (2.9828245639801025)\n",
      "     | > loss_disc_real_0: 0.1907782107591629  (0.21451405684153238)\n",
      "     | > loss_disc_real_1: 0.2877500057220459  (0.31273606419563293)\n",
      "     | > loss_disc_real_2: 0.20999298989772797  (0.22555187344551086)\n",
      "     | > loss_disc_real_3: 0.2186967432498932  (0.23941670854886374)\n",
      "     | > loss_disc_real_4: 0.22119995951652527  (0.2538862427075704)\n",
      "     | > loss_disc_real_5: 0.2036084085702896  (0.22967890401681265)\n",
      "     | > loss_0: 3.019890308380127  (2.9828245639801025)\n",
      "     | > loss_gen: 1.4349305629730225  (1.5564330021540325)\n",
      "     | > loss_kl: 4.541592121124268  (4.504265546798706)\n",
      "     | > loss_feat: 1.0873525142669678  (0.8585656682650248)\n",
      "     | > loss_mel: 24.279903411865234  (24.798385620117188)\n",
      "     | > loss_duration: 0.933220624923706  (1.318741798400879)\n",
      "     | > loss_1: 32.277000427246094  (33.036390940348305)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 3.01920223236084  (2.991918981075287)\n",
      "     | > loss_disc_real_0: 0.16639026999473572  (0.20248311012983322)\n",
      "     | > loss_disc_real_1: 0.2875515818595886  (0.30643994361162186)\n",
      "     | > loss_disc_real_2: 0.20207440853118896  (0.2196825072169304)\n",
      "     | > loss_disc_real_3: 0.21055981516838074  (0.23220248520374298)\n",
      "     | > loss_disc_real_4: 0.19444598257541656  (0.23902617767453194)\n",
      "     | > loss_disc_real_5: 0.17562644183635712  (0.21616578847169876)\n",
      "     | > loss_0: 3.01920223236084  (2.991918981075287)\n",
      "     | > loss_gen: 1.3258652687072754  (1.4987910687923431)\n",
      "     | > loss_kl: 3.7929327487945557  (4.3264323472976685)\n",
      "     | > loss_feat: 1.4155569076538086  (0.9978134781122208)\n",
      "     | > loss_mel: 21.343647003173828  (23.934700965881348)\n",
      "     | > loss_duration: 1.166002869606018  (1.2805570662021637)\n",
      "     | > loss_1: 29.044002532958984  (32.03829383850098)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 3.026094913482666  (2.9987541675567626)\n",
      "     | > loss_disc_real_0: 0.23927411437034607  (0.2098413109779358)\n",
      "     | > loss_disc_real_1: 0.30720391869544983  (0.30659273862838743)\n",
      "     | > loss_disc_real_2: 0.2379056066274643  (0.22332712709903718)\n",
      "     | > loss_disc_real_3: 0.25991424918174744  (0.23774483799934387)\n",
      "     | > loss_disc_real_4: 0.2837793827056885  (0.24797681868076324)\n",
      "     | > loss_disc_real_5: 0.25284355878829956  (0.2235013425350189)\n",
      "     | > loss_0: 3.026094913482666  (2.9987541675567626)\n",
      "     | > loss_gen: 1.5912009477615356  (1.5172730445861817)\n",
      "     | > loss_kl: 4.0508928298950195  (4.2713244438171385)\n",
      "     | > loss_feat: 0.8561108708381653  (0.9694729566574096)\n",
      "     | > loss_mel: 22.34130859375  (23.616022491455077)\n",
      "     | > loss_duration: 1.4019681215286255  (1.304839277267456)\n",
      "     | > loss_1: 30.24148178100586  (31.678931427001952)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 2.9819090366363525  (2.9959466457366943)\n",
      "     | > loss_disc_real_0: 0.23642489314079285  (0.21427190800507864)\n",
      "     | > loss_disc_real_1: 0.3263908624649048  (0.3098924259344737)\n",
      "     | > loss_disc_real_2: 0.2341742068529129  (0.22513497372468314)\n",
      "     | > loss_disc_real_3: 0.25411930680274963  (0.24047391613324484)\n",
      "     | > loss_disc_real_4: 0.2676226496696472  (0.25125112384557724)\n",
      "     | > loss_disc_real_5: 0.2419341653585434  (0.226573479672273)\n",
      "     | > loss_0: 2.9819090366363525  (2.9959466457366943)\n",
      "     | > loss_gen: 1.6170189380645752  (1.5338973601659138)\n",
      "     | > loss_kl: 3.729874610900879  (4.181082804997762)\n",
      "     | > loss_feat: 0.7002752423286438  (0.9246066709359487)\n",
      "     | > loss_mel: 23.956125259399414  (23.67270628611247)\n",
      "     | > loss_duration: 1.1592553853988647  (1.2805752952893574)\n",
      "     | > loss_1: 31.162551879882812  (31.592868169148762)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.002472519874572754 \u001b[0m(+6.608168284098293e-05)\n",
      "     | > avg_loss_disc:\u001b[91m 2.9959466457366943 \u001b[0m(+0.0872196753819785)\n",
      "     | > avg_loss_disc_real_0:\u001b[92m 0.21427190800507864 \u001b[0m(-0.024992123246192932)\n",
      "     | > avg_loss_disc_real_1:\u001b[91m 0.3098924259344737 \u001b[0m(+0.08988205591837567)\n",
      "     | > avg_loss_disc_real_2:\u001b[91m 0.22513497372468314 \u001b[0m(+0.03446857879559201)\n",
      "     | > avg_loss_disc_real_3:\u001b[91m 0.24047391613324484 \u001b[0m(+0.02929364393154782)\n",
      "     | > avg_loss_disc_real_4:\u001b[91m 0.25125112384557724 \u001b[0m(+0.051705469687779754)\n",
      "     | > avg_loss_disc_real_5:\u001b[91m 0.226573479672273 \u001b[0m(+0.013318342467149108)\n",
      "     | > avg_loss_0:\u001b[91m 2.9959466457366943 \u001b[0m(+0.0872196753819785)\n",
      "     | > avg_loss_gen:\u001b[91m 1.5338973601659138 \u001b[0m(+0.13524542252222682)\n",
      "     | > avg_loss_kl:\u001b[92m 4.181082804997762 \u001b[0m(-0.20850324630737305)\n",
      "     | > avg_loss_feat:\u001b[92m 0.9246066709359487 \u001b[0m(-0.19140482942263282)\n",
      "     | > avg_loss_mel:\u001b[92m 23.67270628611247 \u001b[0m(-2.108196258544922)\n",
      "     | > avg_loss_duration:\u001b[92m 1.2805752952893574 \u001b[0m(-0.012056062618891472)\n",
      "     | > avg_loss_1:\u001b[92m 31.592868169148762 \u001b[0m(-2.3849159876505546)\n",
      "\n",
      " > BEST MODEL : /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1/best_model_1000129.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 4/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:40:10) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:40:19 -- STEP: 21/32 -- GLOBAL_STEP: 1000150\u001b[0m\n",
      "     | > loss_disc: 3.027101516723633  (2.956196353549049)\n",
      "     | > loss_disc_real_0: 0.3629564046859741  (0.2555331488450368)\n",
      "     | > loss_disc_real_1: 0.1563989222049713  (0.24257337053616843)\n",
      "     | > loss_disc_real_2: 0.19108712673187256  (0.25491852845464436)\n",
      "     | > loss_disc_real_3: 0.24009744822978973  (0.25925340184143614)\n",
      "     | > loss_disc_real_4: 0.2865941524505615  (0.2597384431532451)\n",
      "     | > loss_disc_real_5: 0.33302080631256104  (0.2611646226474217)\n",
      "     | > loss_0: 3.027101516723633  (2.956196353549049)\n",
      "     | > grad_norm_0: tensor(3.3173, device='cuda:0')  (tensor(2.5490, device='cuda:0'))\n",
      "     | > loss_gen: 1.2342694997787476  (1.6279514914467221)\n",
      "     | > loss_kl: 3.640594720840454  (4.037272544134231)\n",
      "     | > loss_feat: 0.4334413409233093  (0.94321513459796)\n",
      "     | > loss_mel: 21.79864501953125  (23.15546026683989)\n",
      "     | > loss_duration: 1.1506667137145996  (2.7839512314115247)\n",
      "     | > amp_scaler: 128.0  (170.66666666666666)\n",
      "     | > loss_1: 28.257617950439453  (32.5478504725865)\n",
      "     | > grad_norm_1: tensor(139.3747, device='cuda:0')  (tensor(176.1371, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019990001874843754 \n",
      "     | > current_lr_1: 0.00019990001874843754 \n",
      "     | > step_time: 0.3771  (0.37981932503836496)\n",
      "     | > loader_time: 0.0039  (0.0035423778352283294)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.975355386734009  (2.975355386734009)\n",
      "     | > loss_disc_real_0: 0.21523568034172058  (0.21523568034172058)\n",
      "     | > loss_disc_real_1: 0.19374608993530273  (0.19374608993530273)\n",
      "     | > loss_disc_real_2: 0.2379871904850006  (0.2379871904850006)\n",
      "     | > loss_disc_real_3: 0.289067804813385  (0.289067804813385)\n",
      "     | > loss_disc_real_4: 0.30303165316581726  (0.30303165316581726)\n",
      "     | > loss_disc_real_5: 0.2711739242076874  (0.2711739242076874)\n",
      "     | > loss_0: 2.975355386734009  (2.975355386734009)\n",
      "     | > loss_gen: 1.551741600036621  (1.551741600036621)\n",
      "     | > loss_kl: 4.118799209594727  (4.118799209594727)\n",
      "     | > loss_feat: 0.4398926794528961  (0.4398926794528961)\n",
      "     | > loss_mel: 20.315351486206055  (20.315351486206055)\n",
      "     | > loss_duration: 1.453473448753357  (1.453473448753357)\n",
      "     | > loss_1: 27.87925910949707  (27.87925910949707)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.982753038406372  (2.982753038406372)\n",
      "     | > loss_disc_real_0: 0.22103674709796906  (0.22103674709796906)\n",
      "     | > loss_disc_real_1: 0.20977862179279327  (0.20977862179279327)\n",
      "     | > loss_disc_real_2: 0.23648832738399506  (0.23648832738399506)\n",
      "     | > loss_disc_real_3: 0.2867172658443451  (0.2867172658443451)\n",
      "     | > loss_disc_real_4: 0.29961690306663513  (0.29961690306663513)\n",
      "     | > loss_disc_real_5: 0.2677326202392578  (0.2677326202392578)\n",
      "     | > loss_0: 2.982753038406372  (2.982753038406372)\n",
      "     | > loss_gen: 1.5550085306167603  (1.5550085306167603)\n",
      "     | > loss_kl: 4.132559776306152  (4.132559776306152)\n",
      "     | > loss_feat: 0.5181386470794678  (0.5181386470794678)\n",
      "     | > loss_mel: 29.032838821411133  (29.032838821411133)\n",
      "     | > loss_duration: 1.365670084953308  (1.365670084953308)\n",
      "     | > loss_1: 36.60421371459961  (36.60421371459961)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 3.017284870147705  (3.0000189542770386)\n",
      "     | > loss_disc_real_0: 0.22422869503498077  (0.22263272106647491)\n",
      "     | > loss_disc_real_1: 0.20774854719638824  (0.20876358449459076)\n",
      "     | > loss_disc_real_2: 0.24660681188106537  (0.2415475696325302)\n",
      "     | > loss_disc_real_3: 0.29347696900367737  (0.29009711742401123)\n",
      "     | > loss_disc_real_4: 0.30603957176208496  (0.30282823741436005)\n",
      "     | > loss_disc_real_5: 0.27950990200042725  (0.27362126111984253)\n",
      "     | > loss_0: 3.017284870147705  (3.0000189542770386)\n",
      "     | > loss_gen: 1.5575482845306396  (1.5562784075737)\n",
      "     | > loss_kl: 3.0452675819396973  (3.588913679122925)\n",
      "     | > loss_feat: 0.027415664866566658  (0.2727771559730172)\n",
      "     | > loss_mel: 20.66156005859375  (24.84719944000244)\n",
      "     | > loss_duration: 1.736194133758545  (1.5509321093559265)\n",
      "     | > loss_1: 27.027986526489258  (31.816100120544434)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 2.8828108310699463  (2.9609495798746743)\n",
      "     | > loss_disc_real_0: 0.17692576348781586  (0.20739706854025522)\n",
      "     | > loss_disc_real_1: 0.17330551147460938  (0.19694422682126364)\n",
      "     | > loss_disc_real_2: 0.20759879052639008  (0.2302313099304835)\n",
      "     | > loss_disc_real_3: 0.2523864805698395  (0.2775269051392873)\n",
      "     | > loss_disc_real_4: 0.2631755471229553  (0.2896106739838918)\n",
      "     | > loss_disc_real_5: 0.23481275141239166  (0.2606850912173589)\n",
      "     | > loss_0: 2.8828108310699463  (2.9609495798746743)\n",
      "     | > loss_gen: 1.4562792778015137  (1.5229453643163045)\n",
      "     | > loss_kl: 4.374770641326904  (3.8508659998575845)\n",
      "     | > loss_feat: 1.1246399879455566  (0.556731433297197)\n",
      "     | > loss_mel: 25.706653594970703  (25.133684158325195)\n",
      "     | > loss_duration: 0.9164242744445801  (1.339429497718811)\n",
      "     | > loss_1: 33.578765869140625  (32.4036553700765)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 2.8797736167907715  (2.9406555891036987)\n",
      "     | > loss_disc_real_0: 0.19911238551139832  (0.205325897783041)\n",
      "     | > loss_disc_real_1: 0.19117805361747742  (0.19550268352031708)\n",
      "     | > loss_disc_real_2: 0.22147236764431  (0.22804157435894012)\n",
      "     | > loss_disc_real_3: 0.26852285861968994  (0.27527589350938797)\n",
      "     | > loss_disc_real_4: 0.2783026695251465  (0.2867836728692055)\n",
      "     | > loss_disc_real_5: 0.24730727076530457  (0.2573406361043453)\n",
      "     | > loss_0: 2.8797736167907715  (2.9406555891036987)\n",
      "     | > loss_gen: 1.545839548110962  (1.5286689102649689)\n",
      "     | > loss_kl: 3.9747555255889893  (3.881838381290436)\n",
      "     | > loss_feat: 1.065413236618042  (0.6839018841274083)\n",
      "     | > loss_mel: 24.159700393676758  (24.890188217163086)\n",
      "     | > loss_duration: 1.1507959365844727  (1.2922711074352264)\n",
      "     | > loss_1: 31.896503448486328  (32.276867389678955)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 2.9764890670776367  (2.9478222846984865)\n",
      "     | > loss_disc_real_0: 0.21863222122192383  (0.20798716247081755)\n",
      "     | > loss_disc_real_1: 0.19726303219795227  (0.19585475325584412)\n",
      "     | > loss_disc_real_2: 0.24002458155155182  (0.23043817579746245)\n",
      "     | > loss_disc_real_3: 0.28364622592926025  (0.2769499599933624)\n",
      "     | > loss_disc_real_4: 0.29780009388923645  (0.28898695707321165)\n",
      "     | > loss_disc_real_5: 0.26822879910469055  (0.25951826870441436)\n",
      "     | > loss_0: 2.9764890670776367  (2.9478222846984865)\n",
      "     | > loss_gen: 1.544113039970398  (1.5317577362060546)\n",
      "     | > loss_kl: 3.7996575832366943  (3.8654022216796875)\n",
      "     | > loss_feat: 0.3897586762905121  (0.625073242560029)\n",
      "     | > loss_mel: 21.555477142333984  (24.223246002197264)\n",
      "     | > loss_duration: 1.440542459487915  (1.3219253778457642)\n",
      "     | > loss_1: 28.729549407958984  (31.56740379333496)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 2.9418418407440186  (2.946825544039408)\n",
      "     | > loss_disc_real_0: 0.2006891369819641  (0.20677082488934198)\n",
      "     | > loss_disc_real_1: 0.22103583812713623  (0.2000516007343928)\n",
      "     | > loss_disc_real_2: 0.22514040768146515  (0.22955521444479624)\n",
      "     | > loss_disc_real_3: 0.26936304569244385  (0.27568547427654266)\n",
      "     | > loss_disc_real_4: 0.2835220694541931  (0.28807614247004193)\n",
      "     | > loss_disc_real_5: 0.2551864981651306  (0.2587963069478671)\n",
      "     | > loss_0: 2.9418418407440186  (2.946825544039408)\n",
      "     | > loss_gen: 1.5308184623718262  (1.5316011905670166)\n",
      "     | > loss_kl: 3.6350247859954834  (3.827005982398987)\n",
      "     | > loss_feat: 0.8705271482467651  (0.6659822268411517)\n",
      "     | > loss_mel: 23.91583824157715  (24.172011375427246)\n",
      "     | > loss_duration: 1.175458312034607  (1.2975142002105713)\n",
      "     | > loss_1: 31.127668380737305  (31.49411455790202)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0024175643920898438 \u001b[0m(-5.4955482482910156e-05)\n",
      "     | > avg_loss_disc:\u001b[92m 2.946825544039408 \u001b[0m(-0.04912110169728612)\n",
      "     | > avg_loss_disc_real_0:\u001b[92m 0.20677082488934198 \u001b[0m(-0.007501083115736662)\n",
      "     | > avg_loss_disc_real_1:\u001b[92m 0.2000516007343928 \u001b[0m(-0.1098408252000809)\n",
      "     | > avg_loss_disc_real_2:\u001b[91m 0.22955521444479624 \u001b[0m(+0.0044202407201131)\n",
      "     | > avg_loss_disc_real_3:\u001b[91m 0.27568547427654266 \u001b[0m(+0.03521155814329782)\n",
      "     | > avg_loss_disc_real_4:\u001b[91m 0.28807614247004193 \u001b[0m(+0.03682501862446469)\n",
      "     | > avg_loss_disc_real_5:\u001b[91m 0.2587963069478671 \u001b[0m(+0.032222827275594085)\n",
      "     | > avg_loss_0:\u001b[92m 2.946825544039408 \u001b[0m(-0.04912110169728612)\n",
      "     | > avg_loss_gen:\u001b[92m 1.5316011905670166 \u001b[0m(-0.002296169598897224)\n",
      "     | > avg_loss_kl:\u001b[92m 3.827005982398987 \u001b[0m(-0.35407682259877493)\n",
      "     | > avg_loss_feat:\u001b[92m 0.6659822268411517 \u001b[0m(-0.258624444094797)\n",
      "     | > avg_loss_mel:\u001b[91m 24.172011375427246 \u001b[0m(+0.49930508931477746)\n",
      "     | > avg_loss_duration:\u001b[91m 1.2975142002105713 \u001b[0m(+0.01693890492121386)\n",
      "     | > avg_loss_1:\u001b[92m 31.49411455790202 \u001b[0m(-0.09875361124674242)\n",
      "\n",
      " > BEST MODEL : /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1/best_model_1000161.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 5/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:40:29) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:40:35 -- STEP: 14/32 -- GLOBAL_STEP: 1000175\u001b[0m\n",
      "     | > loss_disc: 2.930220603942871  (2.93438948903765)\n",
      "     | > loss_disc_real_0: 0.2970041334629059  (0.2447775261742728)\n",
      "     | > loss_disc_real_1: 0.19750124216079712  (0.24048458146197454)\n",
      "     | > loss_disc_real_2: 0.2722987234592438  (0.2498033908861024)\n",
      "     | > loss_disc_real_3: 0.304342657327652  (0.25317678281239103)\n",
      "     | > loss_disc_real_4: 0.30701038241386414  (0.2534768932632038)\n",
      "     | > loss_disc_real_5: 0.2922857403755188  (0.25073162466287613)\n",
      "     | > loss_0: 2.930220603942871  (2.93438948903765)\n",
      "     | > grad_norm_0: tensor(2.1053, device='cuda:0')  (tensor(1.4486, device='cuda:0'))\n",
      "     | > loss_gen: 1.5608952045440674  (1.5898411273956299)\n",
      "     | > loss_kl: 3.7177786827087402  (3.8437716790608)\n",
      "     | > loss_feat: 0.7985731959342957  (0.863714836537838)\n",
      "     | > loss_mel: 23.504846572875977  (23.48477050236293)\n",
      "     | > loss_duration: 1.2994130849838257  (3.415778432573591)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 30.881507873535156  (33.197876657758435)\n",
      "     | > grad_norm_1: tensor(80.1689, device='cuda:0')  (tensor(150.7825, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019987503124609398 \n",
      "     | > current_lr_1: 0.00019987503124609398 \n",
      "     | > step_time: 0.3705  (0.3847872700010027)\n",
      "     | > loader_time: 0.0035  (0.0037055526460920063)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.9434828758239746  (2.9434828758239746)\n",
      "     | > loss_disc_real_0: 0.21442283689975739  (0.21442283689975739)\n",
      "     | > loss_disc_real_1: 0.26809412240982056  (0.26809412240982056)\n",
      "     | > loss_disc_real_2: 0.22949054837226868  (0.22949054837226868)\n",
      "     | > loss_disc_real_3: 0.2536161243915558  (0.2536161243915558)\n",
      "     | > loss_disc_real_4: 0.20678743720054626  (0.20678743720054626)\n",
      "     | > loss_disc_real_5: 0.1940770447254181  (0.1940770447254181)\n",
      "     | > loss_0: 2.9434828758239746  (2.9434828758239746)\n",
      "     | > loss_gen: 1.4426274299621582  (1.4426274299621582)\n",
      "     | > loss_kl: 3.606613874435425  (3.606613874435425)\n",
      "     | > loss_feat: 0.9130313992500305  (0.9130313992500305)\n",
      "     | > loss_mel: 24.018693923950195  (24.018693923950195)\n",
      "     | > loss_duration: 1.4574884176254272  (1.4574884176254272)\n",
      "     | > loss_1: 31.43845558166504  (31.43845558166504)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.9891116619110107  (2.9891116619110107)\n",
      "     | > loss_disc_real_0: 0.21780598163604736  (0.21780598163604736)\n",
      "     | > loss_disc_real_1: 0.29442298412323  (0.29442298412323)\n",
      "     | > loss_disc_real_2: 0.24496248364448547  (0.24496248364448547)\n",
      "     | > loss_disc_real_3: 0.26783138513565063  (0.26783138513565063)\n",
      "     | > loss_disc_real_4: 0.23475462198257446  (0.23475462198257446)\n",
      "     | > loss_disc_real_5: 0.22240246832370758  (0.22240246832370758)\n",
      "     | > loss_0: 2.9891116619110107  (2.9891116619110107)\n",
      "     | > loss_gen: 1.4984263181686401  (1.4984263181686401)\n",
      "     | > loss_kl: 4.13139533996582  (4.13139533996582)\n",
      "     | > loss_feat: 0.3618201017379761  (0.3618201017379761)\n",
      "     | > loss_mel: 23.65216636657715  (23.65216636657715)\n",
      "     | > loss_duration: 1.3419734239578247  (1.3419734239578247)\n",
      "     | > loss_1: 30.985782623291016  (30.985782623291016)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 2.9577550888061523  (2.9734333753585815)\n",
      "     | > loss_disc_real_0: 0.21898886561393738  (0.21839742362499237)\n",
      "     | > loss_disc_real_1: 0.27413249015808105  (0.2842777371406555)\n",
      "     | > loss_disc_real_2: 0.23853841423988342  (0.24175044894218445)\n",
      "     | > loss_disc_real_3: 0.26610639691352844  (0.26696889102458954)\n",
      "     | > loss_disc_real_4: 0.22960950434207916  (0.2321820631623268)\n",
      "     | > loss_disc_real_5: 0.21476709842681885  (0.21858478337526321)\n",
      "     | > loss_0: 2.9577550888061523  (2.9734333753585815)\n",
      "     | > loss_gen: 1.4954919815063477  (1.496959149837494)\n",
      "     | > loss_kl: 3.6333703994750977  (3.882382869720459)\n",
      "     | > loss_feat: 0.70027756690979  (0.5310488343238831)\n",
      "     | > loss_mel: 23.583480834960938  (23.617823600769043)\n",
      "     | > loss_duration: 1.6879936456680298  (1.5149835348129272)\n",
      "     | > loss_1: 31.100614547729492  (31.043198585510254)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 2.738050699234009  (2.894972483317057)\n",
      "     | > loss_disc_real_0: 0.15433840453624725  (0.19704441726207733)\n",
      "     | > loss_disc_real_1: 0.22537587583065033  (0.2646437833706538)\n",
      "     | > loss_disc_real_2: 0.20347364246845245  (0.22899151345094046)\n",
      "     | > loss_disc_real_3: 0.2272728830575943  (0.25373688836892444)\n",
      "     | > loss_disc_real_4: 0.17022033035755157  (0.21152815222740173)\n",
      "     | > loss_disc_real_5: 0.14929449558258057  (0.19548802077770233)\n",
      "     | > loss_0: 2.738050699234009  (2.894972483317057)\n",
      "     | > loss_gen: 1.4298862218856812  (1.4746015071868896)\n",
      "     | > loss_kl: 3.474860191345215  (3.746541976928711)\n",
      "     | > loss_feat: 1.839144229888916  (0.9670806328455607)\n",
      "     | > loss_mel: 28.336538314819336  (25.190728505452473)\n",
      "     | > loss_duration: 0.8970655202865601  (1.3090108633041382)\n",
      "     | > loss_1: 35.97749328613281  (32.68796348571777)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 2.9301960468292236  (2.903778374195099)\n",
      "     | > loss_disc_real_0: 0.19381748139858246  (0.1962376832962036)\n",
      "     | > loss_disc_real_1: 0.24783988296985626  (0.2604428082704544)\n",
      "     | > loss_disc_real_2: 0.2351076602935791  (0.2305205501616001)\n",
      "     | > loss_disc_real_3: 0.2670598030090332  (0.25706761702895164)\n",
      "     | > loss_disc_real_4: 0.22889754176139832  (0.21587049961090088)\n",
      "     | > loss_disc_real_5: 0.2095806747674942  (0.1990111842751503)\n",
      "     | > loss_0: 2.9301960468292236  (2.903778374195099)\n",
      "     | > loss_gen: 1.4630502462387085  (1.4717136919498444)\n",
      "     | > loss_kl: 3.562826633453369  (3.7006131410598755)\n",
      "     | > loss_feat: 0.5928137898445129  (0.8735139220952988)\n",
      "     | > loss_mel: 24.685937881469727  (25.064530849456787)\n",
      "     | > loss_duration: 1.1493638753890991  (1.2690991163253784)\n",
      "     | > loss_1: 31.453994750976562  (32.37947130203247)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 2.9242360591888428  (2.9078699111938477)\n",
      "     | > loss_disc_real_0: 0.20223960280418396  (0.1974380671977997)\n",
      "     | > loss_disc_real_1: 0.2731016278266907  (0.26297457218170167)\n",
      "     | > loss_disc_real_2: 0.23696602880954742  (0.23180964589118958)\n",
      "     | > loss_disc_real_3: 0.2621460556983948  (0.25808330476284025)\n",
      "     | > loss_disc_real_4: 0.2210654616355896  (0.21690949201583862)\n",
      "     | > loss_disc_real_5: 0.1999344527721405  (0.19919583797454835)\n",
      "     | > loss_0: 2.9242360591888428  (2.9078699111938477)\n",
      "     | > loss_gen: 1.4976255893707275  (1.476896071434021)\n",
      "     | > loss_kl: 3.7942616939544678  (3.719342851638794)\n",
      "     | > loss_feat: 0.7658509612083435  (0.8519813299179078)\n",
      "     | > loss_mel: 23.168460845947266  (24.685316848754884)\n",
      "     | > loss_duration: 1.4072208404541016  (1.2967234611511231)\n",
      "     | > loss_1: 30.633419036865234  (32.03026084899902)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 2.9735584259033203  (2.9188179969787598)\n",
      "     | > loss_disc_real_0: 0.22355908155441284  (0.20179156959056854)\n",
      "     | > loss_disc_real_1: 0.2461497038602829  (0.2601704274614652)\n",
      "     | > loss_disc_real_2: 0.2444474697113037  (0.2339159498612086)\n",
      "     | > loss_disc_real_3: 0.2713228464126587  (0.26028989503781)\n",
      "     | > loss_disc_real_4: 0.2414519488811493  (0.2209999014933904)\n",
      "     | > loss_disc_real_5: 0.22998589277267456  (0.20432751377423605)\n",
      "     | > loss_0: 2.9735584259033203  (2.9188179969787598)\n",
      "     | > loss_gen: 1.4876030683517456  (1.4786805709203084)\n",
      "     | > loss_kl: 3.4537312984466553  (3.675074259440104)\n",
      "     | > loss_feat: 0.3307355046272278  (0.7651070257027944)\n",
      "     | > loss_mel: 24.348894119262695  (24.62924639383952)\n",
      "     | > loss_duration: 1.1579761505126953  (1.2735989093780518)\n",
      "     | > loss_1: 30.778940200805664  (31.821707407633465)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.0024954875310262046 \u001b[0m(+7.792313893636082e-05)\n",
      "     | > avg_loss_disc:\u001b[92m 2.9188179969787598 \u001b[0m(-0.028007547060648452)\n",
      "     | > avg_loss_disc_real_0:\u001b[92m 0.20179156959056854 \u001b[0m(-0.004979255298773438)\n",
      "     | > avg_loss_disc_real_1:\u001b[91m 0.2601704274614652 \u001b[0m(+0.06011882672707239)\n",
      "     | > avg_loss_disc_real_2:\u001b[91m 0.2339159498612086 \u001b[0m(+0.0043607354164123535)\n",
      "     | > avg_loss_disc_real_3:\u001b[92m 0.26028989503781 \u001b[0m(-0.015395579238732637)\n",
      "     | > avg_loss_disc_real_4:\u001b[92m 0.2209999014933904 \u001b[0m(-0.06707624097665152)\n",
      "     | > avg_loss_disc_real_5:\u001b[92m 0.20432751377423605 \u001b[0m(-0.05446879317363104)\n",
      "     | > avg_loss_0:\u001b[92m 2.9188179969787598 \u001b[0m(-0.028007547060648452)\n",
      "     | > avg_loss_gen:\u001b[92m 1.4786805709203084 \u001b[0m(-0.052920619646708245)\n",
      "     | > avg_loss_kl:\u001b[92m 3.675074259440104 \u001b[0m(-0.1519317229588828)\n",
      "     | > avg_loss_feat:\u001b[91m 0.7651070257027944 \u001b[0m(+0.09912479886164272)\n",
      "     | > avg_loss_mel:\u001b[91m 24.62924639383952 \u001b[0m(+0.4572350184122733)\n",
      "     | > avg_loss_duration:\u001b[92m 1.2735989093780518 \u001b[0m(-0.02391529083251953)\n",
      "     | > avg_loss_1:\u001b[91m 31.821707407633465 \u001b[0m(+0.3275928497314453)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 6/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:40:46) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:40:49 -- STEP: 7/32 -- GLOBAL_STEP: 1000200\u001b[0m\n",
      "     | > loss_disc: 3.0627055168151855  (2.9742598874228343)\n",
      "     | > loss_disc_real_0: 0.21484898030757904  (0.2459966582911355)\n",
      "     | > loss_disc_real_1: 0.2207263559103012  (0.24351911033902848)\n",
      "     | > loss_disc_real_2: 0.2522617280483246  (0.2530612370797566)\n",
      "     | > loss_disc_real_3: 0.24375265836715698  (0.250107222369739)\n",
      "     | > loss_disc_real_4: 0.23556940257549286  (0.25377436195101055)\n",
      "     | > loss_disc_real_5: 0.2187199890613556  (0.25859355287892477)\n",
      "     | > loss_0: 3.0627055168151855  (2.9742598874228343)\n",
      "     | > grad_norm_0: tensor(2.4158, device='cuda:0')  (tensor(1.8594, device='cuda:0'))\n",
      "     | > loss_gen: 1.6320443153381348  (1.5681278364998954)\n",
      "     | > loss_kl: 3.9153947830200195  (3.853574173791068)\n",
      "     | > loss_feat: 0.6381932497024536  (0.6928973751408714)\n",
      "     | > loss_mel: 22.138126373291016  (23.297914232526505)\n",
      "     | > loss_duration: 1.3762608766555786  (3.9398380858557567)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 29.70001983642578  (33.35235186985561)\n",
      "     | > grad_norm_1: tensor(175.9729, device='cuda:0')  (tensor(181.7741, device='cuda:0'))\n",
      "     | > current_lr_0: 0.0001998500468671882 \n",
      "     | > current_lr_1: 0.0001998500468671882 \n",
      "     | > step_time: 0.3814  (0.3904059955051967)\n",
      "     | > loader_time: 0.0032  (0.0034342833927699496)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 3.0456273555755615  (3.0456273555755615)\n",
      "     | > loss_disc_real_0: 0.23386085033416748  (0.23386085033416748)\n",
      "     | > loss_disc_real_1: 0.20453287661075592  (0.20453287661075592)\n",
      "     | > loss_disc_real_2: 0.30649566650390625  (0.30649566650390625)\n",
      "     | > loss_disc_real_3: 0.25709962844848633  (0.25709962844848633)\n",
      "     | > loss_disc_real_4: 0.27908793091773987  (0.27908793091773987)\n",
      "     | > loss_disc_real_5: 0.2402380406856537  (0.2402380406856537)\n",
      "     | > loss_0: 3.0456273555755615  (3.0456273555755615)\n",
      "     | > loss_gen: 1.5097721815109253  (1.5097721815109253)\n",
      "     | > loss_kl: 3.698737144470215  (3.698737144470215)\n",
      "     | > loss_feat: 0.39103764295578003  (0.39103764295578003)\n",
      "     | > loss_mel: 18.171701431274414  (18.171701431274414)\n",
      "     | > loss_duration: 1.451106071472168  (1.451106071472168)\n",
      "     | > loss_1: 25.222354888916016  (25.222354888916016)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.958667278289795  (2.958667278289795)\n",
      "     | > loss_disc_real_0: 0.25404196977615356  (0.25404196977615356)\n",
      "     | > loss_disc_real_1: 0.19722217321395874  (0.19722217321395874)\n",
      "     | > loss_disc_real_2: 0.3044799566268921  (0.3044799566268921)\n",
      "     | > loss_disc_real_3: 0.259068101644516  (0.259068101644516)\n",
      "     | > loss_disc_real_4: 0.27993541955947876  (0.27993541955947876)\n",
      "     | > loss_disc_real_5: 0.24513426423072815  (0.24513426423072815)\n",
      "     | > loss_0: 2.958667278289795  (2.958667278289795)\n",
      "     | > loss_gen: 1.5965017080307007  (1.5965017080307007)\n",
      "     | > loss_kl: 3.8301730155944824  (3.8301730155944824)\n",
      "     | > loss_feat: 0.5740473866462708  (0.5740473866462708)\n",
      "     | > loss_mel: 29.325014114379883  (29.325014114379883)\n",
      "     | > loss_duration: 1.3578557968139648  (1.3578557968139648)\n",
      "     | > loss_1: 36.683589935302734  (36.683589935302734)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 3.0022425651550293  (2.980454921722412)\n",
      "     | > loss_disc_real_0: 0.26123368740081787  (0.2576378285884857)\n",
      "     | > loss_disc_real_1: 0.2303837686777115  (0.2138029709458351)\n",
      "     | > loss_disc_real_2: 0.3114124834537506  (0.30794622004032135)\n",
      "     | > loss_disc_real_3: 0.26836392283439636  (0.2637160122394562)\n",
      "     | > loss_disc_real_4: 0.28680384159088135  (0.28336963057518005)\n",
      "     | > loss_disc_real_5: 0.25946375727653503  (0.2522990107536316)\n",
      "     | > loss_0: 3.0022425651550293  (2.980454921722412)\n",
      "     | > loss_gen: 1.6285312175750732  (1.612516462802887)\n",
      "     | > loss_kl: 2.7778255939483643  (3.3039993047714233)\n",
      "     | > loss_feat: 0.1146322563290596  (0.3443398214876652)\n",
      "     | > loss_mel: 17.648223876953125  (23.486618995666504)\n",
      "     | > loss_duration: 1.7269610166549683  (1.5424084067344666)\n",
      "     | > loss_1: 23.89617347717285  (30.289881706237793)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 2.8854117393493652  (2.9487738609313965)\n",
      "     | > loss_disc_real_0: 0.2008916735649109  (0.23872244358062744)\n",
      "     | > loss_disc_real_1: 0.16782580316066742  (0.1984772483507792)\n",
      "     | > loss_disc_real_2: 0.2947167754173279  (0.3035364051659902)\n",
      "     | > loss_disc_real_3: 0.24166086316108704  (0.2563642958799998)\n",
      "     | > loss_disc_real_4: 0.25849151611328125  (0.2750769257545471)\n",
      "     | > loss_disc_real_5: 0.22485464811325073  (0.24315088987350464)\n",
      "     | > loss_0: 2.8854117393493652  (2.9487738609313965)\n",
      "     | > loss_gen: 1.5224487781524658  (1.5824939012527466)\n",
      "     | > loss_kl: 3.4251136779785156  (3.3443707625071206)\n",
      "     | > loss_feat: 0.92295902967453  (0.5372128908832868)\n",
      "     | > loss_mel: 24.127197265625  (23.700145085652668)\n",
      "     | > loss_duration: 0.9039188623428345  (1.3295785586039226)\n",
      "     | > loss_1: 30.90163803100586  (30.49380048116048)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 2.8469338417053223  (2.923313856124878)\n",
      "     | > loss_disc_real_0: 0.18644391000270844  (0.2256528101861477)\n",
      "     | > loss_disc_real_1: 0.13653728365898132  (0.18299225717782974)\n",
      "     | > loss_disc_real_2: 0.28586825728416443  (0.29911936819553375)\n",
      "     | > loss_disc_real_3: 0.23389892280101776  (0.2507479526102543)\n",
      "     | > loss_disc_real_4: 0.24878889322280884  (0.26850491762161255)\n",
      "     | > loss_disc_real_5: 0.19448044896125793  (0.23098327964544296)\n",
      "     | > loss_0: 2.8469338417053223  (2.923313856124878)\n",
      "     | > loss_gen: 1.4912652969360352  (1.5596867501735687)\n",
      "     | > loss_kl: 3.8379335403442383  (3.4677614569664)\n",
      "     | > loss_feat: 1.2382502555847168  (0.7124722320586443)\n",
      "     | > loss_mel: 25.743839263916016  (24.211068630218506)\n",
      "     | > loss_duration: 1.1500612497329712  (1.2846992313861847)\n",
      "     | > loss_1: 33.46134948730469  (31.235687732696533)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 2.746668815612793  (2.887984848022461)\n",
      "     | > loss_disc_real_0: 0.17955465614795685  (0.21643317937850953)\n",
      "     | > loss_disc_real_1: 0.15994451940059662  (0.17838270962238312)\n",
      "     | > loss_disc_real_2: 0.2785053849220276  (0.29499657154083253)\n",
      "     | > loss_disc_real_3: 0.22206461429595947  (0.24501128494739532)\n",
      "     | > loss_disc_real_4: 0.22226373851299286  (0.2592566817998886)\n",
      "     | > loss_disc_real_5: 0.19022029638290405  (0.22283068299293518)\n",
      "     | > loss_0: 2.746668815612793  (2.887984848022461)\n",
      "     | > loss_gen: 1.527266502380371  (1.5532027006149292)\n",
      "     | > loss_kl: 3.2254064083099365  (3.4192904472351073)\n",
      "     | > loss_feat: 1.4354437589645386  (0.8570665374398232)\n",
      "     | > loss_mel: 24.28972816467285  (24.226800537109376)\n",
      "     | > loss_duration: 1.412490725517273  (1.3102575302124024)\n",
      "     | > loss_1: 31.890335083007812  (31.36661720275879)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 3.015695095062256  (2.9092698891957602)\n",
      "     | > loss_disc_real_0: 0.26153481006622314  (0.2239501178264618)\n",
      "     | > loss_disc_real_1: 0.22685515880584717  (0.18646145115296045)\n",
      "     | > loss_disc_real_2: 0.3105742931365967  (0.2975928584734599)\n",
      "     | > loss_disc_real_3: 0.26632755994796753  (0.2485639974474907)\n",
      "     | > loss_disc_real_4: 0.2864631712436676  (0.2637910967071851)\n",
      "     | > loss_disc_real_5: 0.25652381777763367  (0.2284462054570516)\n",
      "     | > loss_0: 3.015695095062256  (2.9092698891957602)\n",
      "     | > loss_gen: 1.6062546968460083  (1.5620446999867756)\n",
      "     | > loss_kl: 3.7010507583618164  (3.466250499089559)\n",
      "     | > loss_feat: 0.18964700400829315  (0.7458299485345682)\n",
      "     | > loss_mel: 20.315265655517578  (23.574878056844074)\n",
      "     | > loss_duration: 1.151129126548767  (1.2837361296017964)\n",
      "     | > loss_1: 26.963346481323242  (30.6327387491862)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0024176438649495444 \u001b[0m(-7.784366607666016e-05)\n",
      "     | > avg_loss_disc:\u001b[92m 2.9092698891957602 \u001b[0m(-0.009548107782999526)\n",
      "     | > avg_loss_disc_real_0:\u001b[91m 0.2239501178264618 \u001b[0m(+0.02215854823589325)\n",
      "     | > avg_loss_disc_real_1:\u001b[92m 0.18646145115296045 \u001b[0m(-0.07370897630850473)\n",
      "     | > avg_loss_disc_real_2:\u001b[91m 0.2975928584734599 \u001b[0m(+0.06367690861225131)\n",
      "     | > avg_loss_disc_real_3:\u001b[92m 0.2485639974474907 \u001b[0m(-0.011725897590319334)\n",
      "     | > avg_loss_disc_real_4:\u001b[91m 0.2637910967071851 \u001b[0m(+0.04279119521379468)\n",
      "     | > avg_loss_disc_real_5:\u001b[91m 0.2284462054570516 \u001b[0m(+0.024118691682815552)\n",
      "     | > avg_loss_0:\u001b[92m 2.9092698891957602 \u001b[0m(-0.009548107782999526)\n",
      "     | > avg_loss_gen:\u001b[91m 1.5620446999867756 \u001b[0m(+0.08336412906646729)\n",
      "     | > avg_loss_kl:\u001b[92m 3.466250499089559 \u001b[0m(-0.20882376035054495)\n",
      "     | > avg_loss_feat:\u001b[92m 0.7458299485345682 \u001b[0m(-0.019277077168226242)\n",
      "     | > avg_loss_mel:\u001b[92m 23.574878056844074 \u001b[0m(-1.054368336995445)\n",
      "     | > avg_loss_duration:\u001b[91m 1.2837361296017964 \u001b[0m(+0.010137220223744636)\n",
      "     | > avg_loss_1:\u001b[92m 30.6327387491862 \u001b[0m(-1.1889686584472656)\n",
      "\n",
      " > BEST MODEL : /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1/best_model_1000225.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 7/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:41:05) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:41:06 -- STEP: 0/32 -- GLOBAL_STEP: 1000225\u001b[0m\n",
      "     | > loss_disc: 3.004987955093384  (3.004987955093384)\n",
      "     | > loss_disc_real_0: 0.2543531060218811  (0.2543531060218811)\n",
      "     | > loss_disc_real_1: 0.23232890665531158  (0.23232890665531158)\n",
      "     | > loss_disc_real_2: 0.31144171953201294  (0.31144171953201294)\n",
      "     | > loss_disc_real_3: 0.2670307457447052  (0.2670307457447052)\n",
      "     | > loss_disc_real_4: 0.28627458214759827  (0.28627458214759827)\n",
      "     | > loss_disc_real_5: 0.2579580843448639  (0.2579580843448639)\n",
      "     | > loss_0: 3.004987955093384  (3.004987955093384)\n",
      "     | > grad_norm_0: tensor(1.3573, device='cuda:0')  (tensor(1.3573, device='cuda:0'))\n",
      "     | > loss_gen: 1.380934476852417  (1.380934476852417)\n",
      "     | > loss_kl: 3.6417148113250732  (3.6417148113250732)\n",
      "     | > loss_feat: 0.11561083793640137  (0.11561083793640137)\n",
      "     | > loss_mel: 21.56520652770996  (21.56520652770996)\n",
      "     | > loss_duration: 1.2032297849655151  (1.2032297849655151)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 27.906696319580078  (27.906696319580078)\n",
      "     | > grad_norm_1: tensor(371.5889, device='cuda:0')  (tensor(371.5889, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019982506561132978 \n",
      "     | > current_lr_1: 0.00019982506561132978 \n",
      "     | > step_time: 0.5259  (0.5258965492248535)\n",
      "     | > loader_time: 0.3261  (0.3261406421661377)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:41:16 -- STEP: 25/32 -- GLOBAL_STEP: 1000250\u001b[0m\n",
      "     | > loss_disc: 2.9107041358947754  (2.9486232089996336)\n",
      "     | > loss_disc_real_0: 0.23418426513671875  (0.2430580335855484)\n",
      "     | > loss_disc_real_1: 0.20833644270896912  (0.24887344479560852)\n",
      "     | > loss_disc_real_2: 0.17076857388019562  (0.2449487715959549)\n",
      "     | > loss_disc_real_3: 0.18066345155239105  (0.2487698394060135)\n",
      "     | > loss_disc_real_4: 0.17414547502994537  (0.24616496741771698)\n",
      "     | > loss_disc_real_5: 0.1776999682188034  (0.24817283809185028)\n",
      "     | > loss_0: 2.9107041358947754  (2.9486232089996336)\n",
      "     | > grad_norm_0: tensor(3.1285, device='cuda:0')  (tensor(2.4997, device='cuda:0'))\n",
      "     | > loss_gen: 1.5575027465820312  (1.6036325550079347)\n",
      "     | > loss_kl: 3.461790084838867  (3.480578022003174)\n",
      "     | > loss_feat: 1.7411890029907227  (0.9346233063936233)\n",
      "     | > loss_mel: 24.878524780273438  (23.778636627197265)\n",
      "     | > loss_duration: 1.5818054676055908  (3.068570532798767)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 33.2208137512207  (32.86604103088379)\n",
      "     | > grad_norm_1: tensor(124.3196, device='cuda:0')  (tensor(137.9059, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019982506561132978 \n",
      "     | > current_lr_1: 0.00019982506561132978 \n",
      "     | > step_time: 0.3866  (0.3892708873748779)\n",
      "     | > loader_time: 0.0035  (0.0035591888427734374)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.9904427528381348  (2.9904427528381348)\n",
      "     | > loss_disc_real_0: 0.2036646455526352  (0.2036646455526352)\n",
      "     | > loss_disc_real_1: 0.2956775724887848  (0.2956775724887848)\n",
      "     | > loss_disc_real_2: 0.2928743362426758  (0.2928743362426758)\n",
      "     | > loss_disc_real_3: 0.28372621536254883  (0.28372621536254883)\n",
      "     | > loss_disc_real_4: 0.26849836111068726  (0.26849836111068726)\n",
      "     | > loss_disc_real_5: 0.2466055154800415  (0.2466055154800415)\n",
      "     | > loss_0: 2.9904427528381348  (2.9904427528381348)\n",
      "     | > loss_gen: 1.6230194568634033  (1.6230194568634033)\n",
      "     | > loss_kl: 3.6855316162109375  (3.6855316162109375)\n",
      "     | > loss_feat: 0.7513460516929626  (0.7513460516929626)\n",
      "     | > loss_mel: 20.881851196289062  (20.881851196289062)\n",
      "     | > loss_duration: 1.4715924263000488  (1.4715924263000488)\n",
      "     | > loss_1: 28.413341522216797  (28.413341522216797)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 3.0251030921936035  (3.0251030921936035)\n",
      "     | > loss_disc_real_0: 0.21681706607341766  (0.21681706607341766)\n",
      "     | > loss_disc_real_1: 0.30949556827545166  (0.30949556827545166)\n",
      "     | > loss_disc_real_2: 0.2996075451374054  (0.2996075451374054)\n",
      "     | > loss_disc_real_3: 0.30025696754455566  (0.30025696754455566)\n",
      "     | > loss_disc_real_4: 0.27623850107192993  (0.27623850107192993)\n",
      "     | > loss_disc_real_5: 0.27534016966819763  (0.27534016966819763)\n",
      "     | > loss_0: 3.0251030921936035  (3.0251030921936035)\n",
      "     | > loss_gen: 1.6749496459960938  (1.6749496459960938)\n",
      "     | > loss_kl: 4.157696723937988  (4.157696723937988)\n",
      "     | > loss_feat: 0.28035441040992737  (0.28035441040992737)\n",
      "     | > loss_mel: 30.618438720703125  (30.618438720703125)\n",
      "     | > loss_duration: 1.3531290292739868  (1.3531290292739868)\n",
      "     | > loss_1: 38.08456802368164  (38.08456802368164)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 3.0300118923187256  (3.0275574922561646)\n",
      "     | > loss_disc_real_0: 0.20193839073181152  (0.2093777284026146)\n",
      "     | > loss_disc_real_1: 0.31150057911872864  (0.31049807369709015)\n",
      "     | > loss_disc_real_2: 0.29963749647140503  (0.2996225208044052)\n",
      "     | > loss_disc_real_3: 0.3028239905834198  (0.30154047906398773)\n",
      "     | > loss_disc_real_4: 0.2752144932746887  (0.2757264971733093)\n",
      "     | > loss_disc_real_5: 0.27127647399902344  (0.27330832183361053)\n",
      "     | > loss_0: 3.0300118923187256  (3.0275574922561646)\n",
      "     | > loss_gen: 1.6579041481018066  (1.6664268970489502)\n",
      "     | > loss_kl: 3.2142298221588135  (3.685963273048401)\n",
      "     | > loss_feat: 0.10136260092258453  (0.19085850566625595)\n",
      "     | > loss_mel: 17.775470733642578  (24.19695472717285)\n",
      "     | > loss_duration: 1.6973345279693604  (1.5252317786216736)\n",
      "     | > loss_1: 24.446300506591797  (31.26543426513672)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 3.2858359813690186  (3.113650321960449)\n",
      "     | > loss_disc_real_0: 0.10778289288282394  (0.17551278322935104)\n",
      "     | > loss_disc_real_1: 0.22472262382507324  (0.28190625707308453)\n",
      "     | > loss_disc_real_2: 0.2507730722427368  (0.28333937128384906)\n",
      "     | > loss_disc_real_3: 0.2454151064157486  (0.2828320215145747)\n",
      "     | > loss_disc_real_4: 0.2165263295173645  (0.25599310795466107)\n",
      "     | > loss_disc_real_5: 0.1870959848165512  (0.24457087616125742)\n",
      "     | > loss_0: 3.2858359813690186  (3.113650321960449)\n",
      "     | > loss_gen: 1.2025580406188965  (1.5118039449055989)\n",
      "     | > loss_kl: 4.046238899230957  (3.8060551484425864)\n",
      "     | > loss_feat: 1.4570167064666748  (0.6129112392663956)\n",
      "     | > loss_mel: 24.195749282836914  (24.196552912394207)\n",
      "     | > loss_duration: 0.8951780200004578  (1.3152138590812683)\n",
      "     | > loss_1: 31.796741485595703  (31.44253667195638)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 2.9472861289978027  (3.0720592737197876)\n",
      "     | > loss_disc_real_0: 0.19132748246192932  (0.1794664580374956)\n",
      "     | > loss_disc_real_1: 0.269610196352005  (0.27883224189281464)\n",
      "     | > loss_disc_real_2: 0.2910875082015991  (0.2852764055132866)\n",
      "     | > loss_disc_real_3: 0.29357296228408813  (0.28551725670695305)\n",
      "     | > loss_disc_real_4: 0.2657109200954437  (0.2584225609898567)\n",
      "     | > loss_disc_real_5: 0.2657315135002136  (0.24986103549599648)\n",
      "     | > loss_0: 2.9472861289978027  (3.0720592737197876)\n",
      "     | > loss_gen: 1.6509926319122314  (1.546601116657257)\n",
      "     | > loss_kl: 3.584397315979004  (3.7506406903266907)\n",
      "     | > loss_feat: 0.5537367463111877  (0.5981176160275936)\n",
      "     | > loss_mel: 22.8804931640625  (23.86753797531128)\n",
      "     | > loss_duration: 1.1414330005645752  (1.271768644452095)\n",
      "     | > loss_1: 29.811054229736328  (31.034666061401367)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 3.022911548614502  (3.0622297286987306)\n",
      "     | > loss_disc_real_0: 0.1592240333557129  (0.17541797310113907)\n",
      "     | > loss_disc_real_1: 0.23666490614414215  (0.27039877474308016)\n",
      "     | > loss_disc_real_2: 0.22889243066310883  (0.27399961054325106)\n",
      "     | > loss_disc_real_3: 0.23828352987766266  (0.27607051134109495)\n",
      "     | > loss_disc_real_4: 0.20055758953094482  (0.24684956669807434)\n",
      "     | > loss_disc_real_5: 0.19021210074424744  (0.23793124854564668)\n",
      "     | > loss_0: 3.022911548614502  (3.0622297286987306)\n",
      "     | > loss_gen: 1.3822263479232788  (1.5137261629104615)\n",
      "     | > loss_kl: 3.5661957263946533  (3.713751697540283)\n",
      "     | > loss_feat: 1.1769969463348389  (0.7138934820890427)\n",
      "     | > loss_mel: 22.308147430419922  (23.55565986633301)\n",
      "     | > loss_duration: 1.4239619970321655  (1.302207314968109)\n",
      "     | > loss_1: 29.857528686523438  (30.79923858642578)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 3.025768280029297  (3.056152820587158)\n",
      "     | > loss_disc_real_0: 0.200461745262146  (0.17959193512797356)\n",
      "     | > loss_disc_real_1: 0.3067098557949066  (0.27645062158505124)\n",
      "     | > loss_disc_real_2: 0.29891419410705566  (0.2781520411372185)\n",
      "     | > loss_disc_real_3: 0.30246827006340027  (0.2804701377948125)\n",
      "     | > loss_disc_real_4: 0.276724249124527  (0.25182868043581647)\n",
      "     | > loss_disc_real_5: 0.2757466435432434  (0.24423381437857947)\n",
      "     | > loss_0: 3.025768280029297  (3.056152820587158)\n",
      "     | > loss_gen: 1.6601625680923462  (1.5381322304407756)\n",
      "     | > loss_kl: 3.6086175441741943  (3.696229338645935)\n",
      "     | > loss_feat: 0.1954280436038971  (0.6274825756748518)\n",
      "     | > loss_mel: 22.367591857910156  (23.357648531595867)\n",
      "     | > loss_duration: 1.1601022481918335  (1.2785231371720631)\n",
      "     | > loss_1: 28.99190330505371  (30.498016039530437)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0023780266443888345 \u001b[0m(-3.9617220560709925e-05)\n",
      "     | > avg_loss_disc:\u001b[91m 3.056152820587158 \u001b[0m(+0.14688293139139796)\n",
      "     | > avg_loss_disc_real_0:\u001b[92m 0.17959193512797356 \u001b[0m(-0.044358182698488235)\n",
      "     | > avg_loss_disc_real_1:\u001b[91m 0.27645062158505124 \u001b[0m(+0.08998917043209079)\n",
      "     | > avg_loss_disc_real_2:\u001b[92m 0.2781520411372185 \u001b[0m(-0.019440817336241423)\n",
      "     | > avg_loss_disc_real_3:\u001b[91m 0.2804701377948125 \u001b[0m(+0.03190614034732181)\n",
      "     | > avg_loss_disc_real_4:\u001b[92m 0.25182868043581647 \u001b[0m(-0.011962416271368626)\n",
      "     | > avg_loss_disc_real_5:\u001b[91m 0.24423381437857947 \u001b[0m(+0.015787608921527863)\n",
      "     | > avg_loss_0:\u001b[91m 3.056152820587158 \u001b[0m(+0.14688293139139796)\n",
      "     | > avg_loss_gen:\u001b[92m 1.5381322304407756 \u001b[0m(-0.023912469546000015)\n",
      "     | > avg_loss_kl:\u001b[91m 3.696229338645935 \u001b[0m(+0.229978839556376)\n",
      "     | > avg_loss_feat:\u001b[92m 0.6274825756748518 \u001b[0m(-0.11834737285971642)\n",
      "     | > avg_loss_mel:\u001b[92m 23.357648531595867 \u001b[0m(-0.21722952524820727)\n",
      "     | > avg_loss_duration:\u001b[92m 1.2785231371720631 \u001b[0m(-0.005212992429733276)\n",
      "     | > avg_loss_1:\u001b[92m 30.498016039530437 \u001b[0m(-0.13472270965576172)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 8/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:41:22) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:41:30 -- STEP: 18/32 -- GLOBAL_STEP: 1000275\u001b[0m\n",
      "     | > loss_disc: 2.896718740463257  (3.0774268176820545)\n",
      "     | > loss_disc_real_0: 0.2611241936683655  (0.27330398394001854)\n",
      "     | > loss_disc_real_1: 0.21130366623401642  (0.27658461613787544)\n",
      "     | > loss_disc_real_2: 0.20838966965675354  (0.28635971496502566)\n",
      "     | > loss_disc_real_3: 0.20358328521251678  (0.27127376364337075)\n",
      "     | > loss_disc_real_4: 0.2280571311712265  (0.2779991899927457)\n",
      "     | > loss_disc_real_5: 0.2675177752971649  (0.2829056398736106)\n",
      "     | > loss_0: 2.896718740463257  (3.0774268176820545)\n",
      "     | > grad_norm_0: tensor(1.4716, device='cuda:0')  (tensor(5.4565, device='cuda:0'))\n",
      "     | > loss_gen: 1.390794277191162  (1.7352637184990778)\n",
      "     | > loss_kl: 3.5866761207580566  (3.4509974585639105)\n",
      "     | > loss_feat: 0.8547067046165466  (0.9609731270207299)\n",
      "     | > loss_mel: 25.983287811279297  (24.572851816813152)\n",
      "     | > loss_duration: 1.291580080986023  (2.943094882700178)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 33.1070442199707  (33.6631809870402)\n",
      "     | > grad_norm_1: tensor(121.2481, device='cuda:0')  (tensor(179.2255, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019980008747812837 \n",
      "     | > current_lr_1: 0.00019980008747812837 \n",
      "     | > step_time: 0.3846  (0.3925167719523112)\n",
      "     | > loader_time: 0.0033  (0.0035044617123074)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 3.0057973861694336  (3.0057973861694336)\n",
      "     | > loss_disc_real_0: 0.2029632329940796  (0.2029632329940796)\n",
      "     | > loss_disc_real_1: 0.2002967894077301  (0.2002967894077301)\n",
      "     | > loss_disc_real_2: 0.2333889603614807  (0.2333889603614807)\n",
      "     | > loss_disc_real_3: 0.22044269740581512  (0.22044269740581512)\n",
      "     | > loss_disc_real_4: 0.23721030354499817  (0.23721030354499817)\n",
      "     | > loss_disc_real_5: 0.23193402588367462  (0.23193402588367462)\n",
      "     | > loss_0: 3.0057973861694336  (3.0057973861694336)\n",
      "     | > loss_gen: 1.3395462036132812  (1.3395462036132812)\n",
      "     | > loss_kl: 3.503066301345825  (3.503066301345825)\n",
      "     | > loss_feat: 0.44670259952545166  (0.44670259952545166)\n",
      "     | > loss_mel: 21.873247146606445  (21.873247146606445)\n",
      "     | > loss_duration: 1.460248589515686  (1.460248589515686)\n",
      "     | > loss_1: 28.622812271118164  (28.622812271118164)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.9588770866394043  (2.9588770866394043)\n",
      "     | > loss_disc_real_0: 0.1673825979232788  (0.1673825979232788)\n",
      "     | > loss_disc_real_1: 0.19963175058364868  (0.19963175058364868)\n",
      "     | > loss_disc_real_2: 0.23174335062503815  (0.23174335062503815)\n",
      "     | > loss_disc_real_3: 0.2205733060836792  (0.2205733060836792)\n",
      "     | > loss_disc_real_4: 0.22598682343959808  (0.22598682343959808)\n",
      "     | > loss_disc_real_5: 0.22733399271965027  (0.22733399271965027)\n",
      "     | > loss_0: 2.9588770866394043  (2.9588770866394043)\n",
      "     | > loss_gen: 1.334869146347046  (1.334869146347046)\n",
      "     | > loss_kl: 4.053879737854004  (4.053879737854004)\n",
      "     | > loss_feat: 0.4872298836708069  (0.4872298836708069)\n",
      "     | > loss_mel: 18.646995544433594  (18.646995544433594)\n",
      "     | > loss_duration: 1.3664772510528564  (1.3664772510528564)\n",
      "     | > loss_1: 25.88945198059082  (25.88945198059082)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 2.9507226943969727  (2.9547998905181885)\n",
      "     | > loss_disc_real_0: 0.17543578147888184  (0.17140918970108032)\n",
      "     | > loss_disc_real_1: 0.20083443820476532  (0.200233094394207)\n",
      "     | > loss_disc_real_2: 0.23114325106143951  (0.23144330084323883)\n",
      "     | > loss_disc_real_3: 0.21522225439548492  (0.21789778023958206)\n",
      "     | > loss_disc_real_4: 0.23001310229301453  (0.2279999628663063)\n",
      "     | > loss_disc_real_5: 0.22063465416431427  (0.22398432344198227)\n",
      "     | > loss_0: 2.9507226943969727  (2.9547998905181885)\n",
      "     | > loss_gen: 1.3454142808914185  (1.3401417136192322)\n",
      "     | > loss_kl: 3.2721850872039795  (3.6630324125289917)\n",
      "     | > loss_feat: 0.4931197762489319  (0.4901748299598694)\n",
      "     | > loss_mel: 21.409360885620117  (20.028178215026855)\n",
      "     | > loss_duration: 1.657170295715332  (1.5118237733840942)\n",
      "     | > loss_1: 28.177249908447266  (27.033350944519043)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 2.8062856197357178  (2.9052951335906982)\n",
      "     | > loss_disc_real_0: 0.13165558874607086  (0.15815798938274384)\n",
      "     | > loss_disc_real_1: 0.16985248029232025  (0.1901062230269114)\n",
      "     | > loss_disc_real_2: 0.21981513500213623  (0.2275672455628713)\n",
      "     | > loss_disc_real_3: 0.1722055971622467  (0.20266705254713693)\n",
      "     | > loss_disc_real_4: 0.19683624804019928  (0.21761205792427063)\n",
      "     | > loss_disc_real_5: 0.19393615424633026  (0.2139682670434316)\n",
      "     | > loss_0: 2.8062856197357178  (2.9052951335906982)\n",
      "     | > loss_gen: 1.3000659942626953  (1.3267831405003865)\n",
      "     | > loss_kl: 3.8994455337524414  (3.7418367862701416)\n",
      "     | > loss_feat: 1.5212407112121582  (0.8338634570439657)\n",
      "     | > loss_mel: 27.134580612182617  (22.396979014078777)\n",
      "     | > loss_duration: 0.8845553398132324  (1.3027342955271404)\n",
      "     | > loss_1: 34.73988723754883  (29.602196375528973)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 2.986149311065674  (2.925508677959442)\n",
      "     | > loss_disc_real_0: 0.19510947167873383  (0.16739585995674133)\n",
      "     | > loss_disc_real_1: 0.21228095889091492  (0.1956499069929123)\n",
      "     | > loss_disc_real_2: 0.23461388051509857  (0.22932890430092812)\n",
      "     | > loss_disc_real_3: 0.22614765167236328  (0.20853720232844353)\n",
      "     | > loss_disc_real_4: 0.24093927443027496  (0.2234438620507717)\n",
      "     | > loss_disc_real_5: 0.2400008887052536  (0.2204764224588871)\n",
      "     | > loss_0: 2.986149311065674  (2.925508677959442)\n",
      "     | > loss_gen: 1.3734216690063477  (1.3384427726268768)\n",
      "     | > loss_kl: 3.483607769012451  (3.677279531955719)\n",
      "     | > loss_feat: 0.26054373383522034  (0.6905335262417793)\n",
      "     | > loss_mel: 20.474769592285156  (21.91642665863037)\n",
      "     | > loss_duration: 1.1437355279922485  (1.2629846036434174)\n",
      "     | > loss_1: 26.7360782623291  (28.885666847229004)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 2.9490749835968018  (2.930221939086914)\n",
      "     | > loss_disc_real_0: 0.15815582871437073  (0.16554785370826722)\n",
      "     | > loss_disc_real_1: 0.19610176980495453  (0.19574027955532075)\n",
      "     | > loss_disc_real_2: 0.2244364470243454  (0.22835041284561158)\n",
      "     | > loss_disc_real_3: 0.18471971154212952  (0.20377370417118074)\n",
      "     | > loss_disc_real_4: 0.1962910294532776  (0.21801329553127288)\n",
      "     | > loss_disc_real_5: 0.19850237667560577  (0.21608161330223083)\n",
      "     | > loss_0: 2.9490749835968018  (2.930221939086914)\n",
      "     | > loss_gen: 1.2608299255371094  (1.3229202032089233)\n",
      "     | > loss_kl: 3.0523152351379395  (3.552286672592163)\n",
      "     | > loss_feat: 0.8800557851791382  (0.7284379780292511)\n",
      "     | > loss_mel: 20.971010208129883  (21.727343368530274)\n",
      "     | > loss_duration: 1.4084358215332031  (1.2920748472213746)\n",
      "     | > loss_1: 27.572647094726562  (28.623062896728516)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 2.9421546459198  (2.9322107235590615)\n",
      "     | > loss_disc_real_0: 0.1960395872592926  (0.17062980930010477)\n",
      "     | > loss_disc_real_1: 0.2078109085559845  (0.19775205105543137)\n",
      "     | > loss_disc_real_2: 0.2320518046617508  (0.22896731148163477)\n",
      "     | > loss_disc_real_3: 0.21151088178157806  (0.2050632337729136)\n",
      "     | > loss_disc_real_4: 0.2263903021812439  (0.21940946330626807)\n",
      "     | > loss_disc_real_5: 0.21995002031326294  (0.21672634780406952)\n",
      "     | > loss_0: 2.9421546459198  (2.9322107235590615)\n",
      "     | > loss_gen: 1.363328218460083  (1.32965487241745)\n",
      "     | > loss_kl: 3.37734317779541  (3.523129423459371)\n",
      "     | > loss_feat: 0.5313193202018738  (0.6955848683913549)\n",
      "     | > loss_mel: 22.819599151611328  (21.90938599904378)\n",
      "     | > loss_duration: 1.1527531147003174  (1.268854558467865)\n",
      "     | > loss_1: 29.24434471130371  (28.726609865824383)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.002464850743611654 \u001b[0m(+8.68240992228193e-05)\n",
      "     | > avg_loss_disc:\u001b[92m 2.9322107235590615 \u001b[0m(-0.12394209702809666)\n",
      "     | > avg_loss_disc_real_0:\u001b[92m 0.17062980930010477 \u001b[0m(-0.008962125827868789)\n",
      "     | > avg_loss_disc_real_1:\u001b[92m 0.19775205105543137 \u001b[0m(-0.07869857052961987)\n",
      "     | > avg_loss_disc_real_2:\u001b[92m 0.22896731148163477 \u001b[0m(-0.04918472965558371)\n",
      "     | > avg_loss_disc_real_3:\u001b[92m 0.2050632337729136 \u001b[0m(-0.0754069040218989)\n",
      "     | > avg_loss_disc_real_4:\u001b[92m 0.21940946330626807 \u001b[0m(-0.0324192171295484)\n",
      "     | > avg_loss_disc_real_5:\u001b[92m 0.21672634780406952 \u001b[0m(-0.027507466574509948)\n",
      "     | > avg_loss_0:\u001b[92m 2.9322107235590615 \u001b[0m(-0.12394209702809666)\n",
      "     | > avg_loss_gen:\u001b[92m 1.32965487241745 \u001b[0m(-0.20847735802332568)\n",
      "     | > avg_loss_kl:\u001b[92m 3.523129423459371 \u001b[0m(-0.17309991518656398)\n",
      "     | > avg_loss_feat:\u001b[91m 0.6955848683913549 \u001b[0m(+0.06810229271650314)\n",
      "     | > avg_loss_mel:\u001b[92m 21.90938599904378 \u001b[0m(-1.4482625325520857)\n",
      "     | > avg_loss_duration:\u001b[92m 1.268854558467865 \u001b[0m(-0.009668578704198127)\n",
      "     | > avg_loss_1:\u001b[92m 28.726609865824383 \u001b[0m(-1.7714061737060547)\n",
      "\n",
      " > BEST MODEL : /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1/best_model_1000289.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 9/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:41:42) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:41:48 -- STEP: 11/32 -- GLOBAL_STEP: 1000300\u001b[0m\n",
      "     | > loss_disc: 2.8307363986968994  (2.9432595643130215)\n",
      "     | > loss_disc_real_0: 0.23796014487743378  (0.2379658411849629)\n",
      "     | > loss_disc_real_1: 0.26695898175239563  (0.26071669974110345)\n",
      "     | > loss_disc_real_2: 0.24546486139297485  (0.2511845989660783)\n",
      "     | > loss_disc_real_3: 0.2604740858078003  (0.2666909843683243)\n",
      "     | > loss_disc_real_4: 0.25994282960891724  (0.26729237085038965)\n",
      "     | > loss_disc_real_5: 0.25698304176330566  (0.25363856283101166)\n",
      "     | > loss_0: 2.8307363986968994  (2.9432595643130215)\n",
      "     | > grad_norm_0: tensor(1.3800, device='cuda:0')  (tensor(1.9140, device='cuda:0'))\n",
      "     | > loss_gen: 1.5397452116012573  (1.6414571783759377)\n",
      "     | > loss_kl: 3.1238515377044678  (3.4373865127563477)\n",
      "     | > loss_feat: 1.1187664270401  (0.8150636445392262)\n",
      "     | > loss_mel: 20.73832130432129  (22.76845221085982)\n",
      "     | > loss_duration: 1.9400925636291504  (4.00836845961484)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 28.460777282714844  (32.67072868347168)\n",
      "     | > grad_norm_1: tensor(129.5682, device='cuda:0')  (tensor(119.2582, device='cuda:0'))\n",
      "     | > current_lr_0: 0.0001997751124671936 \n",
      "     | > current_lr_1: 0.0001997751124671936 \n",
      "     | > step_time: 0.3939  (0.4132918661290949)\n",
      "     | > loader_time: 0.0028  (0.0035093047402121806)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.970571279525757  (2.970571279525757)\n",
      "     | > loss_disc_real_0: 0.2549435794353485  (0.2549435794353485)\n",
      "     | > loss_disc_real_1: 0.2555844187736511  (0.2555844187736511)\n",
      "     | > loss_disc_real_2: 0.2419404536485672  (0.2419404536485672)\n",
      "     | > loss_disc_real_3: 0.22621938586235046  (0.22621938586235046)\n",
      "     | > loss_disc_real_4: 0.23511600494384766  (0.23511600494384766)\n",
      "     | > loss_disc_real_5: 0.2277601659297943  (0.2277601659297943)\n",
      "     | > loss_0: 2.970571279525757  (2.970571279525757)\n",
      "     | > loss_gen: 1.4759202003479004  (1.4759202003479004)\n",
      "     | > loss_kl: 3.8477632999420166  (3.8477632999420166)\n",
      "     | > loss_feat: 0.6326943635940552  (0.6326943635940552)\n",
      "     | > loss_mel: 23.067520141601562  (23.067520141601562)\n",
      "     | > loss_duration: 1.455918550491333  (1.455918550491333)\n",
      "     | > loss_1: 30.479816436767578  (30.479816436767578)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.985045909881592  (2.985045909881592)\n",
      "     | > loss_disc_real_0: 0.2491150200366974  (0.2491150200366974)\n",
      "     | > loss_disc_real_1: 0.26249122619628906  (0.26249122619628906)\n",
      "     | > loss_disc_real_2: 0.2541888356208801  (0.2541888356208801)\n",
      "     | > loss_disc_real_3: 0.24117247760295868  (0.24117247760295868)\n",
      "     | > loss_disc_real_4: 0.24600006639957428  (0.24600006639957428)\n",
      "     | > loss_disc_real_5: 0.24564915895462036  (0.24564915895462036)\n",
      "     | > loss_0: 2.985045909881592  (2.985045909881592)\n",
      "     | > loss_gen: 1.515628695487976  (1.515628695487976)\n",
      "     | > loss_kl: 4.044865608215332  (4.044865608215332)\n",
      "     | > loss_feat: 0.27346718311309814  (0.27346718311309814)\n",
      "     | > loss_mel: 29.0877742767334  (29.0877742767334)\n",
      "     | > loss_duration: 1.3502963781356812  (1.3502963781356812)\n",
      "     | > loss_1: 36.272029876708984  (36.272029876708984)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 2.9739131927490234  (2.9794795513153076)\n",
      "     | > loss_disc_real_0: 0.23174020648002625  (0.24042761325836182)\n",
      "     | > loss_disc_real_1: 0.2670179605484009  (0.26475459337234497)\n",
      "     | > loss_disc_real_2: 0.24992303550243378  (0.25205593556165695)\n",
      "     | > loss_disc_real_3: 0.23504985868930817  (0.23811116814613342)\n",
      "     | > loss_disc_real_4: 0.24222737550735474  (0.2441137209534645)\n",
      "     | > loss_disc_real_5: 0.23991656303405762  (0.242782860994339)\n",
      "     | > loss_0: 2.9739131927490234  (2.9794795513153076)\n",
      "     | > loss_gen: 1.4963260889053345  (1.5059773921966553)\n",
      "     | > loss_kl: 3.250075340270996  (3.647470474243164)\n",
      "     | > loss_feat: 0.4081686735153198  (0.340817928314209)\n",
      "     | > loss_mel: 22.543739318847656  (25.815756797790527)\n",
      "     | > loss_duration: 1.7069780826568604  (1.5286372303962708)\n",
      "     | > loss_1: 29.405288696289062  (32.83865928649902)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 3.016954183578491  (2.9919710954030356)\n",
      "     | > loss_disc_real_0: 0.24468424916267395  (0.24184649189313254)\n",
      "     | > loss_disc_real_1: 0.2771986424922943  (0.26890260974566144)\n",
      "     | > loss_disc_real_2: 0.25550445914268494  (0.25320544342199963)\n",
      "     | > loss_disc_real_3: 0.2437969148159027  (0.24000641703605652)\n",
      "     | > loss_disc_real_4: 0.24695593118667603  (0.245061124364535)\n",
      "     | > loss_disc_real_5: 0.2481681853532791  (0.2445779691139857)\n",
      "     | > loss_0: 3.016954183578491  (2.9919710954030356)\n",
      "     | > loss_gen: 1.5032559633255005  (1.5050702492396038)\n",
      "     | > loss_kl: 3.728872537612915  (3.6746044953664145)\n",
      "     | > loss_feat: 0.1788560450077057  (0.2868306338787079)\n",
      "     | > loss_mel: 21.44454002380371  (24.358684539794922)\n",
      "     | > loss_duration: 0.8816057443618774  (1.3129600683848064)\n",
      "     | > loss_1: 27.73712921142578  (31.13814926147461)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 3.0012083053588867  (2.9942803978919983)\n",
      "     | > loss_disc_real_0: 0.24861928820610046  (0.2435396909713745)\n",
      "     | > loss_disc_real_1: 0.2748585045337677  (0.270391583442688)\n",
      "     | > loss_disc_real_2: 0.2572331726551056  (0.2542123757302761)\n",
      "     | > loss_disc_real_3: 0.24439075589179993  (0.24110250174999237)\n",
      "     | > loss_disc_real_4: 0.2478959709405899  (0.24576983600854874)\n",
      "     | > loss_disc_real_5: 0.2498205304145813  (0.2458886094391346)\n",
      "     | > loss_0: 3.0012083053588867  (2.9942803978919983)\n",
      "     | > loss_gen: 1.523666501045227  (1.5097193121910095)\n",
      "     | > loss_kl: 3.2780580520629883  (3.575467884540558)\n",
      "     | > loss_feat: 0.06380364298820496  (0.23107388615608215)\n",
      "     | > loss_mel: 21.97193145751953  (23.761996269226074)\n",
      "     | > loss_duration: 1.138744592666626  (1.2694061994552612)\n",
      "     | > loss_1: 27.97620391845703  (30.347662925720215)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 3.0234642028808594  (3.0001171588897706)\n",
      "     | > loss_disc_real_0: 0.16764459013938904  (0.2283606708049774)\n",
      "     | > loss_disc_real_1: 0.22419679164886475  (0.26115262508392334)\n",
      "     | > loss_disc_real_2: 0.22112536430358887  (0.24759497344493867)\n",
      "     | > loss_disc_real_3: 0.1824600100517273  (0.22937400341033937)\n",
      "     | > loss_disc_real_4: 0.19181908667087555  (0.2349796861410141)\n",
      "     | > loss_disc_real_5: 0.18017379939556122  (0.23274564743041992)\n",
      "     | > loss_0: 3.0234642028808594  (3.0001171588897706)\n",
      "     | > loss_gen: 1.2350589036941528  (1.4547872304916383)\n",
      "     | > loss_kl: 3.1789538860321045  (3.496165084838867)\n",
      "     | > loss_feat: 1.2514533996582031  (0.43514978885650635)\n",
      "     | > loss_mel: 22.29174041748047  (23.467945098876953)\n",
      "     | > loss_duration: 1.4047882556915283  (1.2964826107025147)\n",
      "     | > loss_1: 29.361997604370117  (30.150529861450195)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 2.8989737033843994  (2.983259916305542)\n",
      "     | > loss_disc_real_0: 0.2124951183795929  (0.22571641206741333)\n",
      "     | > loss_disc_real_1: 0.25332310795783997  (0.2598477055629094)\n",
      "     | > loss_disc_real_2: 0.24038633704185486  (0.24639353404442468)\n",
      "     | > loss_disc_real_3: 0.22837387025356293  (0.22920731455087662)\n",
      "     | > loss_disc_real_4: 0.23017680644989014  (0.23417920619249344)\n",
      "     | > loss_disc_real_5: 0.2330894023180008  (0.2328029399116834)\n",
      "     | > loss_0: 2.8989737033843994  (2.983259916305542)\n",
      "     | > loss_gen: 1.5154372453689575  (1.4648955663045247)\n",
      "     | > loss_kl: 3.0539700984954834  (3.4224659204483032)\n",
      "     | > loss_feat: 0.8127486109733582  (0.49808292587598163)\n",
      "     | > loss_mel: 22.745832443237305  (23.34759298960368)\n",
      "     | > loss_duration: 1.144749641418457  (1.2711937824885051)\n",
      "     | > loss_1: 29.27273941040039  (30.004231452941895)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0023746887842814126 \u001b[0m(-9.016195933024117e-05)\n",
      "     | > avg_loss_disc:\u001b[91m 2.983259916305542 \u001b[0m(+0.051049192746480454)\n",
      "     | > avg_loss_disc_real_0:\u001b[91m 0.22571641206741333 \u001b[0m(+0.05508660276730856)\n",
      "     | > avg_loss_disc_real_1:\u001b[91m 0.2598477055629094 \u001b[0m(+0.06209565450747806)\n",
      "     | > avg_loss_disc_real_2:\u001b[91m 0.24639353404442468 \u001b[0m(+0.017426222562789917)\n",
      "     | > avg_loss_disc_real_3:\u001b[91m 0.22920731455087662 \u001b[0m(+0.024144080777963012)\n",
      "     | > avg_loss_disc_real_4:\u001b[91m 0.23417920619249344 \u001b[0m(+0.014769742886225373)\n",
      "     | > avg_loss_disc_real_5:\u001b[91m 0.2328029399116834 \u001b[0m(+0.01607659210761389)\n",
      "     | > avg_loss_0:\u001b[91m 2.983259916305542 \u001b[0m(+0.051049192746480454)\n",
      "     | > avg_loss_gen:\u001b[91m 1.4648955663045247 \u001b[0m(+0.13524069388707471)\n",
      "     | > avg_loss_kl:\u001b[92m 3.4224659204483032 \u001b[0m(-0.10066350301106786)\n",
      "     | > avg_loss_feat:\u001b[92m 0.49808292587598163 \u001b[0m(-0.19750194251537329)\n",
      "     | > avg_loss_mel:\u001b[91m 23.34759298960368 \u001b[0m(+1.4382069905598982)\n",
      "     | > avg_loss_duration:\u001b[91m 1.2711937824885051 \u001b[0m(+0.0023392240206401294)\n",
      "     | > avg_loss_1:\u001b[91m 30.004231452941895 \u001b[0m(+1.2776215871175118)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 10/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:42:00) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:42:03 -- STEP: 4/32 -- GLOBAL_STEP: 1000325\u001b[0m\n",
      "     | > loss_disc: 2.935298442840576  (2.8930066227912903)\n",
      "     | > loss_disc_real_0: 0.3087009787559509  (0.22911525890231133)\n",
      "     | > loss_disc_real_1: 0.2789049744606018  (0.2517285421490669)\n",
      "     | > loss_disc_real_2: 0.27336087822914124  (0.24931176006793976)\n",
      "     | > loss_disc_real_3: 0.28265827894210815  (0.24453239142894745)\n",
      "     | > loss_disc_real_4: 0.28257277607917786  (0.23999875783920288)\n",
      "     | > loss_disc_real_5: 0.2719707489013672  (0.2370583526790142)\n",
      "     | > loss_0: 2.935298442840576  (2.8930066227912903)\n",
      "     | > grad_norm_0: tensor(2.2086, device='cuda:0')  (tensor(2.0457, device='cuda:0'))\n",
      "     | > loss_gen: 1.7238073348999023  (1.648240566253662)\n",
      "     | > loss_kl: 2.930959463119507  (3.558816909790039)\n",
      "     | > loss_feat: 0.6891348361968994  (1.087882250547409)\n",
      "     | > loss_mel: 19.905649185180664  (23.512739658355713)\n",
      "     | > loss_duration: 1.397395133972168  (5.674444884061813)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 26.64694595336914  (35.482123374938965)\n",
      "     | > grad_norm_1: tensor(183.5764, device='cuda:0')  (tensor(193.4859, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019975014057813518 \n",
      "     | > current_lr_1: 0.00019975014057813518 \n",
      "     | > step_time: 0.3925  (0.40182989835739136)\n",
      "     | > loader_time: 0.0049  (0.003524482250213623)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:42:13 -- STEP: 29/32 -- GLOBAL_STEP: 1000350\u001b[0m\n",
      "     | > loss_disc: 2.934488296508789  (2.9340925792167925)\n",
      "     | > loss_disc_real_0: 0.3014257550239563  (0.23742967972467685)\n",
      "     | > loss_disc_real_1: 0.2762833833694458  (0.249920790565425)\n",
      "     | > loss_disc_real_2: 0.27870434522628784  (0.24832806299472676)\n",
      "     | > loss_disc_real_3: 0.2651722729206085  (0.25052505423282756)\n",
      "     | > loss_disc_real_4: 0.2597517967224121  (0.2512099583601129)\n",
      "     | > loss_disc_real_5: 0.28539416193962097  (0.24496055522869375)\n",
      "     | > loss_0: 2.934488296508789  (2.9340925792167925)\n",
      "     | > grad_norm_0: tensor(2.8257, device='cuda:0')  (tensor(2.7050, device='cuda:0'))\n",
      "     | > loss_gen: 1.7201383113861084  (1.603301767645211)\n",
      "     | > loss_kl: 3.345304250717163  (3.424360957638971)\n",
      "     | > loss_feat: 0.717498779296875  (0.9283051583273655)\n",
      "     | > loss_mel: 22.53323745727539  (23.74979012587975)\n",
      "     | > loss_duration: 13.095464706420898  (3.487576525786827)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 41.411643981933594  (33.193334316385204)\n",
      "     | > grad_norm_1: tensor(94.5492, device='cuda:0')  (tensor(170.4929, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019975014057813518 \n",
      "     | > current_lr_1: 0.00019975014057813518 \n",
      "     | > step_time: 0.4395  (0.4028469118578681)\n",
      "     | > loader_time: 0.0033  (0.003383060981487406)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.9594881534576416  (2.9594881534576416)\n",
      "     | > loss_disc_real_0: 0.21555767953395844  (0.21555767953395844)\n",
      "     | > loss_disc_real_1: 0.2412979006767273  (0.2412979006767273)\n",
      "     | > loss_disc_real_2: 0.22965668141841888  (0.22965668141841888)\n",
      "     | > loss_disc_real_3: 0.23978734016418457  (0.23978734016418457)\n",
      "     | > loss_disc_real_4: 0.24386091530323029  (0.24386091530323029)\n",
      "     | > loss_disc_real_5: 0.21565519273281097  (0.21565519273281097)\n",
      "     | > loss_0: 2.9594881534576416  (2.9594881534576416)\n",
      "     | > loss_gen: 1.4312524795532227  (1.4312524795532227)\n",
      "     | > loss_kl: 3.4509012699127197  (3.4509012699127197)\n",
      "     | > loss_feat: 0.30938684940338135  (0.30938684940338135)\n",
      "     | > loss_mel: 21.27519416809082  (21.27519416809082)\n",
      "     | > loss_duration: 1.4824193716049194  (1.4824193716049194)\n",
      "     | > loss_1: 27.949155807495117  (27.949155807495117)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.9822394847869873  (2.9822394847869873)\n",
      "     | > loss_disc_real_0: 0.2308882772922516  (0.2308882772922516)\n",
      "     | > loss_disc_real_1: 0.24782831966876984  (0.24782831966876984)\n",
      "     | > loss_disc_real_2: 0.23301208019256592  (0.23301208019256592)\n",
      "     | > loss_disc_real_3: 0.2469947189092636  (0.2469947189092636)\n",
      "     | > loss_disc_real_4: 0.2500137686729431  (0.2500137686729431)\n",
      "     | > loss_disc_real_5: 0.24013222754001617  (0.24013222754001617)\n",
      "     | > loss_0: 2.9822394847869873  (2.9822394847869873)\n",
      "     | > loss_gen: 1.4695910215377808  (1.4695910215377808)\n",
      "     | > loss_kl: 4.0028181076049805  (4.0028181076049805)\n",
      "     | > loss_feat: 0.15965735912322998  (0.15965735912322998)\n",
      "     | > loss_mel: 20.34931755065918  (20.34931755065918)\n",
      "     | > loss_duration: 1.3870656490325928  (1.3870656490325928)\n",
      "     | > loss_1: 27.368450164794922  (27.368450164794922)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 3.1700382232666016  (3.0761388540267944)\n",
      "     | > loss_disc_real_0: 0.06969191133975983  (0.1502900943160057)\n",
      "     | > loss_disc_real_1: 0.153030663728714  (0.2004294916987419)\n",
      "     | > loss_disc_real_2: 0.17363430559635162  (0.20332319289445877)\n",
      "     | > loss_disc_real_3: 0.16596367955207825  (0.20647919923067093)\n",
      "     | > loss_disc_real_4: 0.16671134531497955  (0.20836255699396133)\n",
      "     | > loss_disc_real_5: 0.08580479770898819  (0.16296851262450218)\n",
      "     | > loss_0: 3.1700382232666016  (3.0761388540267944)\n",
      "     | > loss_gen: 0.9286288022994995  (1.1991099119186401)\n",
      "     | > loss_kl: 3.0675454139709473  (3.535181760787964)\n",
      "     | > loss_feat: 2.0440118312835693  (1.1018345952033997)\n",
      "     | > loss_mel: 25.486974716186523  (22.91814613342285)\n",
      "     | > loss_duration: 1.7073355913162231  (1.547200620174408)\n",
      "     | > loss_1: 33.2344970703125  (30.30147361755371)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 3.075307607650757  (3.0758617719014487)\n",
      "     | > loss_disc_real_0: 0.1338645964860916  (0.14481492837270102)\n",
      "     | > loss_disc_real_1: 0.17336659133434296  (0.19140852491060892)\n",
      "     | > loss_disc_real_2: 0.17634031176567078  (0.19432889918486276)\n",
      "     | > loss_disc_real_3: 0.1810089498758316  (0.19798911611239114)\n",
      "     | > loss_disc_real_4: 0.18774093687534332  (0.20148868362108865)\n",
      "     | > loss_disc_real_5: 0.12395904213190079  (0.14996535579363504)\n",
      "     | > loss_0: 3.075307607650757  (3.0758617719014487)\n",
      "     | > loss_gen: 1.1563966274261475  (1.1848721504211426)\n",
      "     | > loss_kl: 4.392751216888428  (3.821038246154785)\n",
      "     | > loss_feat: 1.8718618154525757  (1.3585103352864583)\n",
      "     | > loss_mel: 28.06205940246582  (24.632783889770508)\n",
      "     | > loss_duration: 0.8945119380950928  (1.3296377261479695)\n",
      "     | > loss_1: 36.37757873535156  (32.32684199015299)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 2.945920467376709  (3.0433764457702637)\n",
      "     | > loss_disc_real_0: 0.1877736747264862  (0.1555546149611473)\n",
      "     | > loss_disc_real_1: 0.2183607965707779  (0.19814659282565117)\n",
      "     | > loss_disc_real_2: 0.21525800228118896  (0.19956117495894432)\n",
      "     | > loss_disc_real_3: 0.22904086112976074  (0.20575205236673355)\n",
      "     | > loss_disc_real_4: 0.23747600615024567  (0.21048551425337791)\n",
      "     | > loss_disc_real_5: 0.20185311138629913  (0.16293729469180107)\n",
      "     | > loss_0: 2.945920467376709  (3.0433764457702637)\n",
      "     | > loss_gen: 1.3587071895599365  (1.228330910205841)\n",
      "     | > loss_kl: 3.7393202781677246  (3.80060875415802)\n",
      "     | > loss_feat: 0.7503697872161865  (1.2064751982688904)\n",
      "     | > loss_mel: 21.305397033691406  (23.800937175750732)\n",
      "     | > loss_duration: 1.146626591682434  (1.2838849425315857)\n",
      "     | > loss_1: 28.3004207611084  (31.320236682891846)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 3.079366683959961  (3.0505744934082033)\n",
      "     | > loss_disc_real_0: 0.0998687893152237  (0.14441744983196259)\n",
      "     | > loss_disc_real_1: 0.1383390724658966  (0.18618508875370027)\n",
      "     | > loss_disc_real_2: 0.1573377549648285  (0.19111649096012115)\n",
      "     | > loss_disc_real_3: 0.15394417941570282  (0.1953904777765274)\n",
      "     | > loss_disc_real_4: 0.16288110613822937  (0.2009646326303482)\n",
      "     | > loss_disc_real_5: 0.09113854169845581  (0.148577544093132)\n",
      "     | > loss_0: 3.079366683959961  (3.0505744934082033)\n",
      "     | > loss_gen: 0.9829839468002319  (1.1792615175247192)\n",
      "     | > loss_kl: 3.269277572631836  (3.694342517852783)\n",
      "     | > loss_feat: 2.0866031646728516  (1.3825007915496825)\n",
      "     | > loss_mel: 24.416412353515625  (23.92403221130371)\n",
      "     | > loss_duration: 1.4109454154968262  (1.3092970371246337)\n",
      "     | > loss_1: 32.166221618652344  (31.489433670043944)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 3.2728559970855713  (3.0876214106877646)\n",
      "     | > loss_disc_real_0: 0.1594831496477127  (0.14692839980125427)\n",
      "     | > loss_disc_real_1: 0.21212221682071686  (0.19050794343153635)\n",
      "     | > loss_disc_real_2: 0.19742700457572937  (0.1921682432293892)\n",
      "     | > loss_disc_real_3: 0.2006964236497879  (0.1962748020887375)\n",
      "     | > loss_disc_real_4: 0.19908763468265533  (0.20065179963906607)\n",
      "     | > loss_disc_real_5: 0.1565212607383728  (0.1499014968673388)\n",
      "     | > loss_0: 3.2728559970855713  (3.0876214106877646)\n",
      "     | > loss_gen: 1.1271244287490845  (1.17057200272878)\n",
      "     | > loss_kl: 3.298293113708496  (3.6283342838287354)\n",
      "     | > loss_feat: 0.8610067963600159  (1.2955851256847382)\n",
      "     | > loss_mel: 20.661880493164062  (23.380340258280437)\n",
      "     | > loss_duration: 1.1571733951568604  (1.2839430967966716)\n",
      "     | > loss_1: 27.105478286743164  (30.758774439493816)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.002461592356363932 \u001b[0m(+8.690357208251953e-05)\n",
      "     | > avg_loss_disc:\u001b[91m 3.0876214106877646 \u001b[0m(+0.10436149438222264)\n",
      "     | > avg_loss_disc_real_0:\u001b[92m 0.14692839980125427 \u001b[0m(-0.07878801226615906)\n",
      "     | > avg_loss_disc_real_1:\u001b[92m 0.19050794343153635 \u001b[0m(-0.06933976213137308)\n",
      "     | > avg_loss_disc_real_2:\u001b[92m 0.1921682432293892 \u001b[0m(-0.05422529081503549)\n",
      "     | > avg_loss_disc_real_3:\u001b[92m 0.1962748020887375 \u001b[0m(-0.03293251246213913)\n",
      "     | > avg_loss_disc_real_4:\u001b[92m 0.20065179963906607 \u001b[0m(-0.03352740655342737)\n",
      "     | > avg_loss_disc_real_5:\u001b[92m 0.1499014968673388 \u001b[0m(-0.0829014430443446)\n",
      "     | > avg_loss_0:\u001b[91m 3.0876214106877646 \u001b[0m(+0.10436149438222264)\n",
      "     | > avg_loss_gen:\u001b[92m 1.17057200272878 \u001b[0m(-0.29432356357574463)\n",
      "     | > avg_loss_kl:\u001b[91m 3.6283342838287354 \u001b[0m(+0.20586836338043213)\n",
      "     | > avg_loss_feat:\u001b[91m 1.2955851256847382 \u001b[0m(+0.7975021998087566)\n",
      "     | > avg_loss_mel:\u001b[91m 23.380340258280437 \u001b[0m(+0.03274726867675781)\n",
      "     | > avg_loss_duration:\u001b[91m 1.2839430967966716 \u001b[0m(+0.012749314308166504)\n",
      "     | > avg_loss_1:\u001b[91m 30.758774439493816 \u001b[0m(+0.7545429865519218)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 11/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:42:18) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:42:28 -- STEP: 22/32 -- GLOBAL_STEP: 1000375\u001b[0m\n",
      "     | > loss_disc: 2.9713661670684814  (2.9431525577198374)\n",
      "     | > loss_disc_real_0: 0.214852973818779  (0.24692487648942255)\n",
      "     | > loss_disc_real_1: 0.2179538607597351  (0.2528863224116239)\n",
      "     | > loss_disc_real_2: 0.2121286243200302  (0.2527976686304266)\n",
      "     | > loss_disc_real_3: 0.22949106991291046  (0.25021587312221527)\n",
      "     | > loss_disc_real_4: 0.22334495186805725  (0.2480075095187534)\n",
      "     | > loss_disc_real_5: 0.22450384497642517  (0.2526989592747255)\n",
      "     | > loss_0: 2.9713661670684814  (2.9431525577198374)\n",
      "     | > grad_norm_0: tensor(1.9744, device='cuda:0')  (tensor(1.9589, device='cuda:0'))\n",
      "     | > loss_gen: 1.3869041204452515  (1.5778545412150295)\n",
      "     | > loss_kl: 3.4606661796569824  (3.3794514482671563)\n",
      "     | > loss_feat: 0.4794180393218994  (0.6855712891979651)\n",
      "     | > loss_mel: 20.903913497924805  (22.65971348502419)\n",
      "     | > loss_duration: 13.020298957824707  (3.1475011110305786)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 39.25120162963867  (31.450092055580832)\n",
      "     | > grad_norm_1: tensor(146.5676, device='cuda:0')  (tensor(185.2234, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019972517181056292 \n",
      "     | > current_lr_1: 0.00019972517181056292 \n",
      "     | > step_time: 0.4009  (0.4095141129060225)\n",
      "     | > loader_time: 0.003  (0.0035671645944768734)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.8778882026672363  (2.8778882026672363)\n",
      "     | > loss_disc_real_0: 0.13962437212467194  (0.13962437212467194)\n",
      "     | > loss_disc_real_1: 0.24349458515644073  (0.24349458515644073)\n",
      "     | > loss_disc_real_2: 0.23799675703048706  (0.23799675703048706)\n",
      "     | > loss_disc_real_3: 0.2227843552827835  (0.2227843552827835)\n",
      "     | > loss_disc_real_4: 0.21809718012809753  (0.21809718012809753)\n",
      "     | > loss_disc_real_5: 0.1812628209590912  (0.1812628209590912)\n",
      "     | > loss_0: 2.8778882026672363  (2.8778882026672363)\n",
      "     | > loss_gen: 1.383963942527771  (1.383963942527771)\n",
      "     | > loss_kl: 3.132535457611084  (3.132535457611084)\n",
      "     | > loss_feat: 1.0094704627990723  (1.0094704627990723)\n",
      "     | > loss_mel: 23.8929443359375  (23.8929443359375)\n",
      "     | > loss_duration: 1.4755712747573853  (1.4755712747573853)\n",
      "     | > loss_1: 30.894485473632812  (30.894485473632812)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.916403293609619  (2.916403293609619)\n",
      "     | > loss_disc_real_0: 0.18820598721504211  (0.18820598721504211)\n",
      "     | > loss_disc_real_1: 0.26091963052749634  (0.26091963052749634)\n",
      "     | > loss_disc_real_2: 0.2407587170600891  (0.2407587170600891)\n",
      "     | > loss_disc_real_3: 0.221157044172287  (0.221157044172287)\n",
      "     | > loss_disc_real_4: 0.22653287649154663  (0.22653287649154663)\n",
      "     | > loss_disc_real_5: 0.18541057407855988  (0.18541057407855988)\n",
      "     | > loss_0: 2.916403293609619  (2.916403293609619)\n",
      "     | > loss_gen: 1.4281853437423706  (1.4281853437423706)\n",
      "     | > loss_kl: 3.798478364944458  (3.798478364944458)\n",
      "     | > loss_feat: 0.896425724029541  (0.896425724029541)\n",
      "     | > loss_mel: 31.02159881591797  (31.02159881591797)\n",
      "     | > loss_duration: 1.3916869163513184  (1.3916869163513184)\n",
      "     | > loss_1: 38.536373138427734  (38.536373138427734)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 3.0185539722442627  (2.967478632926941)\n",
      "     | > loss_disc_real_0: 0.11594772338867188  (0.152076855301857)\n",
      "     | > loss_disc_real_1: 0.2374994158744812  (0.24920952320098877)\n",
      "     | > loss_disc_real_2: 0.23078763484954834  (0.23577317595481873)\n",
      "     | > loss_disc_real_3: 0.20680761337280273  (0.21398232877254486)\n",
      "     | > loss_disc_real_4: 0.196585550904274  (0.2115592136979103)\n",
      "     | > loss_disc_real_5: 0.15145929157733917  (0.16843493282794952)\n",
      "     | > loss_0: 3.0185539722442627  (2.967478632926941)\n",
      "     | > loss_gen: 1.2296321392059326  (1.3289087414741516)\n",
      "     | > loss_kl: 2.7871572971343994  (3.2928178310394287)\n",
      "     | > loss_feat: 1.1329015493392944  (1.0146636366844177)\n",
      "     | > loss_mel: 23.14596939086914  (27.083784103393555)\n",
      "     | > loss_duration: 1.7387847900390625  (1.5652358531951904)\n",
      "     | > loss_1: 30.03444480895996  (34.28540897369385)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 2.934072971343994  (2.956343412399292)\n",
      "     | > loss_disc_real_0: 0.1240537017583847  (0.14273580412069956)\n",
      "     | > loss_disc_real_1: 0.23391836881637573  (0.24411247173945108)\n",
      "     | > loss_disc_real_2: 0.21065203845500946  (0.2273994634548823)\n",
      "     | > loss_disc_real_3: 0.17407408356666565  (0.20067958037058511)\n",
      "     | > loss_disc_real_4: 0.16744214296340942  (0.1968535234530767)\n",
      "     | > loss_disc_real_5: 0.12211908400058746  (0.15299631655216217)\n",
      "     | > loss_0: 2.934072971343994  (2.956343412399292)\n",
      "     | > loss_gen: 1.1908820867538452  (1.2828998565673828)\n",
      "     | > loss_kl: 4.055114269256592  (3.546916643778483)\n",
      "     | > loss_feat: 1.5259162187576294  (1.185081164042155)\n",
      "     | > loss_mel: 23.529630661010742  (25.89906628926595)\n",
      "     | > loss_duration: 0.8932651281356812  (1.3412456115086873)\n",
      "     | > loss_1: 31.194807052612305  (33.255208333333336)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 2.895507335662842  (2.9411343932151794)\n",
      "     | > loss_disc_real_0: 0.14081674814224243  (0.14225604012608528)\n",
      "     | > loss_disc_real_1: 0.24512498080730438  (0.2443655990064144)\n",
      "     | > loss_disc_real_2: 0.23599518835544586  (0.2295483946800232)\n",
      "     | > loss_disc_real_3: 0.22760172188282013  (0.20741011574864388)\n",
      "     | > loss_disc_real_4: 0.22876328229904175  (0.20483096316456795)\n",
      "     | > loss_disc_real_5: 0.17266114056110382  (0.15791252255439758)\n",
      "     | > loss_0: 2.895507335662842  (2.9411343932151794)\n",
      "     | > loss_gen: 1.3814914226531982  (1.3075477480888367)\n",
      "     | > loss_kl: 3.5784363746643066  (3.554796576499939)\n",
      "     | > loss_feat: 1.1023162603378296  (1.1643899381160736)\n",
      "     | > loss_mel: 22.175966262817383  (24.96829128265381)\n",
      "     | > loss_duration: 1.155089020729065  (1.2947064638137817)\n",
      "     | > loss_1: 29.393299102783203  (32.2897310256958)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 3.000659942626953  (2.9530395030975343)\n",
      "     | > loss_disc_real_0: 0.15049868822097778  (0.14390456974506377)\n",
      "     | > loss_disc_real_1: 0.2460688203573227  (0.24470624327659607)\n",
      "     | > loss_disc_real_2: 0.23832179605960846  (0.23130307495594024)\n",
      "     | > loss_disc_real_3: 0.2121160328388214  (0.20835129916667938)\n",
      "     | > loss_disc_real_4: 0.20636512339115143  (0.20513779520988465)\n",
      "     | > loss_disc_real_5: 0.18753278255462646  (0.16383657455444336)\n",
      "     | > loss_0: 3.000659942626953  (2.9530395030975343)\n",
      "     | > loss_gen: 1.3268399238586426  (1.311406183242798)\n",
      "     | > loss_kl: 2.75254225730896  (3.3943457126617433)\n",
      "     | > loss_feat: 0.9775183796882629  (1.1270156264305116)\n",
      "     | > loss_mel: 23.23778533935547  (24.622190093994142)\n",
      "     | > loss_duration: 1.4375386238098145  (1.3232728958129882)\n",
      "     | > loss_1: 29.732223510742188  (31.77822952270508)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 3.0008227825164795  (2.961003383000692)\n",
      "     | > loss_disc_real_0: 0.21792450547218323  (0.15624122569958368)\n",
      "     | > loss_disc_real_1: 0.2830825746059418  (0.2511022984981537)\n",
      "     | > loss_disc_real_2: 0.27512824535369873  (0.23860727002223334)\n",
      "     | > loss_disc_real_3: 0.2670897841453552  (0.21814104666312537)\n",
      "     | > loss_disc_real_4: 0.26450109481811523  (0.21503167847792307)\n",
      "     | > loss_disc_real_5: 0.2376682013273239  (0.17614184568325678)\n",
      "     | > loss_0: 3.0008227825164795  (2.961003383000692)\n",
      "     | > loss_gen: 1.5514953136444092  (1.3514210383097331)\n",
      "     | > loss_kl: 3.7565431594848633  (3.4547119537989297)\n",
      "     | > loss_feat: 0.059569116681814194  (0.9491078748057286)\n",
      "     | > loss_mel: 21.814720153808594  (24.15427843729655)\n",
      "     | > loss_duration: 1.162979006767273  (1.2965572476387024)\n",
      "     | > loss_1: 28.345306396484375  (31.20607566833496)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.002467473347981771 \u001b[0m(+5.880991617838831e-06)\n",
      "     | > avg_loss_disc:\u001b[92m 2.961003383000692 \u001b[0m(-0.12661802768707275)\n",
      "     | > avg_loss_disc_real_0:\u001b[91m 0.15624122569958368 \u001b[0m(+0.009312825898329408)\n",
      "     | > avg_loss_disc_real_1:\u001b[91m 0.2511022984981537 \u001b[0m(+0.06059435506661734)\n",
      "     | > avg_loss_disc_real_2:\u001b[91m 0.23860727002223334 \u001b[0m(+0.046439026792844146)\n",
      "     | > avg_loss_disc_real_3:\u001b[91m 0.21814104666312537 \u001b[0m(+0.021866244574387877)\n",
      "     | > avg_loss_disc_real_4:\u001b[91m 0.21503167847792307 \u001b[0m(+0.014379878838856996)\n",
      "     | > avg_loss_disc_real_5:\u001b[91m 0.17614184568325678 \u001b[0m(+0.02624034881591797)\n",
      "     | > avg_loss_0:\u001b[92m 2.961003383000692 \u001b[0m(-0.12661802768707275)\n",
      "     | > avg_loss_gen:\u001b[91m 1.3514210383097331 \u001b[0m(+0.1808490355809531)\n",
      "     | > avg_loss_kl:\u001b[92m 3.4547119537989297 \u001b[0m(-0.17362233002980565)\n",
      "     | > avg_loss_feat:\u001b[92m 0.9491078748057286 \u001b[0m(-0.3464772508790096)\n",
      "     | > avg_loss_mel:\u001b[91m 24.15427843729655 \u001b[0m(+0.7739381790161133)\n",
      "     | > avg_loss_duration:\u001b[91m 1.2965572476387024 \u001b[0m(+0.012614150842030769)\n",
      "     | > avg_loss_1:\u001b[91m 31.20607566833496 \u001b[0m(+0.44730122884114465)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 12/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:42:36) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:42:44 -- STEP: 15/32 -- GLOBAL_STEP: 1000400\u001b[0m\n",
      "     | > loss_disc: 2.967383623123169  (2.9279075622558595)\n",
      "     | > loss_disc_real_0: 0.23592665791511536  (0.2470593919356664)\n",
      "     | > loss_disc_real_1: 0.22440700232982635  (0.25732646783192953)\n",
      "     | > loss_disc_real_2: 0.23154160380363464  (0.25966643691062924)\n",
      "     | > loss_disc_real_3: 0.28072381019592285  (0.2626300762097041)\n",
      "     | > loss_disc_real_4: 0.27567002177238464  (0.264117216070493)\n",
      "     | > loss_disc_real_5: 0.310916930437088  (0.2676515688498815)\n",
      "     | > loss_0: 2.967383623123169  (2.9279075622558595)\n",
      "     | > grad_norm_0: tensor(1.2236, device='cuda:0')  (tensor(2.5447, device='cuda:0'))\n",
      "     | > loss_gen: 1.3633183240890503  (1.6653982718785605)\n",
      "     | > loss_kl: 3.1111483573913574  (3.419169616699219)\n",
      "     | > loss_feat: 0.6716402173042297  (0.9823302606741587)\n",
      "     | > loss_mel: 21.920936584472656  (24.427758026123048)\n",
      "     | > loss_duration: 1.3385093212127686  (3.1971007585525513)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 28.40555191040039  (33.69175707499187)\n",
      "     | > grad_norm_1: tensor(110.4549, device='cuda:0')  (tensor(135.1009, device='cuda:0'))\n",
      "     | > current_lr_0: 0.0001997002061640866 \n",
      "     | > current_lr_1: 0.0001997002061640866 \n",
      "     | > step_time: 0.4337  (0.44945468902587893)\n",
      "     | > loader_time: 0.0042  (0.003650220235188802)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.9360387325286865  (2.9360387325286865)\n",
      "     | > loss_disc_real_0: 0.26913970708847046  (0.26913970708847046)\n",
      "     | > loss_disc_real_1: 0.25710296630859375  (0.25710296630859375)\n",
      "     | > loss_disc_real_2: 0.26769405603408813  (0.26769405603408813)\n",
      "     | > loss_disc_real_3: 0.2295631617307663  (0.2295631617307663)\n",
      "     | > loss_disc_real_4: 0.2226274162530899  (0.2226274162530899)\n",
      "     | > loss_disc_real_5: 0.18994279205799103  (0.18994279205799103)\n",
      "     | > loss_0: 2.9360387325286865  (2.9360387325286865)\n",
      "     | > loss_gen: 1.5138155221939087  (1.5138155221939087)\n",
      "     | > loss_kl: 3.2684719562530518  (3.2684719562530518)\n",
      "     | > loss_feat: 0.924938440322876  (0.924938440322876)\n",
      "     | > loss_mel: 23.49406623840332  (23.49406623840332)\n",
      "     | > loss_duration: 1.4771416187286377  (1.4771416187286377)\n",
      "     | > loss_1: 30.678434371948242  (30.678434371948242)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.894996166229248  (2.894996166229248)\n",
      "     | > loss_disc_real_0: 0.22618739306926727  (0.22618739306926727)\n",
      "     | > loss_disc_real_1: 0.2544235587120056  (0.2544235587120056)\n",
      "     | > loss_disc_real_2: 0.26977404952049255  (0.26977404952049255)\n",
      "     | > loss_disc_real_3: 0.22429272532463074  (0.22429272532463074)\n",
      "     | > loss_disc_real_4: 0.225126713514328  (0.225126713514328)\n",
      "     | > loss_disc_real_5: 0.19850169122219086  (0.19850169122219086)\n",
      "     | > loss_0: 2.894996166229248  (2.894996166229248)\n",
      "     | > loss_gen: 1.515844702720642  (1.515844702720642)\n",
      "     | > loss_kl: 3.797612428665161  (3.797612428665161)\n",
      "     | > loss_feat: 0.9113935232162476  (0.9113935232162476)\n",
      "     | > loss_mel: 25.083450317382812  (25.083450317382812)\n",
      "     | > loss_duration: 1.352948784828186  (1.352948784828186)\n",
      "     | > loss_1: 32.66124725341797  (32.66124725341797)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 2.9402661323547363  (2.917631149291992)\n",
      "     | > loss_disc_real_0: 0.24623583257198334  (0.2362116128206253)\n",
      "     | > loss_disc_real_1: 0.27338308095932007  (0.26390331983566284)\n",
      "     | > loss_disc_real_2: 0.28322580456733704  (0.2764999270439148)\n",
      "     | > loss_disc_real_3: 0.24969711899757385  (0.2369949221611023)\n",
      "     | > loss_disc_real_4: 0.2481933981180191  (0.23666005581617355)\n",
      "     | > loss_disc_real_5: 0.2070005238056183  (0.20275110751390457)\n",
      "     | > loss_0: 2.9402661323547363  (2.917631149291992)\n",
      "     | > loss_gen: 1.5851044654846191  (1.5504745841026306)\n",
      "     | > loss_kl: 3.35962176322937  (3.5786170959472656)\n",
      "     | > loss_feat: 0.6476466059684753  (0.7795200645923615)\n",
      "     | > loss_mel: 23.904541015625  (24.493995666503906)\n",
      "     | > loss_duration: 1.6811091899871826  (1.5170289874076843)\n",
      "     | > loss_1: 31.178022384643555  (31.91963481903076)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 3.1522536277770996  (2.9958386421203613)\n",
      "     | > loss_disc_real_0: 0.2257174700498581  (0.23271356523036957)\n",
      "     | > loss_disc_real_1: 0.2507476210594177  (0.2595180869102478)\n",
      "     | > loss_disc_real_2: 0.25009405612945557  (0.2676979700724284)\n",
      "     | > loss_disc_real_3: 0.20975999534130096  (0.22791661322116852)\n",
      "     | > loss_disc_real_4: 0.19456006586551666  (0.22262672583262125)\n",
      "     | > loss_disc_real_5: 0.1829194724559784  (0.19614056249459585)\n",
      "     | > loss_0: 3.1522536277770996  (2.9958386421203613)\n",
      "     | > loss_gen: 1.3246862888336182  (1.4752118190129597)\n",
      "     | > loss_kl: 3.847930669784546  (3.668388287226359)\n",
      "     | > loss_feat: 1.0022321939468384  (0.8537574410438538)\n",
      "     | > loss_mel: 23.219974517822266  (24.06932195027669)\n",
      "     | > loss_duration: 0.8692184090614319  (1.3010921279589336)\n",
      "     | > loss_1: 30.264041900634766  (31.367770512898762)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 2.99107027053833  (2.9946465492248535)\n",
      "     | > loss_disc_real_0: 0.28149932622909546  (0.24491000548005104)\n",
      "     | > loss_disc_real_1: 0.2909404933452606  (0.267373688519001)\n",
      "     | > loss_disc_real_2: 0.29025721549987793  (0.27333778142929077)\n",
      "     | > loss_disc_real_3: 0.255219429731369  (0.23474231734871864)\n",
      "     | > loss_disc_real_4: 0.24991144239902496  (0.22944790497422218)\n",
      "     | > loss_disc_real_5: 0.2120881825685501  (0.2001274675130844)\n",
      "     | > loss_0: 2.99107027053833  (2.9946465492248535)\n",
      "     | > loss_gen: 1.6036090850830078  (1.5073111355304718)\n",
      "     | > loss_kl: 3.5109078884124756  (3.629018187522888)\n",
      "     | > loss_feat: 0.17838643491268158  (0.6849146895110607)\n",
      "     | > loss_mel: 19.099597930908203  (22.82689094543457)\n",
      "     | > loss_duration: 1.1378759145736694  (1.2602880746126175)\n",
      "     | > loss_1: 25.530378341674805  (29.908422470092773)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 2.9239609241485596  (2.9805094242095946)\n",
      "     | > loss_disc_real_0: 0.24093306064605713  (0.24411461651325225)\n",
      "     | > loss_disc_real_1: 0.26618024706840515  (0.2671350002288818)\n",
      "     | > loss_disc_real_2: 0.26319438219070435  (0.2713091015815735)\n",
      "     | > loss_disc_real_3: 0.22514216601848602  (0.2328222870826721)\n",
      "     | > loss_disc_real_4: 0.20767706632614136  (0.22509373724460602)\n",
      "     | > loss_disc_real_5: 0.19230683147907257  (0.19856334030628203)\n",
      "     | > loss_0: 2.9239609241485596  (2.9805094242095946)\n",
      "     | > loss_gen: 1.5021405220031738  (1.5062770128250123)\n",
      "     | > loss_kl: 3.348956346511841  (3.5730058193206786)\n",
      "     | > loss_feat: 0.7984457612037659  (0.7076209038496017)\n",
      "     | > loss_mel: 19.34601402282715  (22.130715560913085)\n",
      "     | > loss_duration: 1.4183542728424072  (1.2919013142585754)\n",
      "     | > loss_1: 26.413909912109375  (29.209519958496095)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 2.972698211669922  (2.9792075554529824)\n",
      "     | > loss_disc_real_0: 0.2631244957447052  (0.24728292971849442)\n",
      "     | > loss_disc_real_1: 0.26679959893226624  (0.26707910001277924)\n",
      "     | > loss_disc_real_2: 0.2746449410915375  (0.27186507483323413)\n",
      "     | > loss_disc_real_3: 0.23756647109985352  (0.23361298441886902)\n",
      "     | > loss_disc_real_4: 0.22987079620361328  (0.2258899137377739)\n",
      "     | > loss_disc_real_5: 0.1960676610469818  (0.19814739376306534)\n",
      "     | > loss_0: 2.972698211669922  (2.9792075554529824)\n",
      "     | > loss_gen: 1.513458490371704  (1.507473925749461)\n",
      "     | > loss_kl: 3.3523483276367188  (3.5362295707066855)\n",
      "     | > loss_feat: 0.6593706011772156  (0.6995791867375374)\n",
      "     | > loss_mel: 23.09226417541504  (22.290973663330078)\n",
      "     | > loss_duration: 1.1596312522888184  (1.2698563039302826)\n",
      "     | > loss_1: 29.77707290649414  (29.30411211649577)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.002460956573486328 \u001b[0m(-6.516774495442853e-06)\n",
      "     | > avg_loss_disc:\u001b[91m 2.9792075554529824 \u001b[0m(+0.018204172452290557)\n",
      "     | > avg_loss_disc_real_0:\u001b[91m 0.24728292971849442 \u001b[0m(+0.09104170401891074)\n",
      "     | > avg_loss_disc_real_1:\u001b[91m 0.26707910001277924 \u001b[0m(+0.01597680151462555)\n",
      "     | > avg_loss_disc_real_2:\u001b[91m 0.27186507483323413 \u001b[0m(+0.033257804811000796)\n",
      "     | > avg_loss_disc_real_3:\u001b[91m 0.23361298441886902 \u001b[0m(+0.015471937755743653)\n",
      "     | > avg_loss_disc_real_4:\u001b[91m 0.2258899137377739 \u001b[0m(+0.01085823525985083)\n",
      "     | > avg_loss_disc_real_5:\u001b[91m 0.19814739376306534 \u001b[0m(+0.022005548079808562)\n",
      "     | > avg_loss_0:\u001b[91m 2.9792075554529824 \u001b[0m(+0.018204172452290557)\n",
      "     | > avg_loss_gen:\u001b[91m 1.507473925749461 \u001b[0m(+0.15605288743972778)\n",
      "     | > avg_loss_kl:\u001b[91m 3.5362295707066855 \u001b[0m(+0.08151761690775583)\n",
      "     | > avg_loss_feat:\u001b[92m 0.6995791867375374 \u001b[0m(-0.24952868806819117)\n",
      "     | > avg_loss_mel:\u001b[92m 22.290973663330078 \u001b[0m(-1.8633047739664725)\n",
      "     | > avg_loss_duration:\u001b[92m 1.2698563039302826 \u001b[0m(-0.0267009437084198)\n",
      "     | > avg_loss_1:\u001b[92m 29.30411211649577 \u001b[0m(-1.9019635518391915)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 13/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:42:55) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:42:59 -- STEP: 8/32 -- GLOBAL_STEP: 1000425\u001b[0m\n",
      "     | > loss_disc: 2.9304699897766113  (2.9442722499370575)\n",
      "     | > loss_disc_real_0: 0.163129985332489  (0.24129522778093818)\n",
      "     | > loss_disc_real_1: 0.27867937088012695  (0.2585197649896145)\n",
      "     | > loss_disc_real_2: 0.28915420174598694  (0.25785895995795727)\n",
      "     | > loss_disc_real_3: 0.2915884256362915  (0.2648894414305687)\n",
      "     | > loss_disc_real_4: 0.29907816648483276  (0.26207722909748554)\n",
      "     | > loss_disc_real_5: 0.22154486179351807  (0.24817545339465139)\n",
      "     | > loss_0: 2.9304699897766113  (2.9442722499370575)\n",
      "     | > grad_norm_0: tensor(2.6239, device='cuda:0')  (tensor(2.1953, device='cuda:0'))\n",
      "     | > loss_gen: 1.6841001510620117  (1.633663296699524)\n",
      "     | > loss_kl: 3.477492094039917  (3.518806368112564)\n",
      "     | > loss_feat: 0.9253401160240173  (0.9460066556930542)\n",
      "     | > loss_mel: 25.595888137817383  (22.70574116706848)\n",
      "     | > loss_duration: 1.7452071905136108  (3.598430335521698)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 33.42802810668945  (32.402647495269775)\n",
      "     | > grad_norm_1: tensor(98.3312, device='cuda:0')  (tensor(134.1837, device='cuda:0'))\n",
      "     | > current_lr_0: 0.00019967524363831608 \n",
      "     | > current_lr_1: 0.00019967524363831608 \n",
      "     | > step_time: 0.462  (0.41923171281814575)\n",
      "     | > loader_time: 0.0046  (0.003546595573425293)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.997973918914795  (2.997973918914795)\n",
      "     | > loss_disc_real_0: 0.296810120344162  (0.296810120344162)\n",
      "     | > loss_disc_real_1: 0.22450734674930573  (0.22450734674930573)\n",
      "     | > loss_disc_real_2: 0.26638832688331604  (0.26638832688331604)\n",
      "     | > loss_disc_real_3: 0.27325737476348877  (0.27325737476348877)\n",
      "     | > loss_disc_real_4: 0.27791863679885864  (0.27791863679885864)\n",
      "     | > loss_disc_real_5: 0.2992372214794159  (0.2992372214794159)\n",
      "     | > loss_0: 2.997973918914795  (2.997973918914795)\n",
      "     | > loss_gen: 1.6612581014633179  (1.6612581014633179)\n",
      "     | > loss_kl: 3.085458278656006  (3.085458278656006)\n",
      "     | > loss_feat: 0.16434288024902344  (0.16434288024902344)\n",
      "     | > loss_mel: 22.046234130859375  (22.046234130859375)\n",
      "     | > loss_duration: 1.4559197425842285  (1.4559197425842285)\n",
      "     | > loss_1: 28.4132137298584  (28.4132137298584)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 3.019620418548584  (3.019620418548584)\n",
      "     | > loss_disc_real_0: 0.29604923725128174  (0.29604923725128174)\n",
      "     | > loss_disc_real_1: 0.22010622918605804  (0.22010622918605804)\n",
      "     | > loss_disc_real_2: 0.2602440118789673  (0.2602440118789673)\n",
      "     | > loss_disc_real_3: 0.26871809363365173  (0.26871809363365173)\n",
      "     | > loss_disc_real_4: 0.271497905254364  (0.271497905254364)\n",
      "     | > loss_disc_real_5: 0.3059164583683014  (0.3059164583683014)\n",
      "     | > loss_0: 3.019620418548584  (3.019620418548584)\n",
      "     | > loss_gen: 1.6189210414886475  (1.6189210414886475)\n",
      "     | > loss_kl: 3.7475414276123047  (3.7475414276123047)\n",
      "     | > loss_feat: 0.44765305519104004  (0.44765305519104004)\n",
      "     | > loss_mel: 28.930320739746094  (28.930320739746094)\n",
      "     | > loss_duration: 1.3520424365997314  (1.3520424365997314)\n",
      "     | > loss_1: 36.09647750854492  (36.09647750854492)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 2.995051145553589  (3.0073357820510864)\n",
      "     | > loss_disc_real_0: 0.2876149117946625  (0.2918320745229721)\n",
      "     | > loss_disc_real_1: 0.22257928550243378  (0.2213427573442459)\n",
      "     | > loss_disc_real_2: 0.2594121992588043  (0.2598281055688858)\n",
      "     | > loss_disc_real_3: 0.262812077999115  (0.26576508581638336)\n",
      "     | > loss_disc_real_4: 0.26682162284851074  (0.2691597640514374)\n",
      "     | > loss_disc_real_5: 0.2931026816368103  (0.29950957000255585)\n",
      "     | > loss_0: 2.995051145553589  (3.0073357820510864)\n",
      "     | > loss_gen: 1.6136537790298462  (1.6162874102592468)\n",
      "     | > loss_kl: 3.1228740215301514  (3.435207724571228)\n",
      "     | > loss_feat: 0.3332598805427551  (0.3904564678668976)\n",
      "     | > loss_mel: 21.636003494262695  (25.283162117004395)\n",
      "     | > loss_duration: 1.719710111618042  (1.5358762741088867)\n",
      "     | > loss_1: 28.425498962402344  (32.26098823547363)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 2.968665599822998  (2.99444572130839)\n",
      "     | > loss_disc_real_0: 0.2687070369720459  (0.2841237286726634)\n",
      "     | > loss_disc_real_1: 0.2077282965183258  (0.21680460373560587)\n",
      "     | > loss_disc_real_2: 0.24060776829719543  (0.25342132647832233)\n",
      "     | > loss_disc_real_3: 0.2427181452512741  (0.2580827722946803)\n",
      "     | > loss_disc_real_4: 0.24540548026561737  (0.26124166945616406)\n",
      "     | > loss_disc_real_5: 0.26320528984069824  (0.28740814328193665)\n",
      "     | > loss_0: 2.968665599822998  (2.99444572130839)\n",
      "     | > loss_gen: 1.527557373046875  (1.5867107311884563)\n",
      "     | > loss_kl: 3.6059834957122803  (3.4921329816182456)\n",
      "     | > loss_feat: 0.9385595321655273  (0.5731574892997742)\n",
      "     | > loss_mel: 25.374839782714844  (25.31372133890788)\n",
      "     | > loss_duration: 0.8734457492828369  (1.3150660991668701)\n",
      "     | > loss_1: 32.32038879394531  (32.28078842163086)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 3.0202672481536865  (3.0009011030197144)\n",
      "     | > loss_disc_real_0: 0.23955421149730682  (0.27298134937882423)\n",
      "     | > loss_disc_real_1: 0.19861797988414764  (0.21225794777274132)\n",
      "     | > loss_disc_real_2: 0.2338825762271881  (0.2485366389155388)\n",
      "     | > loss_disc_real_3: 0.23943471908569336  (0.25342075899243355)\n",
      "     | > loss_disc_real_4: 0.23844140768051147  (0.2555416040122509)\n",
      "     | > loss_disc_real_5: 0.2577842175960541  (0.280002161860466)\n",
      "     | > loss_0: 3.0202672481536865  (3.0009011030197144)\n",
      "     | > loss_gen: 1.4254298210144043  (1.5463905036449432)\n",
      "     | > loss_kl: 3.5600359439849854  (3.5091087222099304)\n",
      "     | > loss_feat: 1.0092365741729736  (0.682177260518074)\n",
      "     | > loss_mel: 24.56861114501953  (25.12744379043579)\n",
      "     | > loss_duration: 1.140622854232788  (1.2714552879333496)\n",
      "     | > loss_1: 31.703937530517578  (32.13657569885254)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss_disc: 3.092440605163574  (3.0192090034484864)\n",
      "     | > loss_disc_real_0: 0.2119014412164688  (0.26076536774635317)\n",
      "     | > loss_disc_real_1: 0.17103047668933868  (0.2040124535560608)\n",
      "     | > loss_disc_real_2: 0.19923309981822968  (0.23867593109607696)\n",
      "     | > loss_disc_real_3: 0.18757636845111847  (0.24025188088417054)\n",
      "     | > loss_disc_real_4: 0.18081814050674438  (0.2405969113111496)\n",
      "     | > loss_disc_real_5: 0.2159416526556015  (0.2671900600194931)\n",
      "     | > loss_0: 3.092440605163574  (3.0192090034484864)\n",
      "     | > loss_gen: 1.2443829774856567  (1.4859889984130858)\n",
      "     | > loss_kl: 3.005841016769409  (3.408455181121826)\n",
      "     | > loss_feat: 1.3799712657928467  (0.8217360615730286)\n",
      "     | > loss_mel: 21.942537307739258  (24.490462493896484)\n",
      "     | > loss_duration: 1.4085321426391602  (1.2988706588745118)\n",
      "     | > loss_1: 28.981266021728516  (31.505513763427736)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss_disc: 2.995964527130127  (3.0153349240620932)\n",
      "     | > loss_disc_real_0: 0.2414042353630066  (0.2575385123491287)\n",
      "     | > loss_disc_real_1: 0.19839102029800415  (0.20307554801305136)\n",
      "     | > loss_disc_real_2: 0.22120361030101776  (0.23576387763023376)\n",
      "     | > loss_disc_real_3: 0.22742165625095367  (0.2381135101119677)\n",
      "     | > loss_disc_real_4: 0.2306346744298935  (0.2389365384976069)\n",
      "     | > loss_disc_real_5: 0.23766735196113586  (0.26226960867643356)\n",
      "     | > loss_0: 2.995964527130127  (3.0153349240620932)\n",
      "     | > loss_gen: 1.4107130765914917  (1.4734430114428203)\n",
      "     | > loss_kl: 2.853968381881714  (3.3160407145818076)\n",
      "     | > loss_feat: 1.0747942924499512  (0.863912433385849)\n",
      "     | > loss_mel: 23.928176879882812  (24.396748224894207)\n",
      "     | > loss_duration: 1.1407802104949951  (1.272522250811259)\n",
      "     | > loss_1: 30.408432006835938  (31.32266680399577)\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0024423996607462564 \u001b[0m(-1.855691274007176e-05)\n",
      "     | > avg_loss_disc:\u001b[91m 3.0153349240620932 \u001b[0m(+0.03612736860911081)\n",
      "     | > avg_loss_disc_real_0:\u001b[91m 0.2575385123491287 \u001b[0m(+0.010255582630634308)\n",
      "     | > avg_loss_disc_real_1:\u001b[92m 0.20307554801305136 \u001b[0m(-0.06400355199972788)\n",
      "     | > avg_loss_disc_real_2:\u001b[92m 0.23576387763023376 \u001b[0m(-0.03610119720300037)\n",
      "     | > avg_loss_disc_real_3:\u001b[91m 0.2381135101119677 \u001b[0m(+0.004500525693098695)\n",
      "     | > avg_loss_disc_real_4:\u001b[91m 0.2389365384976069 \u001b[0m(+0.013046624759833009)\n",
      "     | > avg_loss_disc_real_5:\u001b[91m 0.26226960867643356 \u001b[0m(+0.06412221491336823)\n",
      "     | > avg_loss_0:\u001b[91m 3.0153349240620932 \u001b[0m(+0.03612736860911081)\n",
      "     | > avg_loss_gen:\u001b[92m 1.4734430114428203 \u001b[0m(-0.034030914306640625)\n",
      "     | > avg_loss_kl:\u001b[92m 3.3160407145818076 \u001b[0m(-0.22018885612487793)\n",
      "     | > avg_loss_feat:\u001b[91m 0.863912433385849 \u001b[0m(+0.16433324664831161)\n",
      "     | > avg_loss_mel:\u001b[91m 24.396748224894207 \u001b[0m(+2.105774561564129)\n",
      "     | > avg_loss_duration:\u001b[91m 1.272522250811259 \u001b[0m(+0.002665946880976433)\n",
      "     | > avg_loss_1:\u001b[91m 31.32266680399577 \u001b[0m(+2.0185546875)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 14/5000\u001b[0m\n",
      " --> /home/sagemaker-user/dist/main/vitstts_checkpoint/vits_tyler1_phonemes-March-01-2024_07+38AM-e526ca1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-03-01 07:43:13) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:43:14 -- STEP: 1/32 -- GLOBAL_STEP: 1000450\u001b[0m\n",
      "     | > loss_disc: 2.991879463195801  (2.991879463195801)\n",
      "     | > loss_disc_real_0: 0.25866761803627014  (0.25866761803627014)\n",
      "     | > loss_disc_real_1: 0.2811332643032074  (0.2811332643032074)\n",
      "     | > loss_disc_real_2: 0.24196726083755493  (0.24196726083755493)\n",
      "     | > loss_disc_real_3: 0.215794637799263  (0.215794637799263)\n",
      "     | > loss_disc_real_4: 0.24737854301929474  (0.24737854301929474)\n",
      "     | > loss_disc_real_5: 0.24609224498271942  (0.24609224498271942)\n",
      "     | > loss_0: 2.991879463195801  (2.991879463195801)\n",
      "     | > grad_norm_0: tensor(2.7324, device='cuda:0')  (tensor(2.7324, device='cuda:0'))\n",
      "     | > loss_gen: 1.4395909309387207  (1.4395909309387207)\n",
      "     | > loss_kl: 3.524757146835327  (3.524757146835327)\n",
      "     | > loss_feat: 0.7062395811080933  (0.7062395811080933)\n",
      "     | > loss_mel: 23.392162322998047  (23.392162322998047)\n",
      "     | > loss_duration: 1.3900766372680664  (1.3900766372680664)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 30.45282745361328  (30.45282745361328)\n",
      "     | > grad_norm_1: tensor(158.8653, device='cuda:0')  (tensor(158.8653, device='cuda:0'))\n",
      "     | > current_lr_0: 0.0001996502842328613 \n",
      "     | > current_lr_1: 0.0001996502842328613 \n",
      "     | > step_time: 0.4159  (0.4158644676208496)\n",
      "     | > loader_time: 0.0038  (0.0038497447967529297)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-03-01 07:43:25 -- STEP: 26/32 -- GLOBAL_STEP: 1000475\u001b[0m\n",
      "     | > loss_disc: 3.139615774154663  (2.9585226682516246)\n",
      "     | > loss_disc_real_0: 0.2031179964542389  (0.24239331827713892)\n",
      "     | > loss_disc_real_1: 0.19636757671833038  (0.24922533505238015)\n",
      "     | > loss_disc_real_2: 0.18515776097774506  (0.24871676128644213)\n",
      "     | > loss_disc_real_3: 0.20975227653980255  (0.2475858021240968)\n",
      "     | > loss_disc_real_4: 0.2284715324640274  (0.24759428546978884)\n",
      "     | > loss_disc_real_5: 0.21464554965496063  (0.2405845929796879)\n",
      "     | > loss_0: 3.139615774154663  (2.9585226682516246)\n",
      "     | > grad_norm_0: tensor(5.4310, device='cuda:0')  (tensor(3.1935, device='cuda:0'))\n",
      "     | > loss_gen: 1.7568140029907227  (1.58144604242765)\n",
      "     | > loss_kl: 3.846388816833496  (3.3326969605225782)\n",
      "     | > loss_feat: 1.3239190578460693  (0.830104205184258)\n",
      "     | > loss_mel: 24.23993492126465  (23.29283171433669)\n",
      "     | > loss_duration: 1.6300740242004395  (2.8549331105672398)\n",
      "     | > amp_scaler: 128.0  (128.0)\n",
      "     | > loss_1: 32.7971305847168  (31.892012082613427)\n",
      "     | > grad_norm_1: tensor(188.5036, device='cuda:0')  (tensor(177.3233, device='cuda:0'))\n",
      "     | > current_lr_0: 0.0001996502842328613 \n",
      "     | > current_lr_1: 0.0001996502842328613 \n",
      "     | > step_time: 0.3977  (0.4119472320263202)\n",
      "     | > loader_time: 0.0028  (0.003440077488238995)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss_disc: 2.899077892303467  (2.899077892303467)\n",
      "     | > loss_disc_real_0: 0.20739395916461945  (0.20739395916461945)\n",
      "     | > loss_disc_real_1: 0.2013736516237259  (0.2013736516237259)\n",
      "     | > loss_disc_real_2: 0.20145614445209503  (0.20145614445209503)\n",
      "     | > loss_disc_real_3: 0.21248741447925568  (0.21248741447925568)\n",
      "     | > loss_disc_real_4: 0.20871001482009888  (0.20871001482009888)\n",
      "     | > loss_disc_real_5: 0.20574265718460083  (0.20574265718460083)\n",
      "     | > loss_0: 2.899077892303467  (2.899077892303467)\n",
      "     | > loss_gen: 1.3541221618652344  (1.3541221618652344)\n",
      "     | > loss_kl: 3.4640824794769287  (3.4640824794769287)\n",
      "     | > loss_feat: 0.7054261565208435  (0.7054261565208435)\n",
      "     | > loss_mel: 22.767059326171875  (22.767059326171875)\n",
      "     | > loss_duration: 1.475252628326416  (1.475252628326416)\n",
      "     | > loss_1: 29.765941619873047  (29.765941619873047)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss_disc: 2.929184913635254  (2.929184913635254)\n",
      "     | > loss_disc_real_0: 0.19749385118484497  (0.19749385118484497)\n",
      "     | > loss_disc_real_1: 0.19974038004875183  (0.19974038004875183)\n",
      "     | > loss_disc_real_2: 0.1901724487543106  (0.1901724487543106)\n",
      "     | > loss_disc_real_3: 0.20070067048072815  (0.20070067048072815)\n",
      "     | > loss_disc_real_4: 0.2022736370563507  (0.2022736370563507)\n",
      "     | > loss_disc_real_5: 0.20349165797233582  (0.20349165797233582)\n",
      "     | > loss_0: 2.929184913635254  (2.929184913635254)\n",
      "     | > loss_gen: 1.3079580068588257  (1.3079580068588257)\n",
      "     | > loss_kl: 3.664959192276001  (3.664959192276001)\n",
      "     | > loss_feat: 1.0870920419692993  (1.0870920419692993)\n",
      "     | > loss_mel: 30.799768447875977  (30.799768447875977)\n",
      "     | > loss_duration: 1.3801491260528564  (1.3801491260528564)\n",
      "     | > loss_1: 38.239925384521484  (38.239925384521484)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss_disc: 2.9204394817352295  (2.9248121976852417)\n",
      "     | > loss_disc_real_0: 0.22622808814048767  (0.21186096966266632)\n",
      "     | > loss_disc_real_1: 0.2012132853269577  (0.20047683268785477)\n",
      "     | > loss_disc_real_2: 0.1928696185350418  (0.1915210336446762)\n",
      "     | > loss_disc_real_3: 0.20027980208396912  (0.20049023628234863)\n",
      "     | > loss_disc_real_4: 0.18807421624660492  (0.1951739266514778)\n",
      "     | > loss_disc_real_5: 0.17225049436092377  (0.1878710761666298)\n",
      "     | > loss_0: 2.9204394817352295  (2.9248121976852417)\n",
      "     | > loss_gen: 1.299906849861145  (1.3039324283599854)\n",
      "     | > loss_kl: 2.538041114807129  (3.101500153541565)\n",
      "     | > loss_feat: 0.964422345161438  (1.0257571935653687)\n",
      "     | > loss_mel: 22.850069046020508  (26.824918746948242)\n",
      "     | > loss_duration: 1.7225638628005981  (1.5513564944267273)\n",
      "     | > loss_1: 29.375003814697266  (33.807464599609375)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss_disc: 2.9370129108428955  (2.9288791020711265)\n",
      "     | > loss_disc_real_0: 0.2672325670719147  (0.23031816879908243)\n",
      "     | > loss_disc_real_1: 0.2160109430551529  (0.20565486947695413)\n",
      "     | > loss_disc_real_2: 0.21506018936634064  (0.19936741888523102)\n",
      "     | > loss_disc_real_3: 0.21713443100452423  (0.2060383011897405)\n",
      "     | > loss_disc_real_4: 0.21863892674446106  (0.2029955933491389)\n",
      "     | > loss_disc_real_5: 0.21409887075424194  (0.19661367436250052)\n",
      "     | > loss_0: 2.9370129108428955  (2.9288791020711265)\n",
      "     | > loss_gen: 1.4203217029571533  (1.342728853225708)\n",
      "     | > loss_kl: 3.7642478942871094  (3.322416067123413)\n",
      "     | > loss_feat: 0.28711187839508057  (0.779542088508606)\n",
      "     | > loss_mel: 23.181781768798828  (25.61053975423177)\n",
      "     | > loss_duration: 0.8660595417022705  (1.3229241768519084)\n",
      "     | > loss_1: 29.51952362060547  (32.378150939941406)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss_disc: 2.9029455184936523  (2.922395706176758)\n",
      "     | > loss_disc_real